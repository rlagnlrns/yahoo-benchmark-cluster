2020-08-26 08:17:51,550 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-26 08:17:51,571 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-26 08:17:51,989 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-26 08:17:52,165 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-26 08:17:52,242 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-26 08:17:52,452 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-26 08:17:52,614 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-26 08:17:52,619 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-26 08:17:52,624 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-26 08:17:52,660 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-26 08:17:52,662 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-26 08:17:52,662 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-26 08:17:52,682 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-26 08:17:52,683 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-26 08:17:52,683 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-26 08:17:52,684 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-26 08:17:52,755 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-26 08:17:52,852 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-26 08:17:52,852 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-26 08:17:52,868 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-26 08:17:52,875 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-26 08:17:52,878 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-26 08:17:52,880 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-26 08:17:52,881 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-26 08:17:52,884 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-26 08:17:52,968 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-26 08:17:52,968 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-26 08:17:52,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-26 08:17:52,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-26 08:17:52,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-26 08:17:52,982 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-26 08:17:52,983 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-26 08:17:52,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 08:17:52,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 08:17:52,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 08:17:52,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-26 08:17:52,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-26 08:17:53,000 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-26 08:17:53,000 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-26 08:17:53,050 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-26 08:17:53,051 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-26 08:17:53,051 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-26 08:17:53,051 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 08:17:53,052 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-26 08:17:53,052 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-26 08:17:53,054 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-26 08:17:53,054 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 08:17:53,054 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-26 08:17:53,054 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-26 08:17:53,059 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-26 08:17:53,155 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 08:17:53,175 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-26 08:17:53,352 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-26 08:17:53,352 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 08:17:53,354 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-26 08:17:53,377 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 08:17:53,384 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2020-08-26 08:17:53,443 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-26 08:17:53,444 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 08:17:53,444 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2020-08-26 08:17:53,493 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 08:17:53,494 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-26 08:17:53,499 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-26 08:17:53,502 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-26 08:17:53,503 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 08:17:53,532 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-26 08:17:53,681 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-26 08:17:53,689 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-26 08:17:53,697 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-26 08:17:53,704 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-26 08:17:53,707 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-26 08:17:53,708 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-26 08:17:53,708 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-26 08:17:53,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-26 08:17:53,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-26 08:17:53,708 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-26 08:17:53,712 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-26 08:17:53,712 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-26 08:17:54,052 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-26 08:17:54,054 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-26 08:17:54,055 INFO org.mortbay.log: jetty-6.1.26
2020-08-26 08:17:54,125 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2020-08-26 08:17:54,419 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 08:17:54,422 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-26 08:17:54,422 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 08:17:55,715 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-08-26 08:17:55,715 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-26 08:17:55,798 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-26 08:17:55,799 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-26 08:17:55,819 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-26 08:17:55,824 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 08:17:55,824 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-26 08:27:52,885 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-26 09:30:47,672 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-26 09:30:47,681 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-26 09:30:47,683 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2020-08-26 09:30:47,784 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-26 09:30:47,787 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-26 09:30:47,789 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 09:30:47,790 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-26 09:30:47,793 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-26 09:30:47,794 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 09:30:47,795 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-26 09:30:47,795 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-26 09:30:47,796 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2020-08-26 09:30:47,800 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-26 09:30:47,800 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 09:30:47,803 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2020-08-26 09:30:47,807 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 09:30:47,807 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-26 09:30:47,808 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-26 09:30:47,808 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-26 09:30:47,809 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-26 09:30:47,810 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-26 09:30:47,811 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-26 09:30:47,811 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-26 09:30:47,811 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-26 09:30:47,811 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-26 09:30:47,813 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-26 09:30:47,813 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-26 09:30:47,813 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-26 09:30:47,815 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-26 09:30:47,815 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-26 09:31:34,203 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-26 09:31:34,220 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-26 09:31:34,610 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-26 09:31:34,792 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-26 09:31:34,928 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-26 09:31:35,079 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-26 09:31:35,144 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-26 09:31:35,153 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-26 09:31:35,159 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-26 09:31:35,195 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-26 09:31:35,198 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-26 09:31:35,198 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-26 09:31:35,219 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-26 09:31:35,220 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-26 09:31:35,221 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-26 09:31:35,222 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-26 09:31:35,301 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-26 09:31:35,397 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-26 09:31:35,397 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-26 09:31:35,414 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-26 09:31:35,421 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-26 09:31:35,424 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-26 09:31:35,426 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-26 09:31:35,427 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-26 09:31:35,429 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-26 09:31:35,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-26 09:31:35,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-26 09:31:35,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-08-26 09:31:35,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-26 09:31:35,503 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-26 09:31:35,503 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-26 09:31:35,505 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-26 09:31:35,505 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 09:31:35,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 09:31:35,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-26 09:31:35,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-26 09:31:35,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-26 09:31:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-26 09:31:35,521 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-26 09:31:35,537 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-26 09:31:35,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-26 09:31:35,538 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-26 09:31:35,538 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 09:31:35,539 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-26 09:31:35,539 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-26 09:31:35,542 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-26 09:31:35,543 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 09:31:35,543 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-26 09:31:35,543 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-26 09:31:35,547 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-26 09:31:35,584 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 09:31:35,601 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-26 09:31:35,782 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-26 09:31:35,783 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 09:31:35,784 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-26 09:31:35,810 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 09:31:35,818 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-26 09:31:35,834 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-26 09:31:35,838 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 09:31:35,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-26 09:31:35,884 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-26 09:31:35,884 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-26 09:31:35,890 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-26 09:31:35,891 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 09:31:35,894 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-26 09:31:35,919 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-26 09:31:36,082 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-26 09:31:36,091 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-26 09:31:36,098 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-26 09:31:36,109 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-26 09:31:36,112 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-26 09:31:36,112 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-26 09:31:36,112 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-26 09:31:36,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-26 09:31:36,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-26 09:31:36,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-26 09:31:36,121 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-26 09:31:36,121 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-26 09:31:36,502 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-26 09:31:36,505 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-26 09:31:36,505 INFO org.mortbay.log: jetty-6.1.26
2020-08-26 09:31:36,528 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-26 09:31:36,719 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 09:31:36,725 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-26 09:31:36,725 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-26 09:31:37,800 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-26 09:31:37,801 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-26 09:31:37,831 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-26 09:31:37,837 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-26 09:31:37,841 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-26 09:31:37,851 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-26 09:31:37,859 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-26 09:41:35,428 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-26 10:28:30,882 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-26 10:28:30,887 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-26 10:28:30,888 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-26 10:28:30,989 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-26 10:28:30,992 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 10:28:30,992 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-26 10:28:30,998 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-26 10:28:31,002 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-26 10:28:31,003 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-26 10:28:31,003 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 10:28:31,003 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-26 10:28:31,004 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-26 10:28:31,008 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-26 10:28:31,008 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 10:28:31,008 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-26 10:28:31,012 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-26 10:28:31,012 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-26 10:28:31,012 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-26 10:28:31,013 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-26 10:28:31,013 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-26 10:28:31,015 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-26 10:28:31,015 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-26 10:28:31,015 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-26 10:28:31,016 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-26 10:28:31,016 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-26 10:28:31,018 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-26 10:28:31,018 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-26 10:28:31,018 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-26 10:28:31,019 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-26 10:28:31,019 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 03:09:26,527 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 03:09:26,541 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 03:09:26,948 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 03:09:27,124 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 03:09:27,257 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 03:09:27,396 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 03:09:27,457 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 03:09:27,461 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 03:09:27,467 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 03:09:27,503 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 03:09:27,507 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 03:09:27,507 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 03:09:27,528 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 03:09:27,529 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 03:09:27,530 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 03:09:27,532 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 03:09:27,607 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 03:09:27,720 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 03:09:27,720 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 03:09:27,735 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 03:09:27,742 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 03:09:27,745 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 03:09:27,747 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 03:09:27,748 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 03:09:27,749 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 03:09:27,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 03:09:27,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 03:09:27,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 03:09:27,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 03:09:27,823 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 03:09:27,823 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 03:09:27,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 03:09:27,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 03:09:27,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 03:09:27,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 03:09:27,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 03:09:27,826 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 03:09:27,841 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 03:09:27,846 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 03:09:27,867 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 03:09:27,868 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 03:09:27,868 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 03:09:27,868 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 03:09:27,869 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 03:09:27,869 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 03:09:27,873 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 03:09:27,874 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 03:09:27,874 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 03:09:27,874 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 03:09:27,875 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 03:09:27,911 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 03:09:27,929 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 03:09:28,109 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 03:09:28,109 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 03:09:28,111 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 03:09:28,137 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 03:09:28,143 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 03:09:28,156 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 03:09:28,157 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 03:09:28,157 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 03:09:28,219 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 03:09:28,220 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 03:09:28,225 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 03:09:28,226 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 03:09:28,227 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 03:09:28,250 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 03:09:28,387 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 03:09:28,397 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 03:09:28,404 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 03:09:28,416 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 03:09:28,419 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 03:09:28,419 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 03:09:28,420 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 03:09:28,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 03:09:28,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 03:09:28,421 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 03:09:28,425 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 03:09:28,425 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 03:09:28,786 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 03:09:28,788 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 03:09:28,788 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 03:09:28,814 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 03:09:29,021 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 03:09:29,022 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 03:09:29,022 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 03:09:29,993 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 03:09:29,993 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 03:09:30,021 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 03:09:30,022 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 03:09:30,026 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 03:09:30,027 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 03:09:30,027 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 03:12:06,992 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 03:12:06,996 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 03:12:06,997 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 03:12:07,098 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 03:12:07,102 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 03:12:07,102 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 03:12:07,103 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 03:12:07,103 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 03:12:07,106 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 03:12:07,106 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 03:12:07,106 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 03:12:07,107 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 03:12:07,111 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 03:12:07,111 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 03:12:07,111 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 03:12:07,115 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 03:12:07,116 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 03:12:07,116 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 03:12:07,116 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 03:12:07,116 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 03:12:07,117 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 03:12:07,117 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 03:12:07,117 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 03:12:07,117 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 03:12:07,117 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 03:12:07,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 03:12:07,118 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 03:12:07,118 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 03:12:07,120 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 03:12:07,120 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 04:23:23,392 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 04:23:23,406 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 04:23:23,798 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 04:23:24,002 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 04:23:24,113 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 04:23:24,273 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 04:23:24,333 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 04:23:24,337 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 04:23:24,342 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 04:23:24,378 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 04:23:24,380 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 04:23:24,380 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 04:23:24,400 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 04:23:24,401 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 04:23:24,402 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 04:23:24,403 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 04:23:24,471 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 04:23:24,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 04:23:24,571 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 04:23:24,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 04:23:24,594 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 04:23:24,596 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 04:23:24,598 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 04:23:24,599 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 04:23:24,601 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 04:23:24,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 04:23:24,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 04:23:24,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 04:23:24,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 04:23:24,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 04:23:24,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 04:23:24,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 04:23:24,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:23:24,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:23:24,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:23:24,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 04:23:24,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 04:23:24,711 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 04:23:24,711 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 04:23:24,733 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 04:23:24,733 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 04:23:24,733 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 04:23:24,734 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:23:24,734 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 04:23:24,734 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 04:23:24,738 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 04:23:24,738 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:23:24,738 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 04:23:24,738 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 04:23:24,742 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 04:23:24,778 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:23:24,797 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 04:23:24,996 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 04:23:24,998 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:23:24,999 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 04:23:25,033 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:23:25,038 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 04:23:25,051 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 04:23:25,052 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:23:25,052 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 04:23:25,101 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:23:25,108 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 04:23:25,109 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 04:23:25,110 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:23:25,111 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 04:23:25,151 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 04:23:25,297 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 04:23:25,304 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 04:23:25,313 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 04:23:25,321 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 04:23:25,324 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 04:23:25,325 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 04:23:25,325 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 04:23:25,325 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 04:23:25,325 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 04:23:25,325 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 04:23:25,329 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 04:23:25,329 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 04:23:25,671 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 04:23:25,674 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 04:23:25,674 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 04:23:25,707 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 04:23:25,915 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:23:25,916 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 04:23:25,916 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:23:27,059 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 04:23:27,059 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 04:23:27,092 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 04:23:27,093 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 04:23:27,097 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 04:23:27,097 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:23:27,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 04:33:24,601 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-27 04:54:18,561 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 04:54:18,572 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 04:54:18,579 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 04:54:18,681 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 04:54:18,683 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 04:54:18,683 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 04:54:18,683 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 04:54:18,689 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 04:54:18,690 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 04:54:18,690 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 04:54:18,691 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 04:54:18,691 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 04:54:18,694 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 04:54:18,694 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 04:54:18,695 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 04:54:18,696 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 04:54:18,696 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 04:54:18,696 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 04:54:18,699 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 04:54:18,700 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 04:54:18,702 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 04:54:18,702 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 04:54:18,702 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 04:54:18,702 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 04:54:18,704 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 04:54:18,706 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 04:54:18,706 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 04:54:18,706 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 04:54:18,708 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 04:54:18,708 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 04:55:29,233 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 04:55:29,247 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 04:55:29,627 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 04:55:29,794 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 04:55:29,881 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 04:55:30,074 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 04:55:30,143 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 04:55:30,147 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 04:55:30,153 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 04:55:30,188 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 04:55:30,190 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 04:55:30,191 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 04:55:30,213 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 04:55:30,214 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 04:55:30,215 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 04:55:30,217 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 04:55:30,293 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 04:55:30,400 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 04:55:30,400 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 04:55:30,415 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 04:55:30,423 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 04:55:30,425 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 04:55:30,427 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 04:55:30,428 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 04:55:30,430 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 04:55:30,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 04:55:30,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 04:55:30,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 04:55:30,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 04:55:30,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 04:55:30,506 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 04:55:30,507 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 04:55:30,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:55:30,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:55:30,508 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 04:55:30,509 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 04:55:30,509 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 04:55:30,529 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 04:55:30,529 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 04:55:30,543 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 04:55:30,543 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 04:55:30,544 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 04:55:30,544 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:55:30,545 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 04:55:30,545 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 04:55:30,547 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 04:55:30,547 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:55:30,548 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 04:55:30,548 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 04:55:30,549 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 04:55:30,576 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:55:30,594 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 04:55:30,768 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 04:55:30,768 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:55:30,770 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 04:55:30,794 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:55:30,800 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 04:55:30,813 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 04:55:30,813 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:55:30,813 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 04:55:30,867 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 04:55:30,868 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 04:55:30,875 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 04:55:30,876 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:55:30,876 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 04:55:30,904 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 04:55:31,034 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 04:55:31,044 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 04:55:31,051 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 04:55:31,062 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 04:55:31,066 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 04:55:31,066 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 04:55:31,066 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 04:55:31,066 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 04:55:31,066 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 04:55:31,067 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 04:55:31,070 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 04:55:31,071 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 04:55:31,441 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 04:55:31,448 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 04:55:31,448 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 04:55:31,480 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 04:55:31,675 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:55:31,680 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 04:55:31,680 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 04:55:32,691 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 04:55:32,691 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 04:55:32,721 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 04:55:32,722 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 04:55:32,726 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 04:55:32,729 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 04:55:32,730 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 05:05:30,431 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-27 05:58:39,709 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 05:58:39,724 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 05:58:39,726 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 05:58:39,827 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 05:58:39,834 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 05:58:39,834 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 05:58:39,834 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 05:58:39,835 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 05:58:39,835 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 05:58:39,836 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 05:58:39,837 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 05:58:39,837 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 05:58:39,843 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 05:58:39,843 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 05:58:39,844 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 05:58:39,851 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 05:58:39,851 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 05:58:39,852 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 05:58:39,852 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 05:58:39,852 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 05:58:39,854 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 05:58:39,854 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 05:58:39,854 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 05:58:39,854 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 05:58:39,854 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 05:58:39,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 05:58:39,856 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 05:58:39,856 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 05:58:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 05:58:39,862 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 05:59:37,642 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 05:59:37,654 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 05:59:38,026 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 05:59:38,180 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 05:59:38,258 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 05:59:38,415 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 05:59:38,517 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 05:59:38,520 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 05:59:38,526 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 05:59:38,559 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 05:59:38,561 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 05:59:38,561 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 05:59:38,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 05:59:38,588 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 05:59:38,589 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 05:59:38,590 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 05:59:38,668 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 05:59:38,779 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 05:59:38,779 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 05:59:38,797 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 05:59:38,804 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 05:59:38,808 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 05:59:38,811 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 05:59:38,812 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 05:59:38,815 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 05:59:38,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 05:59:38,887 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 05:59:38,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 05:59:38,891 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 05:59:38,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 05:59:38,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 05:59:38,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 05:59:38,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 05:59:38,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 05:59:38,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 05:59:38,904 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 05:59:38,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 05:59:38,918 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 05:59:38,918 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 05:59:38,934 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 05:59:38,934 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 05:59:38,934 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 05:59:38,934 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 05:59:38,935 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 05:59:38,935 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 05:59:38,939 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 05:59:38,939 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 05:59:38,939 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 05:59:38,939 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 05:59:38,941 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 05:59:38,970 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 05:59:38,983 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 05:59:39,156 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 05:59:39,156 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 05:59:39,158 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 05:59:39,186 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 05:59:39,193 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 05:59:39,206 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 05:59:39,206 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 05:59:39,206 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 05:59:39,294 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 05:59:39,296 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 05:59:39,302 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 05:59:39,308 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 05:59:39,308 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 05:59:39,341 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 05:59:39,520 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 05:59:39,529 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 05:59:39,537 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 05:59:39,548 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 05:59:39,551 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 05:59:39,551 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 05:59:39,551 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 05:59:39,552 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 05:59:39,552 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 05:59:39,552 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 05:59:39,556 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 05:59:39,556 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 05:59:39,902 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 05:59:39,904 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 05:59:39,904 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 05:59:39,938 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 05:59:40,133 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 05:59:40,141 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 05:59:40,141 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 05:59:41,213 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 05:59:41,213 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 05:59:41,246 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 05:59:41,247 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 05:59:41,253 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 05:59:41,257 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 05:59:41,259 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 06:04:31,079 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 06:04:31,089 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:04:31,090 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 06:04:31,092 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 06:04:31,094 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 06:04:31,095 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 06:04:31,097 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:04:31,097 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 06:04:31,098 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:04:31,098 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 06:04:31,098 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 06:04:31,098 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 06:04:31,102 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 06:04:31,102 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:04:31,106 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 06:04:31,107 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 06:04:31,107 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:04:31,107 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 06:04:31,108 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 06:04:31,108 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:04:31,108 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:04:31,108 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 06:04:31,109 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:04:31,109 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:04:31,109 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 06:04:31,110 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 06:04:31,110 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 06:04:31,110 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:04:31,112 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 06:04:31,112 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 06:05:30,896 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 06:05:30,909 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 06:05:31,272 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 06:05:31,488 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 06:05:31,573 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 06:05:31,743 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 06:05:31,810 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 06:05:31,814 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 06:05:31,819 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 06:05:31,856 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 06:05:31,859 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 06:05:31,859 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 06:05:31,881 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 06:05:31,882 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 06:05:31,884 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 06:05:31,885 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 06:05:31,963 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 06:05:32,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 06:05:32,077 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 06:05:32,094 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 06:05:32,101 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 06:05:32,105 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 06:05:32,107 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 06:05:32,108 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 06:05:32,111 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 06:05:32,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 06:05:32,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 06:05:32,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 06:05:32,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 06:05:32,197 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 06:05:32,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 06:05:32,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 06:05:32,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:05:32,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:05:32,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:05:32,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 06:05:32,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 06:05:32,215 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 06:05:32,219 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 06:05:32,235 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 06:05:32,236 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 06:05:32,236 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 06:05:32,236 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:05:32,237 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 06:05:32,237 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 06:05:32,240 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 06:05:32,240 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:05:32,240 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 06:05:32,241 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 06:05:32,242 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 06:05:32,272 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:05:32,289 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 06:05:32,462 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 06:05:32,462 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:05:32,464 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 06:05:32,487 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:05:32,494 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 06:05:32,506 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 06:05:32,507 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:05:32,507 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 06:05:32,560 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:05:32,561 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 06:05:32,566 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 06:05:32,567 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:05:32,567 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 06:05:32,592 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 06:05:32,756 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 06:05:32,764 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 06:05:32,773 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 06:05:32,783 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 06:05:32,787 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 06:05:32,787 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 06:05:32,787 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 06:05:32,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 06:05:32,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 06:05:32,788 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 06:05:32,794 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 06:05:32,794 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 06:05:33,170 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 06:05:33,173 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 06:05:33,173 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 06:05:33,203 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 06:05:33,392 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:05:33,403 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 06:05:33,403 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:05:34,489 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 06:05:34,489 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 06:05:34,518 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 06:05:34,519 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 06:05:34,523 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 06:05:34,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:05:34,527 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 06:05:36,087 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:05:36,089 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 39289 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:39289
2020-08-27 06:05:36,097 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:39289 Node Transitioned from NEW to RUNNING
2020-08-27 06:05:36,102 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:39289 clusterResource: <memory:61440, vCores:12>
2020-08-27 06:05:36,307 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:05:36,307 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 45015 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:45015
2020-08-27 06:05:36,308 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:45015 Node Transitioned from NEW to RUNNING
2020-08-27 06:05:36,308 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:45015 clusterResource: <memory:122880, vCores:24>
2020-08-27 06:05:36,478 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:05:36,478 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 42881 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:42881
2020-08-27 06:05:36,478 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:42881 Node Transitioned from NEW to RUNNING
2020-08-27 06:05:36,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:42881 clusterResource: <memory:184320, vCores:36>
2020-08-27 06:15:32,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-27 06:16:09,584 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 06:16:09,595 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:16:09,596 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 06:16:09,596 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 06:16:09,599 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 06:16:09,601 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:16:09,600 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 06:16:09,606 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 06:16:09,609 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:16:09,609 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 06:16:09,609 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 06:16:09,610 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 06:16:09,612 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 06:16:09,613 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 06:16:09,613 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:16:09,617 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:16:09,617 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 06:16:09,617 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 06:16:09,617 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:16:09,618 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 06:16:09,618 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:16:09,618 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:16:09,618 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 06:16:09,618 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:16:09,619 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 06:16:09,623 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 06:16:09,623 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 06:16:09,623 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:16:09,625 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 06:16:09,625 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-27 06:47:29,656 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-27 06:47:29,669 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-27 06:47:30,077 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-27 06:47:30,233 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-27 06:47:30,311 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-27 06:47:30,454 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-27 06:47:30,549 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-27 06:47:30,553 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-27 06:47:30,558 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-27 06:47:30,596 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-27 06:47:30,598 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-27 06:47:30,598 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-27 06:47:30,632 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-27 06:47:30,633 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-27 06:47:30,634 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-27 06:47:30,635 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-27 06:47:30,713 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-27 06:47:30,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-27 06:47:30,814 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-27 06:47:30,830 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-27 06:47:30,837 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-27 06:47:30,842 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-27 06:47:30,845 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-27 06:47:30,846 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-27 06:47:30,850 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-27 06:47:30,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-27 06:47:30,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-27 06:47:30,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-27 06:47:30,949 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-27 06:47:30,960 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-27 06:47:30,960 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-27 06:47:30,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-27 06:47:30,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:47:30,961 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:47:30,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-27 06:47:30,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-27 06:47:30,962 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-27 06:47:30,992 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-27 06:47:30,992 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-27 06:47:31,008 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-27 06:47:31,008 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-27 06:47:31,008 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-27 06:47:31,008 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:47:31,009 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-27 06:47:31,009 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 06:47:31,019 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 06:47:31,019 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:47:31,019 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-27 06:47:31,019 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-27 06:47:31,032 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-27 06:47:31,077 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:47:31,096 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-27 06:47:31,297 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-27 06:47:31,297 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:47:31,299 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-27 06:47:31,327 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:47:31,335 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-27 06:47:31,351 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-27 06:47:31,356 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:47:31,358 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-27 06:47:31,416 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-27 06:47:31,417 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-27 06:47:31,424 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-27 06:47:31,425 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:47:31,425 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-27 06:47:31,460 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-27 06:47:31,604 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-27 06:47:31,613 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-27 06:47:31,620 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-27 06:47:31,629 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-27 06:47:31,633 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-27 06:47:31,633 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-27 06:47:31,633 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-27 06:47:31,633 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-27 06:47:31,633 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-27 06:47:31,634 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-27 06:47:31,637 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-27 06:47:31,638 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-27 06:47:31,966 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-27 06:47:31,969 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-27 06:47:31,969 INFO org.mortbay.log: jetty-6.1.26
2020-08-27 06:47:31,998 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-27 06:47:32,205 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:47:32,206 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-27 06:47:32,206 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-27 06:47:33,414 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 06:47:33,414 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-27 06:47:33,442 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-27 06:47:33,442 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-27 06:47:33,447 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-27 06:47:33,448 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-27 06:47:33,448 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-27 06:47:35,421 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:47:35,423 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 46404 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:46404
2020-08-27 06:47:35,427 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:46404 Node Transitioned from NEW to RUNNING
2020-08-27 06:47:35,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:46404 clusterResource: <memory:61440, vCores:12>
2020-08-27 06:47:35,713 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:47:35,713 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 43681 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:43681
2020-08-27 06:47:35,714 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:43681 Node Transitioned from NEW to RUNNING
2020-08-27 06:47:35,714 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:43681 clusterResource: <memory:122880, vCores:24>
2020-08-27 06:47:35,813 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-27 06:47:35,813 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 41789 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:41789
2020-08-27 06:47:35,813 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:41789 Node Transitioned from NEW to RUNNING
2020-08-27 06:47:35,814 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:41789 clusterResource: <memory:184320, vCores:36>
2020-08-27 06:48:12,757 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-27 06:48:12,765 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:48:12,768 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-27 06:48:12,869 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-27 06:48:12,876 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-27 06:48:12,876 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:48:12,877 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-27 06:48:12,879 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-27 06:48:12,879 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:48:12,879 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-27 06:48:12,880 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-27 06:48:12,880 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-27 06:48:12,888 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-27 06:48:12,888 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-27 06:48:12,888 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:48:12,892 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-27 06:48:12,893 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-27 06:48:12,894 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-27 06:48:12,894 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-27 06:48:12,894 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:48:12,901 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:48:12,901 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-27 06:48:12,901 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-27 06:48:12,902 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-27 06:48:12,902 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-27 06:48:12,906 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-27 06:48:12,906 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-27 06:48:12,906 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-27 06:48:12,906 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-27 06:48:12,907 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-31 05:21:52,038 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-31 05:21:52,052 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-31 05:21:52,428 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-31 05:21:52,601 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-31 05:21:52,690 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-31 05:21:52,845 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-31 05:21:52,952 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-31 05:21:52,957 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-31 05:21:52,962 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-31 05:21:53,001 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-31 05:21:53,004 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-31 05:21:53,004 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-31 05:21:53,034 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-31 05:21:53,035 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-31 05:21:53,036 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-31 05:21:53,037 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-31 05:21:53,113 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-31 05:21:53,219 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-31 05:21:53,219 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-31 05:21:53,233 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-31 05:21:53,241 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-31 05:21:53,243 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-31 05:21:53,246 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-31 05:21:53,246 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-31 05:21:53,248 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-31 05:21:53,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-31 05:21:53,307 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-31 05:21:53,313 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2020-08-31 05:21:53,313 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-31 05:21:53,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-31 05:21:53,324 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-31 05:21:53,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-31 05:21:53,325 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 05:21:53,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 05:21:53,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 05:21:53,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-31 05:21:53,327 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-31 05:21:53,342 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-31 05:21:53,342 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-31 05:21:53,360 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-31 05:21:53,360 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-31 05:21:53,360 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-31 05:21:53,360 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 05:21:53,362 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-31 05:21:53,362 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 05:21:53,366 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 05:21:53,366 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 05:21:53,366 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-31 05:21:53,366 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 05:21:53,371 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-31 05:21:53,411 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 05:21:53,426 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-31 05:21:53,618 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-31 05:21:53,619 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 05:21:53,620 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-31 05:21:53,651 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 05:21:53,658 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-31 05:21:53,672 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-31 05:21:53,673 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 05:21:53,673 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-31 05:21:53,737 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 05:21:53,740 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-31 05:21:53,747 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-31 05:21:53,747 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 05:21:53,747 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-31 05:21:53,778 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-31 05:21:53,921 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-31 05:21:53,929 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-31 05:21:53,936 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-31 05:21:53,946 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-31 05:21:53,949 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-31 05:21:53,949 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-31 05:21:53,950 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-31 05:21:53,950 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-31 05:21:53,950 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-31 05:21:53,950 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-31 05:21:53,954 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-31 05:21:53,954 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-31 05:21:54,344 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-31 05:21:54,346 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-31 05:21:54,347 INFO org.mortbay.log: jetty-6.1.26
2020-08-31 05:21:54,376 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-31 05:21:54,587 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 05:21:54,594 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 05:21:54,594 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 05:21:55,698 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 05:21:55,698 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-31 05:21:55,730 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-31 05:21:55,733 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-31 05:21:55,737 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-31 05:21:55,738 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 05:21:55,739 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-31 05:21:58,073 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-31 05:21:58,075 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 42748 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:42748
2020-08-31 05:21:58,076 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-31 05:21:58,076 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 41729 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:41729
2020-08-31 05:21:58,079 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:42748 Node Transitioned from NEW to RUNNING
2020-08-31 05:21:58,079 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:41729 Node Transitioned from NEW to RUNNING
2020-08-31 05:21:58,085 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:42748 clusterResource: <memory:61440, vCores:12>
2020-08-31 05:21:58,085 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:41729 clusterResource: <memory:122880, vCores:24>
2020-08-31 05:21:58,298 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-31 05:21:58,299 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 46369 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:46369
2020-08-31 05:21:58,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:46369 Node Transitioned from NEW to RUNNING
2020-08-31 05:21:58,299 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:46369 clusterResource: <memory:184320, vCores:36>
2020-08-31 05:31:53,249 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-31 06:10:15,747 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-08-31 06:10:30,924 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:10:30,926 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-08-31 06:10:30,930 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0001
2020-08-31 06:10:30,936 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0001
2020-08-31 06:10:30,953 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:10:30,961 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0001
2020-08-31 06:10:31,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:10:31,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:10:31,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0001 from user: jinhuijun, in queue: default
2020-08-31 06:10:31,032 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:10:31,076 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0001_000001
2020-08-31 06:10:31,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from NEW to SUBMITTED
2020-08-31 06:10:31,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0001 from user: jinhuijun activated in queue: default
2020-08-31 06:10:31,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1de169af, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:10:31,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0001_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:10:31,104 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:10:31,979 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:10:31,979 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000001
2020-08-31 06:10:31,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:10:31,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0001_000001 container=Container: [ContainerId: container_1598851313344_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:10:31,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:10:31,981 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:32,206 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0001_01_000001
2020-08-31 06:10:32,246 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:10:32,247 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0001_000001
2020-08-31 06:10:32,251 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0001 AttemptId: appattempt_1598851313344_0001_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 06:10:32,295 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:10:32,304 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:10:32,331 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0001_000001
2020-08-31 06:10:32,374 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0001_000001
2020-08-31 06:10:32,374 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:34259',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:10:32,377 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0001_000001
2020-08-31 06:10:32,380 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0001_000001
2020-08-31 06:10:32,775 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0001_000001
2020-08-31 06:10:32,777 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:10:33,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:10:41,546 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0001_000001 (auth:SIMPLE)
2020-08-31 06:10:41,570 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0001_000001
2020-08-31 06:10:41,571 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0001	APPATTEMPTID=appattempt_1598851313344_0001_000001
2020-08-31 06:10:41,574 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:10:41,574 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:10:42,042 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:10:42,042 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000002
2020-08-31 06:10:42,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:10:42,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0001_000001 container=Container: [ContainerId: container_1598851313344_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:10:42,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:10:42,044 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:42,171 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:10:42,171 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000003
2020-08-31 06:10:42,171 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:10:42,171 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0001_000001 container=Container: [ContainerId: container_1598851313344_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:10:42,172 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:10:42,172 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:42,398 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0001_01_000002
2020-08-31 06:10:42,406 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:10:42,407 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0001_01_000003
2020-08-31 06:10:42,413 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:10:43,053 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:10:43,173 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:10:45,497 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0001
2020-08-31 06:10:48,730 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0001_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:10:48,731 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:10:48,731 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0001 with final state: FINISHING
2020-08-31 06:10:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:10:48,732 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0001
2020-08-31 06:10:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:10:48,733 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:10:48,759 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:10:48,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0001_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:10:48,759 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000003
2020-08-31 06:10:48,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:10:48,760 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:10:48,760 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:10:48,760 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:48,761 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:10:48,761 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0001_000001 released container container_1598851313344_0001_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:10:48,853 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0001 unregistered successfully. 
2020-08-31 06:10:49,389 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0001_000001
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0001_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000001
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1536, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1536, vCores:1>
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.008333334 absoluteUsedCapacity=0.008333334 used=<memory:1536, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1
2020-08-31 06:10:49,390 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0001_000001 released container container_1598851313344_0001_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:10:49,391 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0001_000001
2020-08-31 06:10:49,392 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0001_000001 State change from FINISHING to FINISHED
2020-08-31 06:10:49,393 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:10:49,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0001_000001 is done. finalState=FINISHED
2020-08-31 06:10:49,394 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0001
2020-08-31 06:10:49,396 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0001_01_000002 Container Transitioned from RUNNING to KILLED
2020-08-31 06:10:49,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0001_01_000002 in state: KILLED event:KILL
2020-08-31 06:10:49,396 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0001	CONTAINERID=container_1598851313344_0001_01_000002
2020-08-31 06:10:49,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:10:49,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:10:49,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:10:49,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:10:49,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:10:49,402 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0001_000001 released container container_1598851313344_0001_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-08-31 06:10:49,403 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0001 requests cleared
2020-08-31 06:10:49,404 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:10:49,404 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:10:49,406 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0001_000001
2020-08-31 06:10:49,412 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0001/,appMasterHost=10.178.0.23,startTime=1598854230924,finishTime=1598854248731,finalStatus=SUCCEEDED,memorySeconds=39242,vcoreSeconds=30,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:10:50,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:10:51,399 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:20:13,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2020-08-31 06:20:24,865 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 2 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:20:24,866 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 2 submitted by user jinhuijun
2020-08-31 06:20:24,866 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0002
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0002
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0002
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0002 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:20:24,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0002 from user: jinhuijun, in queue: default
2020-08-31 06:20:24,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:20:24,874 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0002_000001
2020-08-31 06:20:24,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from NEW to SUBMITTED
2020-08-31 06:20:24,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0002 from user: jinhuijun activated in queue: default
2020-08-31 06:20:24,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0002 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@78d3a5f4, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:20:24,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0002_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:20:24,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:20:25,414 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:20:25,414 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000001
2020-08-31 06:20:25,414 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0002_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:20:25,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0002_000001 container=Container: [ContainerId: container_1598851313344_0002_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:20:25,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:20:25,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:25,417 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0002_01_000001
2020-08-31 06:20:25,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:20:25,419 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0002_000001
2020-08-31 06:20:25,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0002 AttemptId: appattempt_1598851313344_0002_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0002_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 06:20:25,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:20:25,419 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:20:25,420 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0002_000001
2020-08-31 06:20:25,424 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0002_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0002_000001
2020-08-31 06:20:25,424 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0002_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:33766',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:20:25,424 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0002_000001
2020-08-31 06:20:25,424 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0002_000001
2020-08-31 06:20:25,832 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0002_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0002_000001
2020-08-31 06:20:25,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:20:26,451 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:20:34,976 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0002_000001 (auth:SIMPLE)
2020-08-31 06:20:34,984 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0002_000001
2020-08-31 06:20:34,984 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0002	APPATTEMPTID=appattempt_1598851313344_0002_000001
2020-08-31 06:20:34,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:20:34,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000002
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0002_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0002_000001 container=Container: [ContainerId: container_1598851313344_0002_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:20:35,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:35,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:20:35,705 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000003
2020-08-31 06:20:35,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0002_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:20:35,705 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0002_000001 container=Container: [ContainerId: container_1598851313344_0002_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:20:35,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:20:35,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:35,823 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0002_01_000002
2020-08-31 06:20:35,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:20:35,829 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0002_01_000003
2020-08-31 06:20:35,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:20:36,591 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:20:36,707 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:20:38,916 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0002
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0002_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0002 with final state: FINISHING
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0002
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:20:44,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:20:44,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:20:44,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0002_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:20:44,555 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000003
2020-08-31 06:20:44,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0002_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:20:44,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:20:44,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0002_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:20:44,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:44,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:20:44,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0002_000001 released container container_1598851313344_0002_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:20:44,630 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:20:44,630 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0002_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:20:44,630 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000002
2020-08-31 06:20:44,630 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0002_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:20:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:20:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0002_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:20:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:20:44,631 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0002_000001 released container container_1598851313344_0002_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:20:44,638 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0002 unregistered successfully. 
2020-08-31 06:20:45,239 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0002_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:20:45,239 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0002_000001
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0002_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0002_000001
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0002	CONTAINERID=container_1598851313344_0002_01_000001
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0002_000001 State change from FINISHING to FINISHED
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0002_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0002 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0002
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0002_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0002_000001 released container container_1598851313344_0002_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0002_000001 is done. finalState=FINISHED
2020-08-31 06:20:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0002,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0002/,appMasterHost=10.178.0.22,startTime=1598854824865,finishTime=1598854844532,finalStatus=SUCCEEDED,memorySeconds=47779,vcoreSeconds=36,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:20:45,241 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0002_000001
2020-08-31 06:20:45,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0002 requests cleared
2020-08-31 06:20:45,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0002 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:20:45,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0002 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:20:46,557 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:20:47,259 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:24:45,306 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2020-08-31 06:24:56,155 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 3 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:24:56,155 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user jinhuijun
2020-08-31 06:24:56,155 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0003
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0003
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0003
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0003 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:24:56,156 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0003 from user: jinhuijun, in queue: default
2020-08-31 06:24:56,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:24:56,157 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,157 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from NEW to SUBMITTED
2020-08-31 06:24:56,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0003 from user: jinhuijun activated in queue: default
2020-08-31 06:24:56,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@22e8f948, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:24:56,158 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0003_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:24:56,159 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000001
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0003_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0003_000001 container=Container: [ContainerId: container_1598851313344_0003_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:24:56,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:24:56,321 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0003_01_000001
2020-08-31 06:24:56,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:24:56,325 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0003 AttemptId: appattempt_1598851313344_0003_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0003_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 06:24:56,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:24:56,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:24:56,336 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0003_000001
2020-08-31 06:24:56,354 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0003_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,354 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0003_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:36457',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:24:56,354 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,354 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,421 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0003_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0003_000001
2020-08-31 06:24:56,421 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:24:57,344 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:25:03,361 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0003_000001 (auth:SIMPLE)
2020-08-31 06:25:03,373 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0003_000001
2020-08-31 06:25:03,373 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0003	APPATTEMPTID=appattempt_1598851313344_0003_000001
2020-08-31 06:25:03,374 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:25:03,374 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000002
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0003_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0003_000001 container=Container: [ContainerId: container_1598851313344_0003_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:25:03,777 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:03,913 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0003_01_000002
2020-08-31 06:25:03,928 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:25:04,362 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:25:04,362 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000003
2020-08-31 06:25:04,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0003_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:25:04,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0003_000001 container=Container: [ContainerId: container_1598851313344_0003_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:25:04,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:25:04,363 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:04,408 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0003_01_000003
2020-08-31 06:25:04,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:25:04,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:25:04,437 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000004
2020-08-31 06:25:04,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0003_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:25:04,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0003_000001 container=Container: [ContainerId: container_1598851313344_0003_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:25:04,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 06:25:04,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:04,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:25:05,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:25:07,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0003
2020-08-31 06:25:07,426 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0003_01_000004
2020-08-31 06:25:07,427 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:25:10,433 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 06:25:10,433 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0003_01_000004 in state: RELEASED event:RELEASED
2020-08-31 06:25:10,433 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000004
2020-08-31 06:25:10,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0003_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:25:10,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 06:25:10,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0003_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 06:25:10,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:10,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:25:10,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0003_000001 released container container_1598851313344_0003_01_000004 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: RELEASED
2020-08-31 06:25:16,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0003_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0003 with final state: FINISHING
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0003
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:25:16,087 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:25:16,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0003_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000003
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0003_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0003_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:25:16,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0003_000001 released container container_1598851313344_0003_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:25:16,190 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0003 unregistered successfully. 
2020-08-31 06:25:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:25:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0003_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:25:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000002
2020-08-31 06:25:16,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0003_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:25:16,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:25:16,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0003_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:25:16,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0003_000001 released container container_1598851313344_0003_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:25:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:25:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0003_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:25:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0003	CONTAINERID=container_1598851313344_0003_01_000001
2020-08-31 06:25:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0003_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:25:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0003_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0003_000001 released container container_1598851313344_0003_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0003_000001
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0003_000001
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0003_000001 State change from FINISHING to FINISHED
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0003 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:25:16,674 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0003
2020-08-31 06:25:16,675 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0003,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0003/,appMasterHost=10.178.0.22,startTime=1598855096155,finishTime=1598855116087,finalStatus=SUCCEEDED,memorySeconds=67192,vcoreSeconds=48,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:25:16,679 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0003_000001 is done. finalState=FINISHED
2020-08-31 06:25:16,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0003 requests cleared
2020-08-31 06:25:16,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0003 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:25:16,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0003 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:25:16,683 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0003_000001
2020-08-31 06:25:18,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:25:18,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:31:24,046 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2020-08-31 06:31:34,922 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 4 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:31:34,922 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user jinhuijun
2020-08-31 06:31:34,923 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0004
2020-08-31 06:31:34,923 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0004
2020-08-31 06:31:34,923 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:31:34,942 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0004
2020-08-31 06:31:34,944 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:31:34,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0004 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:31:34,945 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0004 from user: jinhuijun, in queue: default
2020-08-31 06:31:34,945 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:31:34,946 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0004_000001
2020-08-31 06:31:34,946 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from NEW to SUBMITTED
2020-08-31 06:31:34,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0004 from user: jinhuijun activated in queue: default
2020-08-31 06:31:34,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7ab60211, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:31:34,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0004_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:31:34,959 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:31:35,120 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:31:35,120 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000001
2020-08-31 06:31:35,120 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0004_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:31:35,120 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0004_000001 container=Container: [ContainerId: container_1598851313344_0004_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:31:35,121 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:31:35,121 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:35,128 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0004_01_000001
2020-08-31 06:31:35,129 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:31:35,129 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0004_000001
2020-08-31 06:31:35,130 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0004 AttemptId: appattempt_1598851313344_0004_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0004_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 06:31:35,130 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:31:35,132 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:31:35,132 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0004_000001
2020-08-31 06:31:35,136 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0004_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0004_000001
2020-08-31 06:31:35,136 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0004_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:36285',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:31:35,136 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0004_000001
2020-08-31 06:31:35,136 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0004_000001
2020-08-31 06:31:35,150 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0004_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0004_000001
2020-08-31 06:31:35,151 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:31:36,122 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:31:41,783 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0004_000001 (auth:SIMPLE)
2020-08-31 06:31:41,796 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0004_000001
2020-08-31 06:31:41,796 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0004	APPATTEMPTID=appattempt_1598851313344_0004_000001
2020-08-31 06:31:41,797 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:31:41,797 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:31:42,244 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:31:42,244 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000002
2020-08-31 06:31:42,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0004_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:31:42,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0004_000001 container=Container: [ContainerId: container_1598851313344_0004_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:31:42,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:31:42,245 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:42,297 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:31:42,297 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000003
2020-08-31 06:31:42,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0004_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:31:42,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0004_000001 container=Container: [ContainerId: container_1598851313344_0004_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:31:42,298 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:31:42,298 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:42,602 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0004_01_000002
2020-08-31 06:31:42,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:31:42,610 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0004_01_000003
2020-08-31 06:31:42,624 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:31:43,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:31:43,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:31:45,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0004
2020-08-31 06:31:56,605 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0004_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0004 with final state: FINISHING
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0004
2020-08-31 06:31:56,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:31:56,680 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:31:56,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0004_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:31:56,680 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000002
2020-08-31 06:31:56,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0004_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:31:56,680 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:31:56,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0004_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:31:56,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:56,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:31:56,682 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0004_000001 released container container_1598851313344_0004_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:31:56,793 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:31:56,794 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0004_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:31:56,794 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000003
2020-08-31 06:31:56,794 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0004_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:31:56,794 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:31:56,795 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0004_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:31:56,795 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:56,795 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:31:56,795 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0004_000001 released container container_1598851313344_0004_01_000003 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:31:56,825 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0004 unregistered successfully. 
2020-08-31 06:31:57,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:31:57,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0004_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:31:57,231 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0004_000001
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0004_000001
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0004	CONTAINERID=container_1598851313344_0004_01_000001
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0004_000001 State change from FINISHING to FINISHED
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0004_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0004 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0004
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0004,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0004/,appMasterHost=10.178.0.23,startTime=1598855494922,finishTime=1598855516606,finalStatus=SUCCEEDED,memorySeconds=67079,vcoreSeconds=50,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:31:57,232 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0004_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:31:57,233 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:31:57,233 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:31:57,233 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0004_000001 released container container_1598851313344_0004_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:31:57,233 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0004_000001 is done. finalState=FINISHED
2020-08-31 06:31:57,233 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0004_000001
2020-08-31 06:31:57,234 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0004 requests cleared
2020-08-31 06:31:57,237 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0004 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:31:57,237 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0004 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:31:58,803 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:31:59,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:35:53,503 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2020-08-31 06:36:05,345 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 5 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:36:05,346 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user jinhuijun
2020-08-31 06:36:05,346 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0005
2020-08-31 06:36:05,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0005
2020-08-31 06:36:05,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:36:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0005
2020-08-31 06:36:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:36:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0005 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:36:05,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0005 from user: jinhuijun, in queue: default
2020-08-31 06:36:05,357 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:36:05,357 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,357 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from NEW to SUBMITTED
2020-08-31 06:36:05,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0005 from user: jinhuijun activated in queue: default
2020-08-31 06:36:05,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@f3cd4c7, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:36:05,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0005_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:36:05,374 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:36:05,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:36:05,546 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000001
2020-08-31 06:36:05,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0005_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:36:05,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0005_000001 container=Container: [ContainerId: container_1598851313344_0005_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:36:05,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:36:05,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:05,548 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0005_01_000001
2020-08-31 06:36:05,550 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:36:05,550 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,550 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0005 AttemptId: appattempt_1598851313344_0005_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0005_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 06:36:05,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:36:05,551 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:36:05,553 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0005_000001
2020-08-31 06:36:05,576 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0005_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,576 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0005_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:32944',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:36:05,576 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,576 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,679 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0005_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0005_000001
2020-08-31 06:36:05,679 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:36:06,560 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:36:17,779 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0005_000001 (auth:SIMPLE)
2020-08-31 06:36:17,785 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0005_000001
2020-08-31 06:36:17,785 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0005	APPATTEMPTID=appattempt_1598851313344_0005_000001
2020-08-31 06:36:17,785 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:36:17,785 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:36:17,993 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:36:17,994 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000002
2020-08-31 06:36:17,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0005_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:36:17,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0005_000001 container=Container: [ContainerId: container_1598851313344_0005_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:36:17,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:36:17,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:18,054 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0005_01_000002
2020-08-31 06:36:18,056 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:36:18,627 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:36:18,627 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000003
2020-08-31 06:36:18,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0005_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:36:18,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0005_000001 container=Container: [ContainerId: container_1598851313344_0005_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:36:18,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:36:18,628 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:18,708 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0005_01_000003
2020-08-31 06:36:18,712 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:36:19,004 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:36:19,628 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:36:21,772 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0005
2020-08-31 06:36:27,111 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0005_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0005 with final state: FINISHING
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0005
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:36:27,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:36:27,117 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:36:27,117 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0005_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:36:27,117 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000002
2020-08-31 06:36:27,118 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0005_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:36:27,118 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:36:27,118 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0005_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,119 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,119 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:36:27,119 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0005_000001 released container container_1598851313344_0005_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:36:27,126 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:36:27,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0005_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:36:27,126 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000003
2020-08-31 06:36:27,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0005_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:36:27,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:36:27,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0005_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:36:27,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0005_000001 released container container_1598851313344_0005_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:36:27,225 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0005 unregistered successfully. 
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0005_000001
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0005_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0005_000001
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0005	CONTAINERID=container_1598851313344_0005_01_000001
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0005_000001 State change from FINISHING to FINISHED
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0005_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0005 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:36:27,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0005
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0005_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0005_000001 released container container_1598851313344_0005_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0005,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0005/,appMasterHost=10.178.0.24,startTime=1598855765345,finishTime=1598855787112,finalStatus=SUCCEEDED,memorySeconds=49779,vcoreSeconds=39,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:36:27,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0005_000001 is done. finalState=FINISHED
2020-08-31 06:36:27,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0005 requests cleared
2020-08-31 06:36:27,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0005 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:36:27,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0005 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:36:27,730 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0005_000001
2020-08-31 06:36:29,119 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:36:29,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:45:12,220 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 6
2020-08-31 06:45:18,815 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 6 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:45:18,816 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 6 submitted by user jinhuijun
2020-08-31 06:45:18,816 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0006
2020-08-31 06:45:18,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0006
2020-08-31 06:45:18,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:45:18,823 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0006
2020-08-31 06:45:18,828 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:45:18,829 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0006 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0006 from user: jinhuijun, in queue: default
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from NEW to SUBMITTED
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0006 from user: jinhuijun activated in queue: default
2020-08-31 06:45:18,830 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0006 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@450e8713, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:45:18,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0006_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:45:18,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000001
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0006_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0006_000001 container=Container: [ContainerId: container_1598851313344_0006_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:45:18,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:18,864 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0006_01_000001
2020-08-31 06:45:18,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:45:18,865 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0006 AttemptId: appattempt_1598851313344_0006_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0006_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 06:45:18,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:45:18,865 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:45:18,866 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0006_000001
2020-08-31 06:45:18,869 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0006_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,869 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0006_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:45895',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:45:18,869 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,869 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,883 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0006_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0006_000001
2020-08-31 06:45:18,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:45:19,862 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:45:24,314 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0006_000001 (auth:SIMPLE)
2020-08-31 06:45:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0006_000001
2020-08-31 06:45:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0006	APPATTEMPTID=appattempt_1598851313344_0006_000001
2020-08-31 06:45:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:45:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:45:24,510 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:45:24,510 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000002
2020-08-31 06:45:24,510 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0006_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:45:24,511 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0006_000001 container=Container: [ContainerId: container_1598851313344_0006_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:45:24,511 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:45:24,511 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000003
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0006_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0006_000001 container=Container: [ContainerId: container_1598851313344_0006_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:45:24,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:24,661 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0006_01_000002
2020-08-31 06:45:24,662 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:45:24,662 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0006_01_000003
2020-08-31 06:45:24,663 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:45:25,512 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:45:25,557 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:45:27,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0006
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0006_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0006 with final state: FINISHING
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0006
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:45:30,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:45:30,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:45:30,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0006_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:45:30,141 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000003
2020-08-31 06:45:30,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0006_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:45:30,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:45:30,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0006_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:45:30,142 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0006_000001 released container container_1598851313344_0006_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:45:30,209 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0006 unregistered successfully. 
2020-08-31 06:45:30,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:45:30,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0006_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:45:30,435 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000002
2020-08-31 06:45:30,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0006_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:45:30,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:45:30,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0006_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:45:30,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0006_000001 released container container_1598851313344_0006_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:45:30,580 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0006_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:45:30,580 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0006_000001
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0006_000001
2020-08-31 06:45:30,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0006_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0006_000001 State change from FINISHING to FINISHED
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0006	CONTAINERID=container_1598851313344_0006_01_000001
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0006 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0006_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0006
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0006_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0006_000001 released container container_1598851313344_0006_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0006,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0006/,appMasterHost=10.178.0.24,startTime=1598856318815,finishTime=1598856330106,finalStatus=SUCCEEDED,memorySeconds=29699,vcoreSeconds=21,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:45:30,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0006_000001 is done. finalState=FINISHED
2020-08-31 06:45:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0006 requests cleared
2020-08-31 06:45:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0006 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:45:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0006 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:45:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0006_000001
2020-08-31 06:45:32,143 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:45:32,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:46:01,112 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 7
2020-08-31 06:46:07,538 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 7 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 7 submitted by user jinhuijun
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0007
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0007
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0007
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0007 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:46:07,539 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0007 from user: jinhuijun, in queue: default
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from NEW to SUBMITTED
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0007 from user: jinhuijun activated in queue: default
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0007 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@2cfde999, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:46:07,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0007_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:46:07,541 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000001
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0007_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0007_000001 container=Container: [ContainerId: container_1598851313344_0007_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:46:07,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:07,557 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0007_01_000001
2020-08-31 06:46:07,561 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:07,561 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,561 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0007 AttemptId: appattempt_1598851313344_0007_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0007_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 06:46:07,561 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:46:07,570 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:46:07,571 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0007_000001
2020-08-31 06:46:07,581 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0007_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,581 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0007_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:42908',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:46:07,581 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,581 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,616 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0007_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0007_000001
2020-08-31 06:46:07,616 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:46:08,566 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:12,908 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0007_000001 (auth:SIMPLE)
2020-08-31 06:46:12,914 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0007_000001
2020-08-31 06:46:12,914 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0007	APPATTEMPTID=appattempt_1598851313344_0007_000001
2020-08-31 06:46:12,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:46:12,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:46:13,275 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:13,275 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000002
2020-08-31 06:46:13,275 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0007_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:46:13,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0007_000001 container=Container: [ContainerId: container_1598851313344_0007_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:13,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:46:13,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000003
2020-08-31 06:46:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0007_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:46:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0007_000001 container=Container: [ContainerId: container_1598851313344_0007_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:46:13,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:13,669 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0007_01_000002
2020-08-31 06:46:13,674 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:13,675 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0007_01_000003
2020-08-31 06:46:13,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:14,277 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:14,610 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:16,759 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0007
2020-08-31 06:46:18,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0007_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:46:18,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:46:18,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0007 with final state: FINISHING
2020-08-31 06:46:18,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:46:18,969 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0007
2020-08-31 06:46:18,969 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:46:18,969 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:46:19,115 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:19,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0007_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:46:19,115 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000003
2020-08-31 06:46:19,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0007_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:46:19,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:46:19,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0007_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:46:19,116 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0007_000001 released container container_1598851313344_0007_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:46:19,213 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0007 unregistered successfully. 
2020-08-31 06:46:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0007_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:46:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000002
2020-08-31 06:46:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0007_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:46:19,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:46:19,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0007_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:46:19,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0007_000001 released container container_1598851313344_0007_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:46:19,595 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0007_000001
2020-08-31 06:46:19,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0007_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0007_000001
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0007_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0007	CONTAINERID=container_1598851313344_0007_01_000001
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0007_000001 State change from FINISHING to FINISHED
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0007 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0007_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:46:19,596 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0007
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0007_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0007,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0007/,appMasterHost=10.178.0.23,startTime=1598856367538,finishTime=1598856378968,finalStatus=SUCCEEDED,memorySeconds=30060,vcoreSeconds=23,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0007_000001 released container container_1598851313344_0007_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:46:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0007_000001 is done. finalState=FINISHED
2020-08-31 06:46:19,598 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0007 requests cleared
2020-08-31 06:46:19,598 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0007 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:46:19,598 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0007 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:46:19,599 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0007_000001
2020-08-31 06:46:21,316 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:46:21,598 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:46:32,373 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 8
2020-08-31 06:46:39,029 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 8 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:46:39,029 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 8 submitted by user jinhuijun
2020-08-31 06:46:39,029 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0008
2020-08-31 06:46:39,029 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0008
2020-08-31 06:46:39,030 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:46:39,030 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0008
2020-08-31 06:46:39,030 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:46:39,036 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0008 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:46:39,036 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0008 from user: jinhuijun, in queue: default
2020-08-31 06:46:39,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:46:39,037 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from NEW to SUBMITTED
2020-08-31 06:46:39,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0008 from user: jinhuijun activated in queue: default
2020-08-31 06:46:39,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0008 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@6f7d8b63, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:46:39,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0008_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:46:39,049 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:46:39,377 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:39,377 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000001
2020-08-31 06:46:39,377 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0008_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:46:39,377 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0008_000001 container=Container: [ContainerId: container_1598851313344_0008_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:39,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:46:39,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:39,379 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0008_01_000001
2020-08-31 06:46:39,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:39,381 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0008 AttemptId: appattempt_1598851313344_0008_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0008_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 06:46:39,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:46:39,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:46:39,382 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0008_000001
2020-08-31 06:46:39,384 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0008_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,384 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0008_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:44127',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:46:39,384 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,384 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,398 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0008_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0008_000001
2020-08-31 06:46:39,399 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:46:40,385 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:44,868 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0008_000001 (auth:SIMPLE)
2020-08-31 06:46:44,873 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0008_000001
2020-08-31 06:46:44,873 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0008	APPATTEMPTID=appattempt_1598851313344_0008_000001
2020-08-31 06:46:44,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:46:44,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:46:45,420 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:45,420 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000002
2020-08-31 06:46:45,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0008_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:46:45,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0008_000001 container=Container: [ContainerId: container_1598851313344_0008_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:45,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:46:45,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:45,639 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0008_01_000002
2020-08-31 06:46:45,641 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000003
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0008_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0008_000001 container=Container: [ContainerId: container_1598851313344_0008_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:46:45,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:46,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:46,519 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0008_01_000003
2020-08-31 06:46:46,521 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:46,692 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000004
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0008_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:3072, vCores:2> used and <memory:58368, vCores:10> available after allocation
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0008_000001 container=Container: [ContainerId: container_1598851313344_0008_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 06:46:46,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:49,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0008
2020-08-31 06:46:49,610 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:46:51,318 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 06:46:51,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0008_01_000004 in state: RELEASED event:RELEASED
2020-08-31 06:46:51,318 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000004
2020-08-31 06:46:51,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0008_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available, release resources=true
2020-08-31 06:46:51,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 06:46:51,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0008_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:46:51,320 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0008_000001 released container container_1598851313344_0008_01_000004 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:59904, vCores:11> used=<memory:1536, vCores:1> with event: RELEASED
2020-08-31 06:46:51,378 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0008_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:46:51,379 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:46:51,379 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0008 with final state: FINISHING
2020-08-31 06:46:51,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:46:51,380 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0008
2020-08-31 06:46:51,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:46:51,380 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:46:51,386 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0008_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000002
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0008_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0008_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,387 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,388 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:46:51,388 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0008_000001 released container container_1598851313344_0008_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:46:51,483 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0008 unregistered successfully. 
2020-08-31 06:46:51,569 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:51,569 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0008_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:46:51,569 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000003
2020-08-31 06:46:51,569 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0008_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:46:51,569 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:46:51,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0008_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:46:51,570 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0008_000001 released container container_1598851313344_0008_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:46:51,938 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0008_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:46:51,938 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0008_000001
2020-08-31 06:46:51,938 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0008_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0008_000001
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0008	CONTAINERID=container_1598851313344_0008_01_000001
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0008_000001 State change from FINISHING to FINISHED
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0008_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0008 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0008
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0008_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0008_000001 released container container_1598851313344_0008_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0008,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0008/,appMasterHost=10.178.0.22,startTime=1598856399029,finishTime=1598856411379,finalStatus=SUCCEEDED,memorySeconds=38172,vcoreSeconds=26,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:46:51,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0008_000001 is done. finalState=FINISHED
2020-08-31 06:46:51,940 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0008 requests cleared
2020-08-31 06:46:51,940 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0008 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:46:51,940 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0008 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:46:51,941 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0008_000001
2020-08-31 06:46:53,572 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:46:53,941 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:48:05,543 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 9
2020-08-31 06:48:11,872 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 9 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:48:11,872 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 9 submitted by user jinhuijun
2020-08-31 06:48:11,872 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0009
2020-08-31 06:48:11,872 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0009
2020-08-31 06:48:11,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:48:11,873 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0009
2020-08-31 06:48:11,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:48:11,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0009 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:48:11,873 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0009 from user: jinhuijun, in queue: default
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0009_000001
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from NEW to SUBMITTED
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0009 from user: jinhuijun activated in queue: default
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0009 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@75562d62, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:48:11,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0009_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:48:11,875 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:48:12,012 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:48:12,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000001
2020-08-31 06:48:12,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0009_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:48:12,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0009_000001 container=Container: [ContainerId: container_1598851313344_0009_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:48:12,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:48:12,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:12,013 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0009_01_000001
2020-08-31 06:48:12,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:48:12,016 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0009_000001
2020-08-31 06:48:12,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0009 AttemptId: appattempt_1598851313344_0009_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0009_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 06:48:12,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:48:12,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:48:12,017 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0009_000001
2020-08-31 06:48:12,020 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0009_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0009_000001
2020-08-31 06:48:12,020 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0009_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:43288',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:48:12,020 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0009_000001
2020-08-31 06:48:12,020 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0009_000001
2020-08-31 06:48:12,033 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0009_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0009_000001
2020-08-31 06:48:12,033 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:48:13,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:48:17,349 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0009_000001 (auth:SIMPLE)
2020-08-31 06:48:17,353 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0009_000001
2020-08-31 06:48:17,354 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0009	APPATTEMPTID=appattempt_1598851313344_0009_000001
2020-08-31 06:48:17,354 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:48:17,354 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:48:17,779 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:48:17,779 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000002
2020-08-31 06:48:17,779 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0009_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:48:17,779 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0009_000001 container=Container: [ContainerId: container_1598851313344_0009_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:48:17,779 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:48:17,780 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:18,066 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:48:18,066 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000003
2020-08-31 06:48:18,066 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0009_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 06:48:18,067 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0009_000001 container=Container: [ContainerId: container_1598851313344_0009_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:48:18,067 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:48:18,067 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:18,098 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0009_01_000002
2020-08-31 06:48:18,100 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:48:18,101 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0009_01_000003
2020-08-31 06:48:18,104 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:48:18,781 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:48:19,070 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:48:21,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0009
2020-08-31 06:48:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:48:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0009_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:48:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000003
2020-08-31 06:48:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0009_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 06:48:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:48:23,149 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0009_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,149 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,149 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:48:23,149 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0009_000001 released container container_1598851313344_0009_01_000003 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 06:48:23,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0009_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:48:23,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:48:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0009 with final state: FINISHING
2020-08-31 06:48:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:48:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0009
2020-08-31 06:48:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:48:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:48:23,256 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0009 unregistered successfully. 
2020-08-31 06:48:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:48:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0009_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:48:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000002
2020-08-31 06:48:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0009_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:48:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:48:23,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0009_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:48:23,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0009_000001 released container container_1598851313344_0009_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:48:23,624 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0009_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:48:23,624 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0009_000001
2020-08-31 06:48:23,624 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0009_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0009_000001
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0009	CONTAINERID=container_1598851313344_0009_01_000001
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0009_000001 State change from FINISHING to FINISHED
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0009_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0009 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0009
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0009_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0009_000001 released container container_1598851313344_0009_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0009,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0009/,appMasterHost=10.178.0.24,startTime=1598856491872,finishTime=1598856503153,finalStatus=SUCCEEDED,memorySeconds=28132,vcoreSeconds=21,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:48:23,625 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0009_000001 is done. finalState=FINISHED
2020-08-31 06:48:23,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0009 requests cleared
2020-08-31 06:48:23,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0009 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:48:23,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0009 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:48:23,626 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0009_000001
2020-08-31 06:48:25,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:48:25,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:55:02,903 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 10
2020-08-31 06:55:09,205 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 10 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 10 submitted by user jinhuijun
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0010
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0010
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from NEW to NEW_SAVING on event=START
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0010
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0010 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 06:55:09,206 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0010 from user: jinhuijun, in queue: default
2020-08-31 06:55:09,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 06:55:09,207 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from NEW to SUBMITTED
2020-08-31 06:55:09,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0010 from user: jinhuijun activated in queue: default
2020-08-31 06:55:09,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0010 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@44d11ac4, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 06:55:09,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0010_000001 to scheduler from user jinhuijun in queue default
2020-08-31 06:55:09,223 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 06:55:09,524 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:55:09,524 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000001
2020-08-31 06:55:09,524 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0010_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 06:55:09,524 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0010_000001 container=Container: [ContainerId: container_1598851313344_0010_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:55:09,525 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:55:09,525 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:09,525 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0010_01_000001
2020-08-31 06:55:09,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:55:09,528 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0010 AttemptId: appattempt_1598851313344_0010_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0010_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 06:55:09,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 06:55:09,528 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 06:55:09,529 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0010_000001
2020-08-31 06:55:09,531 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0010_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,531 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0010_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:39772',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 06:55:09,531 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,531 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,551 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0010_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0010_000001
2020-08-31 06:55:09,552 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 06:55:10,527 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:55:14,983 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0010_000001 (auth:SIMPLE)
2020-08-31 06:55:14,988 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0010_000001
2020-08-31 06:55:14,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from LAUNCHED to RUNNING
2020-08-31 06:55:14,988 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0010	APPATTEMPTID=appattempt_1598851313344_0010_000001
2020-08-31 06:55:14,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000002
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0010_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0010_000001 container=Container: [ContainerId: container_1598851313344_0010_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:55:15,167 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000003
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0010_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0010_000001 container=Container: [ContainerId: container_1598851313344_0010_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 06:55:15,211 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:15,366 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0010_01_000002
2020-08-31 06:55:15,369 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:55:15,370 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0010_01_000003
2020-08-31 06:55:15,370 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 06:55:16,168 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:55:16,214 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 06:55:18,502 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0010
2020-08-31 06:55:23,938 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:55:23,938 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0010_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 06:55:23,938 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000003
2020-08-31 06:55:23,938 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0010_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:55:23,938 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 06:55:23,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0010_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 06:55:23,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:23,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 06:55:23,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0010_000001 released container container_1598851313344_0010_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:55:23,942 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0010_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 06:55:23,944 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 06:55:23,944 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0010 with final state: FINISHING
2020-08-31 06:55:23,945 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 06:55:23,945 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0010
2020-08-31 06:55:23,945 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 06:55:23,945 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0010_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000002
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0010_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0010_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 06:55:23,978 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0010_000001 released container container_1598851313344_0010_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:55:24,045 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0010 unregistered successfully. 
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0010_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0010_000001
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0010_000001
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0010_000001 State change from FINISHING to FINISHED
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0010 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0010
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0010_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 06:55:24,415 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0010	CONTAINERID=container_1598851313344_0010_01_000001
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0010_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0010_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0010_000001 released container container_1598851313344_0010_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0010,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0010/,appMasterHost=10.178.0.24,startTime=1598856909205,finishTime=1598856923944,finalStatus=SUCCEEDED,memorySeconds=42185,vcoreSeconds=30,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 06:55:24,416 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0010_000001 is done. finalState=FINISHED
2020-08-31 06:55:24,417 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0010 requests cleared
2020-08-31 06:55:24,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0010 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 06:55:24,418 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0010 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 06:55:24,418 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0010_000001
2020-08-31 06:55:25,941 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 06:55:25,980 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:05:17,636 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 11
2020-08-31 07:05:23,798 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 11 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:05:23,799 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 11 submitted by user jinhuijun
2020-08-31 07:05:23,799 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0011
2020-08-31 07:05:23,800 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0011
2020-08-31 07:05:23,800 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:05:23,805 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0011
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0011 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0011 from user: jinhuijun, in queue: default
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,807 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from NEW to SUBMITTED
2020-08-31 07:05:23,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0011 from user: jinhuijun activated in queue: default
2020-08-31 07:05:23,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0011 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@72382e6, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:05:23,808 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0011_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:05:23,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000001
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0011_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0011_000001 container=Container: [ContainerId: container_1598851313344_0011_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:05:23,850 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:23,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0011_01_000001
2020-08-31 07:05:23,853 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:05:23,853 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,853 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0011 AttemptId: appattempt_1598851313344_0011_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0011_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 07:05:23,853 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:05:23,853 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:05:23,863 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0011_000001
2020-08-31 07:05:23,866 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0011_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,866 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0011_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:42313',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:05:23,866 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,866 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,884 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0011_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0011_000001
2020-08-31 07:05:23,884 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:05:24,851 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:05:29,497 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0011_000001 (auth:SIMPLE)
2020-08-31 07:05:29,500 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0011_000001
2020-08-31 07:05:29,500 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0011	APPATTEMPTID=appattempt_1598851313344_0011_000001
2020-08-31 07:05:29,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:05:29,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000002
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0011_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0011_000001 container=Container: [ContainerId: container_1598851313344_0011_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:05:29,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:30,241 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0011_01_000002
2020-08-31 07:05:30,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000003
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0011_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0011_000001 container=Container: [ContainerId: container_1598851313344_0011_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:05:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:30,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:05:31,070 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0011_01_000003
2020-08-31 07:05:31,071 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:05:31,395 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:05:31,395 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000004
2020-08-31 07:05:31,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0011_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:05:31,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0011_000001 container=Container: [ContainerId: container_1598851313344_0011_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:05:31,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:05:31,396 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:31,396 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:05:34,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0011
2020-08-31 07:05:34,115 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0011_01_000004
2020-08-31 07:05:34,116 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:05:37,125 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0011_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000004
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0011_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0011_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:05:37,126 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0011_000001 released container container_1598851313344_0011_01_000004 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: RELEASED
2020-08-31 07:05:39,989 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0011_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0011 with final state: FINISHING
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0011
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:05:39,990 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:05:39,994 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:05:39,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0011_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:05:39,994 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000003
2020-08-31 07:05:39,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0011_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:05:39,994 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:05:39,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0011_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:05:39,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:39,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:05:39,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0011_000001 released container container_1598851313344_0011_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0011_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000002
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0011_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0011_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:05:40,003 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0011_000001 released container container_1598851313344_0011_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:05:40,094 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0011 unregistered successfully. 
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0011_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0011_000001
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0011_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0011_000001
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0011	CONTAINERID=container_1598851313344_0011_01_000001
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0011_000001 State change from FINISHING to FINISHED
2020-08-31 07:05:40,465 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0011_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0011 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0011
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0011_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0011_000001 released container container_1598851313344_0011_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0011,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0011/,appMasterHost=10.178.0.24,startTime=1598857523798,finishTime=1598857539990,finalStatus=SUCCEEDED,memorySeconds=56072,vcoreSeconds=40,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0011_000001 is done. finalState=FINISHED
2020-08-31 07:05:40,466 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0011_000001
2020-08-31 07:05:40,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0011 requests cleared
2020-08-31 07:05:40,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0011 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:05:40,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0011 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:05:41,999 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:05:42,468 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:07:17,287 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 12
2020-08-31 07:07:24,082 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 12 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:07:24,082 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 12 submitted by user jinhuijun
2020-08-31 07:07:24,082 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0012
2020-08-31 07:07:24,082 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0012
2020-08-31 07:07:24,082 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:07:24,083 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0012
2020-08-31 07:07:24,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:07:24,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0012 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:07:24,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0012 from user: jinhuijun, in queue: default
2020-08-31 07:07:24,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:07:24,094 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,094 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from NEW to SUBMITTED
2020-08-31 07:07:24,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0012 from user: jinhuijun activated in queue: default
2020-08-31 07:07:24,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0012 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@40637f2, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:07:24,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0012_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:07:24,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:07:24,246 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:07:24,246 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000001
2020-08-31 07:07:24,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0012_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:07:24,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0012_000001 container=Container: [ContainerId: container_1598851313344_0012_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:07:24,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:07:24,247 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:24,254 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0012_01_000001
2020-08-31 07:07:24,256 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:07:24,257 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0012 AttemptId: appattempt_1598851313344_0012_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0012_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 07:07:24,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:07:24,257 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:07:24,261 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0012_000001
2020-08-31 07:07:24,265 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0012_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,265 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0012_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:46048',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:07:24,265 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,265 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,281 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0012_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0012_000001
2020-08-31 07:07:24,281 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:07:25,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:07:29,595 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0012_000001 (auth:SIMPLE)
2020-08-31 07:07:29,600 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0012_000001
2020-08-31 07:07:29,600 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0012	APPATTEMPTID=appattempt_1598851313344_0012_000001
2020-08-31 07:07:29,601 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:07:29,601 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000002
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0012_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0012_000001 container=Container: [ContainerId: container_1598851313344_0012_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:07:29,788 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:29,936 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0012_01_000002
2020-08-31 07:07:29,938 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000003
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0012_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0012_000001 container=Container: [ContainerId: container_1598851313344_0012_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:07:30,290 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:30,411 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0012_01_000003
2020-08-31 07:07:30,414 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000004
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0012_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0012_000001 container=Container: [ContainerId: container_1598851313344_0012_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:07:30,694 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:30,790 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:07:31,302 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:07:33,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0012
2020-08-31 07:07:33,422 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0012_01_000004
2020-08-31 07:07:33,422 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:07:36,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:07:36,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0012_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:07:36,437 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000004
2020-08-31 07:07:36,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0012_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:07:36,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:07:36,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0012_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:07:36,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:36,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:07:36,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0012_000001 released container container_1598851313344_0012_01_000004 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: RELEASED
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0012_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0012 with final state: FINISHING
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0012
2020-08-31 07:07:38,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:07:38,023 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0012_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000002
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0012_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0012_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:07:38,040 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0012_000001 released container container_1598851313344_0012_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0012_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000003
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0012_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:07:38,092 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0012_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:07:38,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0012_000001 released container container_1598851313344_0012_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:07:38,127 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0012 unregistered successfully. 
2020-08-31 07:07:38,579 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0012_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0012_000001
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0012_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0012_000001
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0012	CONTAINERID=container_1598851313344_0012_01_000001
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0012_000001 State change from FINISHING to FINISHED
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0012_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0012 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0012_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0012
2020-08-31 07:07:38,581 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0012,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0012/,appMasterHost=10.178.0.23,startTime=1598857644082,finishTime=1598857658022,finalStatus=SUCCEEDED,memorySeconds=48157,vcoreSeconds=34,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:07:38,580 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0012_000001 released container container_1598851313344_0012_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:07:38,581 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0012_000001 is done. finalState=FINISHED
2020-08-31 07:07:38,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0012 requests cleared
2020-08-31 07:07:38,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0012 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:07:38,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0012 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:07:38,582 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0012_000001
2020-08-31 07:07:40,042 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:07:40,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:13:43,382 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 13
2020-08-31 07:13:49,669 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 13 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 13 submitted by user jinhuijun
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0013
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0013
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0013
2020-08-31 07:13:49,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0013 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0013 from user: jinhuijun, in queue: default
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from NEW to SUBMITTED
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0013 from user: jinhuijun activated in queue: default
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0013 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@407f372d, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:13:49,671 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0013_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:13:49,672 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:13:49,906 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:13:49,906 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000001
2020-08-31 07:13:49,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0013_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:13:49,906 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0013_000001 container=Container: [ContainerId: container_1598851313344_0013_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:13:49,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:13:49,907 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:13:49,908 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0013_01_000001
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0013 AttemptId: appattempt_1598851313344_0013_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0013_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:13:49,910 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0013_000001
2020-08-31 07:13:49,913 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0013_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,913 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0013_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:36362',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:13:49,913 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,913 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,927 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0013_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0013_000001
2020-08-31 07:13:49,927 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:13:50,908 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:13:55,444 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0013_000001 (auth:SIMPLE)
2020-08-31 07:13:55,448 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0013_000001
2020-08-31 07:13:55,448 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0013	APPATTEMPTID=appattempt_1598851313344_0013_000001
2020-08-31 07:13:55,448 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:13:55,448 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:13:55,935 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:13:55,935 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000002
2020-08-31 07:13:55,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0013_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:13:55,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0013_000001 container=Container: [ContainerId: container_1598851313344_0013_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:13:55,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:13:55,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:13:56,193 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0013_01_000002
2020-08-31 07:13:56,194 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000003
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0013_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0013_000001 container=Container: [ContainerId: container_1598851313344_0013_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:13:56,469 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:13:56,945 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:13:57,013 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0013_01_000003
2020-08-31 07:13:57,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:13:57,471 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000004
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0013_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:3072, vCores:2> used and <memory:58368, vCores:10> available after allocation
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0013_000001 container=Container: [ContainerId: container_1598851313344_0013_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:13:57,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:14:00,043 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0013
2020-08-31 07:14:00,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:14:03,050 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:14:03,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0013_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:14:03,050 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000004
2020-08-31 07:14:03,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0013_01_000004 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available, release resources=true
2020-08-31 07:14:03,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:14:03,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0013_01_000004, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:14:03,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:14:03,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:14:03,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0013_000001 released container container_1598851313344_0013_01_000004 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:59904, vCores:11> used=<memory:1536, vCores:1> with event: RELEASED
2020-08-31 07:14:05,897 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:14:05,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0013_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:14:05,897 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000002
2020-08-31 07:14:05,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0013_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:14:05,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:14:05,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0013_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:14:05,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:14:05,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:14:05,898 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0013_000001 released container container_1598851313344_0013_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:14:05,912 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0013_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0013 with final state: FINISHING
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0013
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:14:05,914 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:14:05,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0013_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000003
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0013_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0013_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:14:05,979 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0013_000001 released container container_1598851313344_0013_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:14:06,112 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0013 unregistered successfully. 
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0013_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0013_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0013	CONTAINERID=container_1598851313344_0013_01_000001
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0013_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0013_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0013_000001
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0013_000001
2020-08-31 07:14:06,485 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0013_000001 State change from FINISHING to FINISHED
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0013 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0013
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0013_000001 released container container_1598851313344_0013_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:14:06,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0013_000001 is done. finalState=FINISHED
2020-08-31 07:14:06,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0013 requests cleared
2020-08-31 07:14:06,487 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0013,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0013/,appMasterHost=10.178.0.24,startTime=1598858029669,finishTime=1598858045914,finalStatus=SUCCEEDED,memorySeconds=55449,vcoreSeconds=39,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:14:06,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0013 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:14:06,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0013 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:14:06,488 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0013_000001
2020-08-31 07:14:07,986 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:14:08,487 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:16:48,822 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 14
2020-08-31 07:16:55,090 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 14 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:16:55,090 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 14 submitted by user jinhuijun
2020-08-31 07:16:55,090 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0014
2020-08-31 07:16:55,101 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0014
2020-08-31 07:16:55,101 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:16:55,103 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0014
2020-08-31 07:16:55,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:16:55,103 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0014 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:16:55,103 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0014 from user: jinhuijun, in queue: default
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from NEW to SUBMITTED
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0014 from user: jinhuijun activated in queue: default
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0014 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@cb402dc, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:16:55,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0014_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:16:55,106 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000001
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0014_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0014_000001 container=Container: [ContainerId: container_1598851313344_0014_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:16:55,512 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:16:55,513 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0014_01_000001
2020-08-31 07:16:55,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:16:55,515 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0014 AttemptId: appattempt_1598851313344_0014_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0014_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 07:16:55,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:16:55,522 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:16:55,528 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0014_000001
2020-08-31 07:16:55,531 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0014_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,531 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0014_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:41069',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:16:55,532 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,532 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,554 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0014_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0014_000001
2020-08-31 07:16:55,554 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:16:56,519 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:17:01,076 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0014_000001 (auth:SIMPLE)
2020-08-31 07:17:01,084 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0014_000001
2020-08-31 07:17:01,084 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0014	APPATTEMPTID=appattempt_1598851313344_0014_000001
2020-08-31 07:17:01,084 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:17:01,084 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:17:01,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:17:01,546 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000002
2020-08-31 07:17:01,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0014_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:17:01,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0014_000001 container=Container: [ContainerId: container_1598851313344_0014_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:17:01,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:17:01,547 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:01,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0014_01_000002
2020-08-31 07:17:01,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000003
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0014_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0014_000001 container=Container: [ContainerId: container_1598851313344_0014_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:17:01,883 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:02,553 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:17:02,685 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0014_01_000003
2020-08-31 07:17:02,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:17:02,884 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:17:02,885 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:17:02,885 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000004
2020-08-31 07:17:02,885 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0014_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:3072, vCores:2> used and <memory:58368, vCores:10> available after allocation
2020-08-31 07:17:02,885 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0014_000001 container=Container: [ContainerId: container_1598851313344_0014_01_000004, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:17:02,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:17:02,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:05,758 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0014
2020-08-31 07:17:05,760 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:17:08,765 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:17:08,765 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0014_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000004
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0014_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available, release resources=true
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0014_01_000004, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:08,766 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:17:08,767 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0014_000001 released container container_1598851313344_0014_01_000004 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:59904, vCores:11> used=<memory:1536, vCores:1> with event: RELEASED
2020-08-31 07:17:13,112 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:17:13,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0014_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:17:13,113 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000003
2020-08-31 07:17:13,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0014_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:17:13,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:17:13,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0014_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:17:13,114 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0014_000001 released container container_1598851313344_0014_01_000003 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:17:13,114 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0014_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000002
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0014_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0014_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:17:13,115 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0014_000001 released container container_1598851313344_0014_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:17:13,130 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0014_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0014 with final state: FINISHING
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0014
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:17:13,131 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:17:13,234 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0014 unregistered successfully. 
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0014_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0014_000001
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0014_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0014_000001
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0014	CONTAINERID=container_1598851313344_0014_01_000001
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0014_000001 State change from FINISHING to FINISHED
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0014_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0014 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0014
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0014_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:17:13,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:17:13,609 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0014,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0014/,appMasterHost=10.178.0.22,startTime=1598858215090,finishTime=1598858233131,finalStatus=SUCCEEDED,memorySeconds=62577,vcoreSeconds=45,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:17:13,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0014_000001 released container container_1598851313344_0014_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:17:13,609 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0014_000001 is done. finalState=FINISHED
2020-08-31 07:17:13,610 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0014_000001
2020-08-31 07:17:13,610 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0014 requests cleared
2020-08-31 07:17:13,612 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0014 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:17:13,612 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0014 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:17:15,101 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:17:15,610 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:19:04,052 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 15
2020-08-31 07:19:10,159 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 15 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:19:10,159 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 15 submitted by user jinhuijun
2020-08-31 07:19:10,159 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0015
2020-08-31 07:19:10,159 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0015
2020-08-31 07:19:10,159 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:19:10,159 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0015
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0015 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0015 from user: jinhuijun, in queue: default
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,160 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from NEW to SUBMITTED
2020-08-31 07:19:10,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0015 from user: jinhuijun activated in queue: default
2020-08-31 07:19:10,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0015 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@179b951e, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:19:10,161 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0015_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:19:10,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000001
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0015_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0015_000001 container=Container: [ContainerId: container_1598851313344_0015_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:19:10,297 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:10,298 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0015_01_000001
2020-08-31 07:19:10,299 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:19:10,299 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0015 AttemptId: appattempt_1598851313344_0015_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0015_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 07:19:10,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:19:10,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:19:10,300 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0015_000001
2020-08-31 07:19:10,302 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0015_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,302 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0015_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:46518',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:19:10,302 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,302 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,327 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0015_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0015_000001
2020-08-31 07:19:10,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:19:11,321 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:19:16,031 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0015_000001 (auth:SIMPLE)
2020-08-31 07:19:16,041 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0015_000001
2020-08-31 07:19:16,041 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0015	APPATTEMPTID=appattempt_1598851313344_0015_000001
2020-08-31 07:19:16,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:19:16,041 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:19:16,360 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:19:16,360 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000002
2020-08-31 07:19:16,360 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0015_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:19:16,361 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0015_000001 container=Container: [ContainerId: container_1598851313344_0015_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:19:16,361 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:19:16,361 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000003
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0015_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0015_000001 container=Container: [ContainerId: container_1598851313344_0015_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:19:16,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:16,393 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0015_01_000002
2020-08-31 07:19:16,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:19:16,395 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0015_01_000003
2020-08-31 07:19:16,398 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:19:17,362 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:19:17,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:19:19,486 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0015
2020-08-31 07:19:24,811 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:19:24,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0015_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:19:24,811 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000002
2020-08-31 07:19:24,811 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0015_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:19:24,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:19:24,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0015_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:19:24,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:24,812 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:19:24,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0015_000001 released container container_1598851313344_0015_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:19:24,832 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:19:24,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0015_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:19:24,832 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000003
2020-08-31 07:19:24,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0015_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:19:24,832 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:19:24,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0015_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:19:24,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:24,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:19:24,833 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0015_000001 released container container_1598851313344_0015_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0015_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0015 with final state: FINISHING
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0015
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:19:24,845 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:19:24,948 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0015 unregistered successfully. 
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0015_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0015_000001
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0015_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0015_000001
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0015_000001 State change from FINISHING to FINISHED
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0015	CONTAINERID=container_1598851313344_0015_01_000001
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0015 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0015_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0015
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0015,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0015/,appMasterHost=10.178.0.23,startTime=1598858350159,finishTime=1598858364845,finalStatus=SUCCEEDED,memorySeconds=41452,vcoreSeconds=31,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:19:25,421 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0015_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0015_000001 released container container_1598851313344_0015_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0015_000001 is done. finalState=FINISHED
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0015_000001
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0015 requests cleared
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0015 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:19:25,422 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0015 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:19:26,813 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:19:27,425 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:20:12,667 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 16
2020-08-31 07:20:19,120 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 16 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:20:19,121 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 16 submitted by user jinhuijun
2020-08-31 07:20:19,121 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0016
2020-08-31 07:20:19,121 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0016
2020-08-31 07:20:19,121 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0016
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0016 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0016 from user: jinhuijun, in queue: default
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,122 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from NEW to SUBMITTED
2020-08-31 07:20:19,123 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0016 from user: jinhuijun activated in queue: default
2020-08-31 07:20:19,123 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0016 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@221799b8, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:20:19,123 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0016_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:20:19,123 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000001
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0016_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0016_000001 container=Container: [ContainerId: container_1598851313344_0016_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:20:19,597 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:19,598 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0016_01_000001
2020-08-31 07:20:19,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:20:19,600 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0016 AttemptId: appattempt_1598851313344_0016_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0016_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ]
2020-08-31 07:20:19,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:20:19,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:20:19,601 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0016_000001
2020-08-31 07:20:19,603 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0016_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,603 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0016_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:43429',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:20:19,603 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,603 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,616 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0016_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] for AM appattempt_1598851313344_0016_000001
2020-08-31 07:20:19,616 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:20:20,620 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:20:25,048 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0016_000001 (auth:SIMPLE)
2020-08-31 07:20:25,053 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0016_000001
2020-08-31 07:20:25,053 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0016	APPATTEMPTID=appattempt_1598851313344_0016_000001
2020-08-31 07:20:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:20:25,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:20:25,175 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:20:25,175 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000002
2020-08-31 07:20:25,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0016_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:20:25,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0016_000001 container=Container: [ContainerId: container_1598851313344_0016_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:20:25,175 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:20:25,176 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:25,196 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0016_01_000002
2020-08-31 07:20:25,200 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:20:25,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:20:25,678 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000003
2020-08-31 07:20:25,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0016_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:20:25,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0016_000001 container=Container: [ContainerId: container_1598851313344_0016_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:20:25,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:20:25,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:25,879 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0016_01_000003
2020-08-31 07:20:25,880 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:20:26,178 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:20:26,679 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:20:28,886 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0016
2020-08-31 07:20:34,127 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:20:34,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0016_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:20:34,127 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000003
2020-08-31 07:20:34,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0016_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:20:34,127 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:20:34,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0016_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:20:34,128 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0016_000001 released container container_1598851313344_0016_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:20:34,139 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:20:34,139 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0016_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:20:34,139 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000002
2020-08-31 07:20:34,139 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0016_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:20:34,140 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:20:34,140 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0016_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,140 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,140 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:20:34,140 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0016_000001 released container container_1598851313344_0016_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0016_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0016 with final state: FINISHING
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0016
2020-08-31 07:20:34,147 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:20:34,148 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:20:34,336 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0016 unregistered successfully. 
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0016_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0016_000001
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0016_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0016_000001
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0016	CONTAINERID=container_1598851313344_0016_01_000001
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0016_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0016_000001 State change from FINISHING to FINISHED
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0016 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0016_01_000001, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0016
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:20:34,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:20:34,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0016_000001 released container container_1598851313344_0016_01_000001 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:20:34,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0016_000001 is done. finalState=FINISHED
2020-08-31 07:20:34,704 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0016,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0016/,appMasterHost=10.178.0.23,startTime=1598858419120,finishTime=1598858434147,finalStatus=SUCCEEDED,memorySeconds=42216,vcoreSeconds=31,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:20:34,707 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0016 requests cleared
2020-08-31 07:20:34,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0016 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:20:34,708 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0016 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:20:34,708 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0016_000001
2020-08-31 07:20:36,141 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:20:36,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:21:08,278 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 17
2020-08-31 07:21:14,863 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 17 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:21:14,863 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 17 submitted by user jinhuijun
2020-08-31 07:21:14,863 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0017
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0017
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0017
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0017 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0017 from user: jinhuijun, in queue: default
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0017_000001
2020-08-31 07:21:14,868 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from NEW to SUBMITTED
2020-08-31 07:21:14,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0017 from user: jinhuijun activated in queue: default
2020-08-31 07:21:14,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0017 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1b681488, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:21:14,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0017_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:21:14,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000001
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0017_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0017_000001 container=Container: [ContainerId: container_1598851313344_0017_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:15,192 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0017_01_000001
2020-08-31 07:21:15,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:21:15,196 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0017_000001
2020-08-31 07:21:15,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0017 AttemptId: appattempt_1598851313344_0017_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0017_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 07:21:15,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:21:15,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:21:15,197 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0017_000001
2020-08-31 07:21:15,206 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0017_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0017_000001
2020-08-31 07:21:15,206 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0017_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:35063',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:21:15,206 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0017_000001
2020-08-31 07:21:15,206 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0017_000001
2020-08-31 07:21:15,231 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0017_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0017_000001
2020-08-31 07:21:15,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:21:16,198 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:21:20,400 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0017_000001 (auth:SIMPLE)
2020-08-31 07:21:20,403 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0017_000001
2020-08-31 07:21:20,404 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0017	APPATTEMPTID=appattempt_1598851313344_0017_000001
2020-08-31 07:21:20,404 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:21:20,404 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000002
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0017_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0017_000001 container=Container: [ContainerId: container_1598851313344_0017_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:21:20,855 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:21,152 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0017_01_000002
2020-08-31 07:21:21,154 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000003
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0017_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0017_000001 container=Container: [ContainerId: container_1598851313344_0017_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:21:21,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:21,858 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:21:22,023 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0017_01_000003
2020-08-31 07:21:22,025 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:21:22,253 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:21:22,254 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:21:22,254 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000004
2020-08-31 07:21:22,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0017_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 3 containers, <memory:4096, vCores:3> used and <memory:57344, vCores:9> available after allocation
2020-08-31 07:21:22,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0017_000001 container=Container: [ContainerId: container_1598851313344_0017_01_000004, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:21:22,254 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:21:22,255 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:25,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0017
2020-08-31 07:21:25,040 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:21:28,047 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:21:28,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0017_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:21:28,047 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000004
2020-08-31 07:21:28,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0017_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available, release resources=true
2020-08-31 07:21:28,047 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:21:28,048 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0017_01_000004, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:21:28,048 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:28,048 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:21:28,048 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0017_000001 released container container_1598851313344_0017_01_000004 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=2 available=<memory:58880, vCores:10> used=<memory:2560, vCores:2> with event: RELEASED
2020-08-31 07:21:30,564 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0017_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000002
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0017_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0017_01_000002, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:21:30,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:30,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:21:30,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0017_000001 released container container_1598851313344_0017_01_000002 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:21:30,582 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:21:30,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0017_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:21:30,582 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000003
2020-08-31 07:21:30,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0017_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:21:30,582 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:21:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0017_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:21:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:21:30,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0017_000001 released container container_1598851313344_0017_01_000003 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0017_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0017 with final state: FINISHING
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0017
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:21:30,665 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:21:30,768 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0017 unregistered successfully. 
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0017_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0017_000001
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0017_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0017_000001
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0017	CONTAINERID=container_1598851313344_0017_01_000001
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0017_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0017_000001 State change from FINISHING to FINISHED
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0017 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0017_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0017
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:21:31,153 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0017,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0017/,appMasterHost=10.178.0.24,startTime=1598858474863,finishTime=1598858490665,finalStatus=SUCCEEDED,memorySeconds=54498,vcoreSeconds=38,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:21:31,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:21:31,154 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0017_000001
2020-08-31 07:21:31,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0017_000001 released container container_1598851313344_0017_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:21:31,155 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0017_000001 is done. finalState=FINISHED
2020-08-31 07:21:31,155 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0017 requests cleared
2020-08-31 07:21:31,155 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0017 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:21:31,155 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0017 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:21:32,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:21:33,155 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:23:06,183 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 18
2020-08-31 07:23:12,436 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 18 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:23:12,436 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 18 submitted by user jinhuijun
2020-08-31 07:23:12,436 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0018
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0018
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0018
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0018 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:23:12,437 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0018 from user: jinhuijun, in queue: default
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from NEW to SUBMITTED
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0018 from user: jinhuijun activated in queue: default
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0018 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@37e657db, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:23:12,438 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0018_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:23:12,440 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000001
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0018_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0018_000001 container=Container: [ContainerId: container_1598851313344_0018_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:23:12,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:12,541 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0018_01_000001
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0018 AttemptId: appattempt_1598851313344_0018_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0018_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:23:12,546 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0018_000001
2020-08-31 07:23:12,548 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0018_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,549 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0018_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:33978',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:23:12,549 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,549 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,576 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0018_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0018_000001
2020-08-31 07:23:12,576 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:23:13,552 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:23:18,086 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0018_000001 (auth:SIMPLE)
2020-08-31 07:23:18,090 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0018_000001
2020-08-31 07:23:18,090 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0018	APPATTEMPTID=appattempt_1598851313344_0018_000001
2020-08-31 07:23:18,090 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:23:18,090 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000002
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0018_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0018_000001 container=Container: [ContainerId: container_1598851313344_0018_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:23:18,439 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:18,610 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:23:18,610 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000003
2020-08-31 07:23:18,610 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0018_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:23:18,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0018_000001 container=Container: [ContainerId: container_1598851313344_0018_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:23:18,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:23:18,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:18,818 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0018_01_000002
2020-08-31 07:23:18,820 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:23:18,820 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0018_01_000003
2020-08-31 07:23:18,821 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:23:19,442 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:23:19,614 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:23:21,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0018
2020-08-31 07:23:28,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0018_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:23:28,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:23:28,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0018 with final state: FINISHING
2020-08-31 07:23:28,548 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:23:28,549 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0018
2020-08-31 07:23:28,549 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:23:28,549 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:23:28,555 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:23:28,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0018_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:23:28,555 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000002
2020-08-31 07:23:28,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0018_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:23:28,555 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:23:28,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0018_01_000002, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:23:28,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:28,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:23:28,556 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0018_000001 released container container_1598851313344_0018_01_000002 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:23:28,574 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:23:28,574 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0018_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000003
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0018_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0018_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:23:28,575 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0018_000001 released container container_1598851313344_0018_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:23:28,652 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0018 unregistered successfully. 
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0018_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0018_000001
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0018_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0018_000001
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0018	CONTAINERID=container_1598851313344_0018_01_000001
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0018_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0018_000001 State change from FINISHING to FINISHED
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0018 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0018_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:23:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:23:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0018_000001 released container container_1598851313344_0018_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:23:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0018_000001 is done. finalState=FINISHED
2020-08-31 07:23:29,109 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0018
2020-08-31 07:23:29,110 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0018_000001
2020-08-31 07:23:29,111 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0018 requests cleared
2020-08-31 07:23:29,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0018 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:23:29,112 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0018,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0018/,appMasterHost=10.178.0.22,startTime=1598858592436,finishTime=1598858608548,finalStatus=SUCCEEDED,memorySeconds=47808,vcoreSeconds=35,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:23:29,112 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0018 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:23:30,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:23:31,113 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:25:44,381 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 19
2020-08-31 07:25:50,726 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 19 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:25:50,726 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 19 submitted by user jinhuijun
2020-08-31 07:25:50,726 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0019
2020-08-31 07:25:50,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0019
2020-08-31 07:25:50,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:25:50,728 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0019
2020-08-31 07:25:50,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:25:50,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0019 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:25:50,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0019 from user: jinhuijun, in queue: default
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from NEW to SUBMITTED
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0019 from user: jinhuijun activated in queue: default
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0019 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7c9e075c, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:25:50,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0019_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:25:50,730 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000001
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0019_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0019_000001 container=Container: [ContainerId: container_1598851313344_0019_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:25:50,848 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:25:50,850 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0019_01_000001
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0019 AttemptId: appattempt_1598851313344_0019_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0019_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ]
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:25:50,852 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0019_000001
2020-08-31 07:25:50,856 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0019_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,856 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0019_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:38429',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:25:50,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,856 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,876 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0019_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] for AM appattempt_1598851313344_0019_000001
2020-08-31 07:25:50,877 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:25:51,851 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:25:56,176 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0019_000001 (auth:SIMPLE)
2020-08-31 07:25:56,184 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0019_000001
2020-08-31 07:25:56,184 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0019	APPATTEMPTID=appattempt_1598851313344_0019_000001
2020-08-31 07:25:56,184 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:25:56,184 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:25:56,434 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:25:56,434 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000002
2020-08-31 07:25:56,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0019_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:25:56,434 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0019_000001 container=Container: [ContainerId: container_1598851313344_0019_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:25:56,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:25:56,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:25:56,542 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0019_01_000002
2020-08-31 07:25:56,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:25:56,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:25:56,971 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000003
2020-08-31 07:25:56,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0019_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:25:56,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0019_000001 container=Container: [ContainerId: container_1598851313344_0019_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:25:56,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:25:56,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:25:56,986 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:41729 for container : container_1598851313344_0019_01_000003
2020-08-31 07:25:56,993 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000004
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0019_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0019_000001 container=Container: [ContainerId: container_1598851313344_0019_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:25:57,203 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:25:57,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:25:57,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:25:59,998 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0019
2020-08-31 07:26:00,000 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0019_01_000004
2020-08-31 07:26:00,001 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:26:03,015 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:26:03,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0019_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:26:03,015 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000004
2020-08-31 07:26:03,015 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0019_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:26:03,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:26:03,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0019_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:26:03,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:26:03,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:26:03,016 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0019_000001 released container container_1598851313344_0019_01_000004 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: RELEASED
2020-08-31 07:28:22,217 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:28:22,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0019_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:28:22,218 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000003
2020-08-31 07:28:22,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0019_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:28:22,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:28:22,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0019_01_000003, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:28:22,219 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0019_000001 released container container_1598851313344_0019_01_000003 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:28:22,233 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0019_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0019 with final state: FINISHING
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0019
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:28:22,234 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:28:22,336 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0019 unregistered successfully. 
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0019_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000002
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0019_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0019_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:28:22,488 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0019_000001 released container container_1598851313344_0019_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:28:22,709 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0019_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:28:22,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0019_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:28:22,709 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0019_000001
2020-08-31 07:28:22,709 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0019	CONTAINERID=container_1598851313344_0019_01_000001
2020-08-31 07:28:22,710 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0019_000001
2020-08-31 07:28:22,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0019_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:41729, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:28:22,710 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0019_000001 State change from FINISHING to FINISHED
2020-08-31 07:28:22,710 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0019 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:28:22,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0019_01_000001, NodeId: broker3.c.poetic-set-285601.internal:41729, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:41729 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0019_000001 released container container_1598851313344_0019_01_000001 on node: host: broker3.c.poetic-set-285601.internal:41729 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0019
2020-08-31 07:28:22,711 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0019_000001 is done. finalState=FINISHED
2020-08-31 07:28:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0019 requests cleared
2020-08-31 07:28:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0019 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:28:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0019 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:28:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0019_000001
2020-08-31 07:28:22,712 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0019,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0019/,appMasterHost=10.178.0.24,startTime=1598858750726,finishTime=1598858902234,finalStatus=SUCCEEDED,memorySeconds=611868,vcoreSeconds=447,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:28:24,491 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:28:24,764 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:30:41,853 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 20
2020-08-31 07:30:48,206 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 20 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:30:48,206 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 20 submitted by user jinhuijun
2020-08-31 07:30:48,206 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598851313344_0020
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598851313344_0020
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598851313344_0020
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598851313344_0020 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598851313344_0020 from user: jinhuijun, in queue: default
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,207 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from NEW to SUBMITTED
2020-08-31 07:30:48,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598851313344_0020 from user: jinhuijun activated in queue: default
2020-08-31 07:30:48,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598851313344_0020 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@625a8b2e, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:30:48,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598851313344_0020_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:30:48,222 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:30:48,870 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000001
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0020_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0020_000001 container=Container: [ContainerId: container_1598851313344_0020_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:30:48,871 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0020_01_000001
2020-08-31 07:30:48,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:30:48,873 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598851313344_0020 AttemptId: appattempt_1598851313344_0020_000001 MasterContainer: Container: [ContainerId: container_1598851313344_0020_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ]
2020-08-31 07:30:48,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:30:48,873 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:30:48,874 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598851313344_0020_000001
2020-08-31 07:30:48,876 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598851313344_0020_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,876 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598851313344_0020_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:44610',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:30:48,876 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,876 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,898 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598851313344_0020_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] for AM appattempt_1598851313344_0020_000001
2020-08-31 07:30:48,899 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:30:49,887 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:30:54,372 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598851313344_0020_000001 (auth:SIMPLE)
2020-08-31 07:30:54,383 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598851313344_0020_000001
2020-08-31 07:30:54,383 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598851313344_0020	APPATTEMPTID=appattempt_1598851313344_0020_000001
2020-08-31 07:30:54,383 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:30:54,384 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000002
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0020_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0020_000001 container=Container: [ContainerId: container_1598851313344_0020_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:30:54,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000003
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598851313344_0020_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598851313344_0020_000001 container=Container: [ContainerId: container_1598851313344_0020_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:30:54,969 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:30:55,134 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:42748 for container : container_1598851313344_0020_01_000002
2020-08-31 07:30:55,136 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:30:55,136 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46369 for container : container_1598851313344_0020_01_000003
2020-08-31 07:30:55,136 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:30:55,979 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:30:55,982 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:30:58,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598851313344_0020
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598851313344_0020_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598851313344_0020 with final state: FINISHING
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598851313344_0020
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:32:28,968 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:32:29,071 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598851313344_0020 unregistered successfully. 
2020-08-31 07:32:29,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:32:29,320 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0020_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:32:29,320 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000002
2020-08-31 07:32:29,320 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0020_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:32:29,320 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:32:29,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0020_01_000002, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:32:29,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0020_000001 released container container_1598851313344_0020_01_000002 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0020_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000003
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0020_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46369, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0020_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46369, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46369 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:32:29,337 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0020_000001 released container container_1598851313344_0020_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46369 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:32:29,543 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598851313344_0020_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:32:29,543 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598851313344_0020_000001
2020-08-31 07:32:29,543 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598851313344_0020_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598851313344_0020_000001
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598851313344_0020	CONTAINERID=container_1598851313344_0020_01_000001
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598851313344_0020_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:42748, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598851313344_0020_000001 State change from FINISHING to FINISHED
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598851313344_0020 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598851313344_0020_01_000001, NodeId: broker1.c.poetic-set-285601.internal:42748, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:42748 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598851313344_0020
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:32:29,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:32:29,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598851313344_0020_000001 released container container_1598851313344_0020_01_000001 on node: host: broker1.c.poetic-set-285601.internal:42748 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:32:29,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598851313344_0020_000001 is done. finalState=FINISHED
2020-08-31 07:32:29,544 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598851313344_0020,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598851313344_0020/,appMasterHost=10.178.0.22,startTime=1598859048206,finishTime=1598859148968,finalStatus=SUCCEEDED,memorySeconds=393034,vcoreSeconds=288,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:32:29,545 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598851313344_0020_000001
2020-08-31 07:32:29,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598851313344_0020 requests cleared
2020-08-31 07:32:29,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598851313344_0020 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:32:29,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598851313344_0020 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:32:31,339 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:32:31,546 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:45:16,496 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-31 07:45:16,525 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:45:16,527 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 07:45:16,630 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-31 07:45:16,634 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-31 07:45:16,637 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-31 07:45:16,638 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:45:16,639 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:45:16,639 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-31 07:45:16,640 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-31 07:45:16,643 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-31 07:45:16,644 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-31 07:45:16,659 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-31 07:45:16,659 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-31 07:45:16,660 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:45:16,663 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-31 07:45:16,663 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:45:16,663 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-31 07:45:16,663 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-31 07:45:16,669 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:45:16,669 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:45:16,669 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:45:16,669 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-31 07:45:16,670 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:45:16,670 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-31 07:45:16,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-31 07:45:16,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-31 07:45:16,672 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:45:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-31 07:45:16,673 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-31 07:48:12,456 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-31 07:48:12,470 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-31 07:48:12,895 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-31 07:48:13,077 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-31 07:48:13,176 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-31 07:48:13,390 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-31 07:48:13,469 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-31 07:48:13,473 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-31 07:48:13,480 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-31 07:48:13,518 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-31 07:48:13,520 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-31 07:48:13,520 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-31 07:48:13,541 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-31 07:48:13,543 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-31 07:48:13,544 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-31 07:48:13,545 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-31 07:48:13,629 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-31 07:48:13,747 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-31 07:48:13,747 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-31 07:48:13,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-31 07:48:13,776 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-31 07:48:13,780 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-31 07:48:13,783 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-31 07:48:13,784 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-31 07:48:13,786 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-31 07:48:13,859 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-31 07:48:13,860 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-31 07:48:13,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-31 07:48:13,864 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-31 07:48:13,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-31 07:48:13,874 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-31 07:48:13,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-31 07:48:13,875 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:48:13,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:48:13,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:48:13,876 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-31 07:48:13,877 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-31 07:48:13,892 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-31 07:48:13,892 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-31 07:48:13,907 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-31 07:48:13,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-31 07:48:13,907 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-31 07:48:13,908 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:48:13,909 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-31 07:48:13,909 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 07:48:13,911 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 07:48:13,911 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:48:13,911 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-31 07:48:13,911 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 07:48:13,913 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-31 07:48:13,941 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:48:13,959 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-31 07:48:14,144 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-31 07:48:14,144 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:48:14,146 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-31 07:48:14,170 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:48:14,178 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-31 07:48:14,192 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-31 07:48:14,195 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:48:14,199 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-31 07:48:14,274 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:48:14,276 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-31 07:48:14,282 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-31 07:48:14,283 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:48:14,283 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-31 07:48:14,319 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-31 07:48:14,465 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-31 07:48:14,473 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-31 07:48:14,481 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-31 07:48:14,493 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-31 07:48:14,496 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-31 07:48:14,497 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-31 07:48:14,497 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-31 07:48:14,497 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-31 07:48:14,497 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-31 07:48:14,497 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-31 07:48:14,503 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-31 07:48:14,503 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-31 07:48:14,894 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-31 07:48:14,903 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-31 07:48:14,904 INFO org.mortbay.log: jetty-6.1.26
2020-08-31 07:48:14,938 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-31 07:48:15,406 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:48:15,428 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 07:48:15,428 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:48:17,593 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 07:48:17,593 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-31 07:48:17,680 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-31 07:48:17,687 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-31 07:48:17,697 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-31 07:48:17,705 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:48:17,705 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-31 07:48:19,138 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:48:19,141 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 46804 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:46804
2020-08-31 07:48:19,155 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:46804 Node Transitioned from NEW to RUNNING
2020-08-31 07:48:19,159 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:46804 clusterResource: <memory:61440, vCores:12>
2020-08-31 07:48:19,562 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:48:19,562 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 46172 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:46172
2020-08-31 07:48:19,565 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:46172 Node Transitioned from NEW to RUNNING
2020-08-31 07:48:19,566 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:46172 clusterResource: <memory:122880, vCores:24>
2020-08-31 07:48:19,705 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:48:19,705 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 36653 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:36653
2020-08-31 07:48:19,705 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:36653 Node Transitioned from NEW to RUNNING
2020-08-31 07:48:19,706 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:36653 clusterResource: <memory:184320, vCores:36>
2020-08-31 07:48:22,115 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-08-31 07:48:35,942 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:48:35,944 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-08-31 07:48:35,946 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598860093893_0001
2020-08-31 07:48:35,951 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598860093893_0001
2020-08-31 07:48:35,971 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:48:35,973 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598860093893_0001
2020-08-31 07:48:36,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:48:36,024 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598860093893_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:48:36,025 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598860093893_0001 from user: jinhuijun, in queue: default
2020-08-31 07:48:36,125 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:48:36,160 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598860093893_0001_000001
2020-08-31 07:48:36,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from NEW to SUBMITTED
2020-08-31 07:48:36,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598860093893_0001 from user: jinhuijun activated in queue: default
2020-08-31 07:48:36,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598860093893_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@20b1fc6b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:48:36,180 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598860093893_0001_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:48:36,198 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:48:36,409 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:48:36,410 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000001
2020-08-31 07:48:36,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860093893_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:46804, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:48:36,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860093893_0001_000001 container=Container: [ContainerId: container_1598860093893_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:48:36,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:48:36,412 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:48:36,442 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:46804 for container : container_1598860093893_0001_01_000001
2020-08-31 07:48:36,466 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:48:36,467 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598860093893_0001_000001
2020-08-31 07:48:36,471 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598860093893_0001 AttemptId: appattempt_1598860093893_0001_000001 MasterContainer: Container: [ContainerId: container_1598860093893_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:46804 }, ]
2020-08-31 07:48:36,491 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:48:36,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:48:36,497 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598860093893_0001_000001
2020-08-31 07:48:36,668 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598860093893_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:46804 }, ] for AM appattempt_1598860093893_0001_000001
2020-08-31 07:48:36,669 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598860093893_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:41630',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:48:36,671 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598860093893_0001_000001
2020-08-31 07:48:36,675 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598860093893_0001_000001
2020-08-31 07:48:37,402 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598860093893_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:46804 }, ] for AM appattempt_1598860093893_0001_000001
2020-08-31 07:48:37,403 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:48:37,455 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:48:46,308 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598860093893_0001_000001 (auth:SIMPLE)
2020-08-31 07:48:46,325 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598860093893_0001_000001
2020-08-31 07:48:46,326 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598860093893_0001	APPATTEMPTID=appattempt_1598860093893_0001_000001
2020-08-31 07:48:46,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:48:46,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:48:46,626 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:48:46,626 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000002
2020-08-31 07:48:46,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860093893_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:46804, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:48:46,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860093893_0001_000001 container=Container: [ContainerId: container_1598860093893_0001_01_000002, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:48:46,626 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:48:46,627 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:48:46,771 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:46804 for container : container_1598860093893_0001_01_000002
2020-08-31 07:48:46,773 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:48:46,994 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:48:46,995 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000003
2020-08-31 07:48:46,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860093893_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46172, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:48:46,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860093893_0001_000001 container=Container: [ContainerId: container_1598860093893_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46172, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:48:46,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:48:46,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:48:47,201 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46172 for container : container_1598860093893_0001_01_000003
2020-08-31 07:48:47,203 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000004
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860093893_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:36653, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860093893_0001_000001 container=Container: [ContainerId: container_1598860093893_0001_01_000004, NodeId: broker3.c.poetic-set-285601.internal:36653, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:48:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:48:47,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:48:48,014 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:48:50,289 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598860093893_0001
2020-08-31 07:48:50,293 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:36653 for container : container_1598860093893_0001_01_000004
2020-08-31 07:48:50,298 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:48:53,314 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:48:53,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860093893_0001_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:48:53,314 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000004
2020-08-31 07:48:53,315 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860093893_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:36653, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:48:53,316 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:48:53,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860093893_0001_01_000004, NodeId: broker3.c.poetic-set-285601.internal:36653, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:36653 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:48:53,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:48:53,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:48:53,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860093893_0001_000001 released container container_1598860093893_0001_01_000004 on node: host: broker3.c.poetic-set-285601.internal:36653 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: RELEASED
2020-08-31 07:49:30,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598860093893_0001_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:49:30,273 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:49:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598860093893_0001 with final state: FINISHING
2020-08-31 07:49:30,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:49:30,275 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598860093893_0001
2020-08-31 07:49:30,275 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:49:30,275 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:49:30,375 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598860093893_0001 unregistered successfully. 
2020-08-31 07:49:30,659 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:49:30,659 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860093893_0001_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:49:30,659 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000003
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860093893_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46172, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860093893_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:46172, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46172 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:49:30,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860093893_0001_000001 released container container_1598860093893_0001_01_000003 on node: host: broker2.c.poetic-set-285601.internal:46172 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:49:30,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:49:30,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860093893_0001_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:49:30,676 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000002
2020-08-31 07:49:30,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860093893_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:46804, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:49:30,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:49:30,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860093893_0001_01_000002, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:46804 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,677 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:49:30,678 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860093893_0001_000001 released container container_1598860093893_0001_01_000002 on node: host: broker1.c.poetic-set-285601.internal:46804 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860093893_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860093893_0001_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860093893_0001	CONTAINERID=container_1598860093893_0001_01_000001
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860093893_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:46804, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860093893_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:46804, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:46804 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:49:30,890 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860093893_0001_000001 released container container_1598860093893_0001_01_000001 on node: host: broker1.c.poetic-set-285601.internal:46804 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:49:30,891 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598860093893_0001_000001
2020-08-31 07:49:30,892 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598860093893_0001_000001
2020-08-31 07:49:30,893 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860093893_0001_000001 State change from FINISHING to FINISHED
2020-08-31 07:49:30,894 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860093893_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:49:30,895 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598860093893_0001
2020-08-31 07:49:30,896 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598860093893_0001_000001 is done. finalState=FINISHED
2020-08-31 07:49:30,905 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598860093893_0001 requests cleared
2020-08-31 07:49:30,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598860093893_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:49:30,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598860093893_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:49:30,924 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598860093893_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598860093893_0001/,appMasterHost=10.178.0.22,startTime=1598860115942,finishTime=1598860170274,finalStatus=SUCCEEDED,memorySeconds=199886,vcoreSeconds=147,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:49:30,926 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598860093893_0001_000001
2020-08-31 07:49:32,661 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:49:32,897 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:49:51,635 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-31 07:49:51,642 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:49:51,643 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 07:49:51,646 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-31 07:49:51,650 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-31 07:49:51,650 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-31 07:49:51,651 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:49:51,653 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-31 07:49:51,654 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-31 07:49:51,654 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:49:51,654 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-31 07:49:51,654 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-31 07:49:51,662 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-31 07:49:51,662 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-31 07:49:51,663 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:49:51,665 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:49:51,665 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-31 07:49:51,665 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-31 07:49:51,666 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-31 07:49:51,667 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:49:51,672 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:49:51,672 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:49:51,672 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-31 07:49:51,672 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:49:51,673 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-31 07:49:51,674 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-31 07:49:51,674 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-31 07:49:51,674 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:49:51,677 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-31 07:49:51,677 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-31 07:53:02,310 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-31 07:53:02,325 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-31 07:53:02,763 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-31 07:53:02,939 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-31 07:53:03,090 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-31 07:53:03,267 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-31 07:53:03,326 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-31 07:53:03,332 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-31 07:53:03,339 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-31 07:53:03,377 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-31 07:53:03,379 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-31 07:53:03,379 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-31 07:53:03,399 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-31 07:53:03,400 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-31 07:53:03,401 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-31 07:53:03,402 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-31 07:53:03,469 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-31 07:53:03,573 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-31 07:53:03,573 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-31 07:53:03,589 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-31 07:53:03,596 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-31 07:53:03,598 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-31 07:53:03,601 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-31 07:53:03,601 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-31 07:53:03,604 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-31 07:53:03,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-31 07:53:03,662 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-31 07:53:03,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-31 07:53:03,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-31 07:53:03,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-31 07:53:03,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-31 07:53:03,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-31 07:53:03,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:53:03,683 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:53:03,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 07:53:03,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-31 07:53:03,684 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-31 07:53:03,698 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-31 07:53:03,698 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-31 07:53:03,713 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-31 07:53:03,713 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-31 07:53:03,714 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-31 07:53:03,714 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:53:03,715 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-31 07:53:03,715 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 07:53:03,718 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 07:53:03,718 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:53:03,718 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-31 07:53:03,718 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 07:53:03,720 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-31 07:53:03,751 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:53:03,770 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-31 07:53:03,954 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-31 07:53:03,954 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:53:03,956 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-31 07:53:03,979 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:53:03,987 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-31 07:53:04,005 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-31 07:53:04,008 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:53:04,010 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-31 07:53:04,065 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 07:53:04,065 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-31 07:53:04,071 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-31 07:53:04,072 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:53:04,072 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-31 07:53:04,099 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-31 07:53:04,243 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-31 07:53:04,250 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-31 07:53:04,259 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-31 07:53:04,268 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-31 07:53:04,271 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-31 07:53:04,271 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-31 07:53:04,272 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-31 07:53:04,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-31 07:53:04,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-31 07:53:04,272 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-31 07:53:04,276 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-31 07:53:04,276 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-31 07:53:04,627 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-31 07:53:04,631 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-31 07:53:04,631 INFO org.mortbay.log: jetty-6.1.26
2020-08-31 07:53:04,660 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-31 07:53:04,863 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:53:04,864 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 07:53:04,864 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 07:53:05,859 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 07:53:05,859 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-31 07:53:05,888 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-31 07:53:05,889 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-31 07:53:05,896 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-31 07:53:05,901 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 07:53:05,901 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-31 07:53:07,875 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:53:07,878 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 46144 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:46144
2020-08-31 07:53:07,882 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:53:07,882 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 38383 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:38383
2020-08-31 07:53:07,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:46144 Node Transitioned from NEW to RUNNING
2020-08-31 07:53:07,905 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:38383 Node Transitioned from NEW to RUNNING
2020-08-31 07:53:07,910 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:46144 clusterResource: <memory:61440, vCores:12>
2020-08-31 07:53:07,911 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:38383 clusterResource: <memory:122880, vCores:24>
2020-08-31 07:53:07,946 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-31 07:53:07,946 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 38900 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:38900
2020-08-31 07:53:07,947 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:38900 Node Transitioned from NEW to RUNNING
2020-08-31 07:53:07,948 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:38900 clusterResource: <memory:184320, vCores:36>
2020-08-31 07:53:12,155 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-08-31 07:53:23,999 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 07:53:24,000 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-08-31 07:53:24,002 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598860383699_0001
2020-08-31 07:53:24,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598860383699_0001
2020-08-31 07:53:24,040 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from NEW to NEW_SAVING on event=START
2020-08-31 07:53:24,041 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598860383699_0001
2020-08-31 07:53:24,048 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 07:53:24,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598860383699_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 07:53:24,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598860383699_0001 from user: jinhuijun, in queue: default
2020-08-31 07:53:24,076 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 07:53:24,149 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598860383699_0001_000001
2020-08-31 07:53:24,150 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from NEW to SUBMITTED
2020-08-31 07:53:24,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598860383699_0001 from user: jinhuijun activated in queue: default
2020-08-31 07:53:24,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598860383699_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7374ecce, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 07:53:24,204 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598860383699_0001_000001 to scheduler from user jinhuijun in queue default
2020-08-31 07:53:24,222 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 07:53:24,318 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:53:24,318 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000001
2020-08-31 07:53:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860383699_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:38383, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 07:53:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860383699_0001_000001 container=Container: [ContainerId: container_1598860383699_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:53:24,321 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:53:24,322 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:53:24,377 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:38383 for container : container_1598860383699_0001_01_000001
2020-08-31 07:53:24,398 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:53:24,400 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598860383699_0001_000001
2020-08-31 07:53:24,404 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598860383699_0001 AttemptId: appattempt_1598860383699_0001_000001 MasterContainer: Container: [ContainerId: container_1598860383699_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:38383 }, ]
2020-08-31 07:53:24,481 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 07:53:24,482 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 07:53:24,493 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598860383699_0001_000001
2020-08-31 07:53:24,872 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598860383699_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:38383 }, ] for AM appattempt_1598860383699_0001_000001
2020-08-31 07:53:24,872 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598860383699_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:41656',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 07:53:24,874 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598860383699_0001_000001
2020-08-31 07:53:24,878 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598860383699_0001_000001
2020-08-31 07:53:26,027 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598860383699_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:38383 }, ] for AM appattempt_1598860383699_0001_000001
2020-08-31 07:53:26,028 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 07:53:26,345 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:53:41,060 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598860383699_0001_000001 (auth:SIMPLE)
2020-08-31 07:53:41,092 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598860383699_0001_000001
2020-08-31 07:53:41,092 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598860383699_0001	APPATTEMPTID=appattempt_1598860383699_0001_000001
2020-08-31 07:53:41,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from LAUNCHED to RUNNING
2020-08-31 07:53:41,093 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000002
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860383699_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:38900, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860383699_0001_000001 container=Container: [ContainerId: container_1598860383699_0001_01_000002, NodeId: broker1.c.poetic-set-285601.internal:38900, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:53:41,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:53:41,376 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:38900 for container : container_1598860383699_0001_01_000002
2020-08-31 07:53:41,379 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:53:41,607 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:53:41,607 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000003
2020-08-31 07:53:41,607 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860383699_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:38383, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 07:53:41,607 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860383699_0001_000001 container=Container: [ContainerId: container_1598860383699_0001_01_000003, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:53:41,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:53:41,608 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:53:41,647 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:38383 for container : container_1598860383699_0001_01_000003
2020-08-31 07:53:41,650 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:53:42,197 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-08-31 07:53:42,198 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000004
2020-08-31 07:53:42,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598860383699_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46144, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 07:53:42,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598860383699_0001_000001 container=Container: [ContainerId: container_1598860383699_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46144, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 07:53:42,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-08-31 07:53:42,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-08-31 07:53:42,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:53:42,618 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 07:53:44,681 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598860383699_0001
2020-08-31 07:53:44,685 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:46144 for container : container_1598860383699_0001_01_000004
2020-08-31 07:53:44,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 07:53:47,712 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-08-31 07:53:47,712 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860383699_0001_01_000004 in state: RELEASED event:RELEASED
2020-08-31 07:53:47,713 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000004
2020-08-31 07:53:47,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860383699_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:46144, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:53:47,715 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-08-31 07:53:47,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860383699_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:46144, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:46144 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-08-31 07:53:47,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 07:53:47,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 07:53:47,716 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860383699_0001_000001 released container container_1598860383699_0001_01_000004 on node: host: broker2.c.poetic-set-285601.internal:46144 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: RELEASED
2020-08-31 07:56:21,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598860383699_0001_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 07:56:21,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 07:56:21,682 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598860383699_0001 with final state: FINISHING
2020-08-31 07:56:21,683 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 07:56:21,683 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598860383699_0001
2020-08-31 07:56:21,684 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 07:56:21,684 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 07:56:21,727 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:56:21,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860383699_0001_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 07:56:21,727 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000002
2020-08-31 07:56:21,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860383699_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:38900, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:56:21,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 07:56:21,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860383699_0001_01_000002, NodeId: broker1.c.poetic-set-285601.internal:38900, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:38900 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 07:56:21,728 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 07:56:21,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 07:56:21,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860383699_0001_000001 released container container_1598860383699_0001_01_000002 on node: host: broker1.c.poetic-set-285601.internal:38900 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:56:21,854 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598860383699_0001 unregistered successfully. 
2020-08-31 07:56:22,069 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:56:22,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860383699_0001_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 07:56:22,069 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000003
2020-08-31 07:56:22,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860383699_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:38383, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 07:56:22,069 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 07:56:22,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860383699_0001_01_000003, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:38383 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 07:56:22,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 07:56:22,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 07:56:22,070 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860383699_0001_000001 released container container_1598860383699_0001_01_000003 on node: host: broker3.c.poetic-set-285601.internal:38383 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 07:56:22,270 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598860383699_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 07:56:22,270 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598860383699_0001_000001
2020-08-31 07:56:22,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598860383699_0001_000001
2020-08-31 07:56:22,272 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598860383699_0001_000001 State change from FINISHING to FINISHED
2020-08-31 07:56:22,270 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598860383699_0001_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 07:56:22,272 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598860383699_0001	CONTAINERID=container_1598860383699_0001_01_000001
2020-08-31 07:56:22,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598860383699_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:38383, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 07:56:22,272 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 07:56:22,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598860383699_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:38383, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:38383 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 07:56:22,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 07:56:22,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 07:56:22,273 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598860383699_0001_000001 released container container_1598860383699_0001_01_000001 on node: host: broker3.c.poetic-set-285601.internal:38383 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 07:56:22,274 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598860383699_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 07:56:22,274 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598860383699_0001_000001 is done. finalState=FINISHED
2020-08-31 07:56:22,276 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598860383699_0001 requests cleared
2020-08-31 07:56:22,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598860383699_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 07:56:22,277 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598860383699_0001
2020-08-31 07:56:22,277 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598860383699_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 07:56:22,277 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598860383699_0001_000001
2020-08-31 07:56:22,279 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598860383699_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598860383699_0001/,appMasterHost=10.178.0.24,startTime=1598860403999,finishTime=1598860581682,finalStatus=SUCCEEDED,memorySeconds=683555,vcoreSeconds=502,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 07:56:23,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:56:24,285 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 07:56:43,929 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-31 07:56:43,933 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:56:43,934 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 07:56:43,936 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-31 07:56:43,939 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-31 07:56:43,939 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:56:43,940 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-31 07:56:43,941 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-31 07:56:43,941 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-31 07:56:43,941 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:56:43,942 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-31 07:56:43,943 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-31 07:56:43,951 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-31 07:56:43,951 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-31 07:56:43,951 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:56:43,953 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 07:56:43,953 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-31 07:56:43,953 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-31 07:56:43,953 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-31 07:56:43,956 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:56:43,958 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:56:43,958 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-31 07:56:43,958 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 07:56:43,958 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 07:56:43,959 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-31 07:56:43,961 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-31 07:56:43,961 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-31 07:56:43,961 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 07:56:43,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-31 07:56:43,961 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-08-31 09:01:22,216 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-08-31 09:01:22,229 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-08-31 09:01:22,598 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-08-31 09:01:22,769 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-08-31 09:01:22,859 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-08-31 09:01:23,089 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-08-31 09:01:23,148 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-08-31 09:01:23,154 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-08-31 09:01:23,161 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-08-31 09:01:23,200 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-08-31 09:01:23,203 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-08-31 09:01:23,203 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-08-31 09:01:23,226 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-08-31 09:01:23,227 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-08-31 09:01:23,228 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-08-31 09:01:23,229 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-08-31 09:01:23,317 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-08-31 09:01:23,435 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-08-31 09:01:23,435 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-08-31 09:01:23,448 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-08-31 09:01:23,455 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-08-31 09:01:23,458 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-08-31 09:01:23,460 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-08-31 09:01:23,461 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-08-31 09:01:23,462 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-08-31 09:01:23,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-08-31 09:01:23,520 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-08-31 09:01:23,524 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-08-31 09:01:23,524 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-08-31 09:01:23,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-08-31 09:01:23,535 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-08-31 09:01:23,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-08-31 09:01:23,536 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 09:01:23,537 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 09:01:23,537 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-08-31 09:01:23,537 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-08-31 09:01:23,538 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-08-31 09:01:23,552 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-08-31 09:01:23,556 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-08-31 09:01:23,572 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-08-31 09:01:23,572 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-08-31 09:01:23,573 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-08-31 09:01:23,573 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 09:01:23,574 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-08-31 09:01:23,574 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 09:01:23,576 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 09:01:23,576 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 09:01:23,576 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-08-31 09:01:23,576 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-08-31 09:01:23,578 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-08-31 09:01:23,612 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 09:01:23,632 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-08-31 09:01:23,837 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-08-31 09:01:23,840 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 09:01:23,843 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-08-31 09:01:23,875 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 09:01:23,882 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-08-31 09:01:23,899 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-08-31 09:01:23,901 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-08-31 09:01:23,905 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 09:01:23,959 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-08-31 09:01:23,960 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-08-31 09:01:23,967 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-08-31 09:01:23,967 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 09:01:23,968 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-08-31 09:01:23,999 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-08-31 09:01:24,205 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-08-31 09:01:24,216 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-08-31 09:01:24,224 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-08-31 09:01:24,235 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-08-31 09:01:24,242 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-08-31 09:01:24,242 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-08-31 09:01:24,242 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-08-31 09:01:24,242 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-08-31 09:01:24,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-08-31 09:01:24,243 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-08-31 09:01:24,247 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-08-31 09:01:24,247 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-08-31 09:01:24,592 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-08-31 09:01:24,595 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-08-31 09:01:24,595 INFO org.mortbay.log: jetty-6.1.26
2020-08-31 09:01:24,623 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-08-31 09:01:24,823 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 09:01:24,825 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-08-31 09:01:24,825 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-08-31 09:01:25,911 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 09:01:25,911 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-08-31 09:01:25,941 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-08-31 09:01:25,947 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-08-31 09:01:25,951 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-08-31 09:01:25,952 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-08-31 09:01:25,960 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-08-31 09:01:28,222 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-08-31 09:01:28,225 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 36759 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:36759
2020-08-31 09:01:28,236 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:36759 Node Transitioned from NEW to RUNNING
2020-08-31 09:01:28,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:36759 clusterResource: <memory:61440, vCores:12>
2020-08-31 09:01:28,352 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-08-31 09:01:28,352 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 37302 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:37302
2020-08-31 09:01:28,352 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:37302 Node Transitioned from NEW to RUNNING
2020-08-31 09:01:28,353 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:37302 clusterResource: <memory:122880, vCores:24>
2020-08-31 09:01:28,356 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-08-31 09:01:28,356 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 34186 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:34186
2020-08-31 09:01:28,357 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:34186 Node Transitioned from NEW to RUNNING
2020-08-31 09:01:28,357 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:34186 clusterResource: <memory:184320, vCores:36>
2020-08-31 09:06:16,444 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-08-31 09:06:23,327 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-08-31 09:06:23,329 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-08-31 09:06:23,331 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1598864483558_0001
2020-08-31 09:06:23,334 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1598864483558_0001
2020-08-31 09:06:23,343 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from NEW to NEW_SAVING on event=START
2020-08-31 09:06:23,343 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1598864483558_0001
2020-08-31 09:06:23,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-08-31 09:06:23,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1598864483558_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-08-31 09:06:23,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1598864483558_0001 from user: jinhuijun, in queue: default
2020-08-31 09:06:23,391 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-08-31 09:06:23,424 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1598864483558_0001_000001
2020-08-31 09:06:23,425 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from NEW to SUBMITTED
2020-08-31 09:06:23,449 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1598864483558_0001 from user: jinhuijun activated in queue: default
2020-08-31 09:06:23,449 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1598864483558_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7374ecce, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-08-31 09:06:23,449 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1598864483558_0001_000001 to scheduler from user jinhuijun in queue default
2020-08-31 09:06:23,459 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from SUBMITTED to SCHEDULED
2020-08-31 09:06:23,515 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-08-31 09:06:23,515 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000001
2020-08-31 09:06:23,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598864483558_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:34186, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-08-31 09:06:23,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598864483558_0001_000001 container=Container: [ContainerId: container_1598864483558_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 09:06:23,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 09:06:23,516 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 09:06:23,628 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:34186 for container : container_1598864483558_0001_01_000001
2020-08-31 09:06:23,641 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 09:06:23,642 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1598864483558_0001_000001
2020-08-31 09:06:23,646 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1598864483558_0001 AttemptId: appattempt_1598864483558_0001_000001 MasterContainer: Container: [ContainerId: container_1598864483558_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:34186 }, ]
2020-08-31 09:06:23,659 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-08-31 09:06:23,660 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-08-31 09:06:23,663 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1598864483558_0001_000001
2020-08-31 09:06:23,693 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1598864483558_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:34186 }, ] for AM appattempt_1598864483558_0001_000001
2020-08-31 09:06:23,694 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1598864483558_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:40156',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-08-31 09:06:23,696 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1598864483558_0001_000001
2020-08-31 09:06:23,698 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1598864483558_0001_000001
2020-08-31 09:06:24,037 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1598864483558_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:34186 }, ] for AM appattempt_1598864483558_0001_000001
2020-08-31 09:06:24,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from ALLOCATED to LAUNCHED
2020-08-31 09:06:24,513 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 09:06:32,098 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1598864483558_0001_000001 (auth:SIMPLE)
2020-08-31 09:06:32,106 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1598864483558_0001_000001
2020-08-31 09:06:32,107 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1598864483558_0001	APPATTEMPTID=appattempt_1598864483558_0001_000001
2020-08-31 09:06:32,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from LAUNCHED to RUNNING
2020-08-31 09:06:32,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-08-31 09:06:32,480 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-08-31 09:06:32,480 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000002
2020-08-31 09:06:32,480 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598864483558_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:37302, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-08-31 09:06:32,480 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598864483558_0001_000001 container=Container: [ContainerId: container_1598864483558_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:37302, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 09:06:32,481 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 09:06:32,481 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 09:06:32,709 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-08-31 09:06:32,709 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000003
2020-08-31 09:06:32,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1598864483558_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:34186, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-08-31 09:06:32,709 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1598864483558_0001_000001 container=Container: [ContainerId: container_1598864483558_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-08-31 09:06:32,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-08-31 09:06:32,710 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-08-31 09:06:32,881 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:37302 for container : container_1598864483558_0001_01_000002
2020-08-31 09:06:32,883 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 09:06:32,884 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:34186 for container : container_1598864483558_0001_01_000003
2020-08-31 09:06:32,885 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-08-31 09:06:33,494 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 09:06:33,723 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-08-31 09:06:35,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1598864483558_0001
2020-08-31 09:11:23,472 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2020-08-31 09:11:24,818 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1598864483558_0001_000001 with final state: FINISHING, and exit status: -1000
2020-08-31 09:11:24,818 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from RUNNING to FINAL_SAVING
2020-08-31 09:11:24,818 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1598864483558_0001 with final state: FINISHING
2020-08-31 09:11:24,819 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-08-31 09:11:24,819 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1598864483558_0001
2020-08-31 09:11:24,823 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from FINAL_SAVING to FINISHING
2020-08-31 09:11:24,823 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-08-31 09:11:24,861 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-08-31 09:11:24,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598864483558_0001_01_000003 in state: COMPLETED event:FINISHED
2020-08-31 09:11:24,861 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000003
2020-08-31 09:11:24,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598864483558_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:34186, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-08-31 09:11:24,861 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-08-31 09:11:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598864483558_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:34186 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-08-31 09:11:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-08-31 09:11:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-08-31 09:11:24,862 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598864483558_0001_000001 released container container_1598864483558_0001_01_000003 on node: host: broker1.c.poetic-set-285601.internal:34186 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-08-31 09:11:24,925 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1598864483558_0001 unregistered successfully. 
2020-08-31 09:11:25,183 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-08-31 09:11:25,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598864483558_0001_01_000002 in state: COMPLETED event:FINISHED
2020-08-31 09:11:25,183 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000002
2020-08-31 09:11:25,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598864483558_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:37302, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 09:11:25,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-08-31 09:11:25,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598864483558_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:37302, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:37302 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-08-31 09:11:25,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-08-31 09:11:25,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-08-31 09:11:25,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598864483558_0001_000001 released container container_1598864483558_0001_01_000002 on node: host: broker3.c.poetic-set-285601.internal:37302 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 09:11:25,313 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1598864483558_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-08-31 09:11:25,313 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1598864483558_0001_000001
2020-08-31 09:11:25,313 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1598864483558_0001_01_000001 in state: COMPLETED event:FINISHED
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1598864483558_0001	CONTAINERID=container_1598864483558_0001_01_000001
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1598864483558_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:34186, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1598864483558_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:34186, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:34186 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1598864483558_0001_000001 released container container_1598864483558_0001_01_000001 on node: host: broker1.c.poetic-set-285601.internal:34186 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-08-31 09:11:25,314 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1598864483558_0001_000001
2020-08-31 09:11:25,316 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1598864483558_0001_000001 State change from FINISHING to FINISHED
2020-08-31 09:11:25,317 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1598864483558_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-08-31 09:11:25,317 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1598864483558_0001_000001 is done. finalState=FINISHED
2020-08-31 09:11:25,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1598864483558_0001 requests cleared
2020-08-31 09:11:25,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1598864483558_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-08-31 09:11:25,318 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1598864483558_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-08-31 09:11:25,318 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1598864483558_0001
2020-08-31 09:11:25,319 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1598864483558_0001_000001
2020-08-31 09:11:25,321 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1598864483558_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1598864483558_0001/,appMasterHost=10.178.0.22,startTime=1598864783327,finishTime=1598865084818,finalStatus=SUCCEEDED,memorySeconds=1207378,vcoreSeconds=885,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-08-31 09:11:27,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 09:11:27,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-08-31 09:11:47,049 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-08-31 09:11:47,085 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 09:11:47,087 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-08-31 09:11:47,188 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-08-31 09:11:47,190 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-08-31 09:11:47,190 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 09:11:47,191 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-08-31 09:11:47,196 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-08-31 09:11:47,197 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-08-31 09:11:47,197 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-08-31 09:11:47,198 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 09:11:47,198 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-08-31 09:11:47,201 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-08-31 09:11:47,201 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 09:11:47,202 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-08-31 09:11:47,208 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-08-31 09:11:47,208 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-08-31 09:11:47,208 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-08-31 09:11:47,208 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 09:11:47,208 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-08-31 09:11:47,209 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 09:11:47,210 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-08-31 09:11:47,210 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-08-31 09:11:47,210 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-08-31 09:11:47,210 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-08-31 09:11:47,214 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-08-31 09:11:47,214 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-08-31 09:11:47,214 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-08-31 09:11:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-08-31 09:11:47,215 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-09-03 11:54:50,284 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-09-03 11:54:50,299 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-09-03 11:54:50,795 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-09-03 11:54:51,035 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-09-03 11:54:51,158 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-09-03 11:54:51,304 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-09-03 11:54:51,363 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-09-03 11:54:51,368 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-09-03 11:54:51,373 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-09-03 11:54:51,409 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-09-03 11:54:51,411 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-09-03 11:54:51,412 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-09-03 11:54:51,432 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-09-03 11:54:51,433 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-09-03 11:54:51,434 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-09-03 11:54:51,435 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-09-03 11:54:51,510 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-09-03 11:54:51,630 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-09-03 11:54:51,630 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-09-03 11:54:51,651 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-09-03 11:54:51,658 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-09-03 11:54:51,661 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-09-03 11:54:51,663 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-09-03 11:54:51,664 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-09-03 11:54:51,665 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-09-03 11:54:51,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-09-03 11:54:51,719 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-09-03 11:54:51,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-09-03 11:54:51,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-09-03 11:54:51,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-09-03 11:54:51,733 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-09-03 11:54:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-09-03 11:54:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 11:54:51,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 11:54:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 11:54:51,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-09-03 11:54:51,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-09-03 11:54:51,755 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-09-03 11:54:51,755 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-09-03 11:54:51,770 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-09-03 11:54:51,770 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-09-03 11:54:51,770 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-09-03 11:54:51,770 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 11:54:51,771 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-09-03 11:54:51,771 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 11:54:51,774 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 11:54:51,775 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 11:54:51,775 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-09-03 11:54:51,775 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 11:54:51,777 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-09-03 11:54:51,815 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 11:54:51,837 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-09-03 11:54:52,042 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-09-03 11:54:52,045 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 11:54:52,047 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-09-03 11:54:52,080 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 11:54:52,087 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-09-03 11:54:52,102 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-09-03 11:54:52,106 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 11:54:52,106 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-09-03 11:54:52,170 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 11:54:52,172 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-09-03 11:54:52,177 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-09-03 11:54:52,178 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 11:54:52,178 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-09-03 11:54:52,210 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-09-03 11:54:52,359 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-09-03 11:54:52,367 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-09-03 11:54:52,374 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-09-03 11:54:52,383 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-09-03 11:54:52,386 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-09-03 11:54:52,387 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-09-03 11:54:52,387 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-09-03 11:54:52,387 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-09-03 11:54:52,387 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-09-03 11:54:52,387 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-09-03 11:54:52,391 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-09-03 11:54:52,391 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-09-03 11:54:52,700 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-09-03 11:54:52,703 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-09-03 11:54:52,703 INFO org.mortbay.log: jetty-6.1.26
2020-09-03 11:54:52,733 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-09-03 11:54:52,931 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 11:54:52,937 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 11:54:52,937 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 11:54:53,934 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 11:54:53,934 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-09-03 11:54:53,967 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-09-03 11:54:53,968 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-09-03 11:54:53,974 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-09-03 11:54:53,974 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 11:54:53,974 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-09-03 11:54:56,361 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-09-03 11:54:56,364 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 34517 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:34517
2020-09-03 11:54:56,377 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:34517 Node Transitioned from NEW to RUNNING
2020-09-03 11:54:56,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:34517 clusterResource: <memory:61440, vCores:12>
2020-09-03 11:54:56,575 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-09-03 11:54:56,575 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 32952 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:32952
2020-09-03 11:54:56,586 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:32952 Node Transitioned from NEW to RUNNING
2020-09-03 11:54:56,592 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:32952 clusterResource: <memory:122880, vCores:24>
2020-09-03 11:54:56,674 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-09-03 11:54:56,675 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 39891 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:39891
2020-09-03 11:54:56,675 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:39891 Node Transitioned from NEW to RUNNING
2020-09-03 11:54:56,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:39891 clusterResource: <memory:184320, vCores:36>
2020-09-03 11:55:09,042 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-09-03 11:55:22,139 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-09-03 11:55:22,141 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-09-03 11:55:22,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1599134091756_0001
2020-09-03 11:55:22,146 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1599134091756_0001
2020-09-03 11:55:22,177 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from NEW to NEW_SAVING on event=START
2020-09-03 11:55:22,178 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1599134091756_0001
2020-09-03 11:55:22,179 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-09-03 11:55:22,181 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1599134091756_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-09-03 11:55:22,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1599134091756_0001 from user: jinhuijun, in queue: default
2020-09-03 11:55:22,199 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-09-03 11:55:22,239 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1599134091756_0001_000001
2020-09-03 11:55:22,240 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from NEW to SUBMITTED
2020-09-03 11:55:22,270 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1599134091756_0001 from user: jinhuijun activated in queue: default
2020-09-03 11:55:22,270 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1599134091756_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7374ecce, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-09-03 11:55:22,271 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1599134091756_0001_000001 to scheduler from user jinhuijun in queue default
2020-09-03 11:55:22,280 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from SUBMITTED to SCHEDULED
2020-09-03 11:55:22,693 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-09-03 11:55:22,693 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000001
2020-09-03 11:55:22,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599134091756_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:34517, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-09-03 11:55:22,697 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599134091756_0001_000001 container=Container: [ContainerId: container_1599134091756_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 11:55:22,698 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-03 11:55:22,698 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:22,724 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:34517 for container : container_1599134091756_0001_01_000001
2020-09-03 11:55:22,742 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 11:55:22,743 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1599134091756_0001_000001
2020-09-03 11:55:22,747 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1599134091756_0001 AttemptId: appattempt_1599134091756_0001_000001 MasterContainer: Container: [ContainerId: container_1599134091756_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:34517 }, ]
2020-09-03 11:55:22,762 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-09-03 11:55:22,763 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-09-03 11:55:22,767 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1599134091756_0001_000001
2020-09-03 11:55:22,945 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1599134091756_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:34517 }, ] for AM appattempt_1599134091756_0001_000001
2020-09-03 11:55:22,945 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1599134091756_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:42881',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-09-03 11:55:22,948 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1599134091756_0001_000001
2020-09-03 11:55:22,952 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1599134091756_0001_000001
2020-09-03 11:55:23,515 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1599134091756_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:34517 }, ] for AM appattempt_1599134091756_0001_000001
2020-09-03 11:55:23,517 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from ALLOCATED to LAUNCHED
2020-09-03 11:55:23,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 11:55:31,502 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1599134091756_0001_000001 (auth:SIMPLE)
2020-09-03 11:55:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1599134091756_0001_000001
2020-09-03 11:55:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1599134091756_0001	APPATTEMPTID=appattempt_1599134091756_0001_000001
2020-09-03 11:55:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from LAUNCHED to RUNNING
2020-09-03 11:55:31,520 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-09-03 11:55:32,822 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-09-03 11:55:32,822 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000002
2020-09-03 11:55:32,822 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599134091756_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:34517, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-09-03 11:55:32,822 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599134091756_0001_000001 container=Container: [ContainerId: container_1599134091756_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 11:55:32,823 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-03 11:55:32,823 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:32,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-09-03 11:55:32,974 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000003
2020-09-03 11:55:32,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599134091756_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:32952, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-03 11:55:32,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599134091756_0001_000001 container=Container: [ContainerId: container_1599134091756_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:32952, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 11:55:32,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-03 11:55:32,974 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:33,012 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:34517 for container : container_1599134091756_0001_01_000002
2020-09-03 11:55:33,013 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 11:55:33,014 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:32952 for container : container_1599134091756_0001_01_000003
2020-09-03 11:55:33,016 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 11:55:33,843 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 11:55:33,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 11:55:36,121 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1599134091756_0001
2020-09-03 11:55:37,462 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1599134091756_0001_000001 with final state: FINISHING, and exit status: -1000
2020-09-03 11:55:37,463 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from RUNNING to FINAL_SAVING
2020-09-03 11:55:37,463 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1599134091756_0001 with final state: FINISHING
2020-09-03 11:55:37,463 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-09-03 11:55:37,465 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1599134091756_0001
2020-09-03 11:55:37,465 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from FINAL_SAVING to FINISHING
2020-09-03 11:55:37,466 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-09-03 11:55:37,566 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1599134091756_0001 unregistered successfully. 
2020-09-03 11:55:37,866 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-09-03 11:55:37,866 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599134091756_0001_01_000002 in state: COMPLETED event:FINISHED
2020-09-03 11:55:37,867 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000002
2020-09-03 11:55:37,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599134091756_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:34517, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-09-03 11:55:37,867 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-09-03 11:55:37,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599134091756_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.24:34517 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-09-03 11:55:37,868 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:37,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-03 11:55:37,869 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599134091756_0001_000001 released container container_1599134091756_0001_01_000002 on node: host: broker3.c.poetic-set-285601.internal:34517 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-09-03 11:55:38,034 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-09-03 11:55:38,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599134091756_0001_01_000001 in state: COMPLETED event:FINISHED
2020-09-03 11:55:38,034 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000001
2020-09-03 11:55:38,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599134091756_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:34517, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 11:55:38,034 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1536, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1536, vCores:1>
2020-09-03 11:55:38,035 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599134091756_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:34517, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:34517 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-09-03 11:55:38,035 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.008333334 absoluteUsedCapacity=0.008333334 used=<memory:1536, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:38,035 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1
2020-09-03 11:55:38,035 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599134091756_0001_000001 released container container_1599134091756_0001_01_000001 on node: host: broker3.c.poetic-set-285601.internal:34517 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-09-03 11:55:38,035 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1599134091756_0001_000001
2020-09-03 11:55:38,036 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1599134091756_0001_000001
2020-09-03 11:55:38,037 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599134091756_0001_000001 State change from FINISHING to FINISHED
2020-09-03 11:55:38,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599134091756_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-09-03 11:55:38,045 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1599134091756_0001
2020-09-03 11:55:38,046 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1599134091756_0001_000001 is done. finalState=FINISHED
2020-09-03 11:55:38,050 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599134091756_0001_01_000003 Container Transitioned from RUNNING to KILLED
2020-09-03 11:55:38,050 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599134091756_0001_01_000003 in state: KILLED event:KILL
2020-09-03 11:55:38,051 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599134091756_0001	CONTAINERID=container_1599134091756_0001_01_000003
2020-09-03 11:55:38,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599134091756_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:32952, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 11:55:38,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-09-03 11:55:38,048 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1599134091756_0001_000001
2020-09-03 11:55:38,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599134091756_0001_01_000003, NodeId: broker2.c.poetic-set-285601.internal:32952, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:32952 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-09-03 11:55:38,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-09-03 11:55:38,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-09-03 11:55:38,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599134091756_0001_000001 released container container_1599134091756_0001_01_000003 on node: host: broker2.c.poetic-set-285601.internal:32952 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-03 11:55:38,055 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1599134091756_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1599134091756_0001/,appMasterHost=10.178.0.24,startTime=1599134122139,finishTime=1599134137463,finalStatus=SUCCEEDED,memorySeconds=31250,vcoreSeconds=25,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-09-03 11:55:38,056 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Container container_1599134091756_0001_01_000003 already scheduled for cleanup, no further processing
2020-09-03 11:55:38,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1599134091756_0001 requests cleared
2020-09-03 11:55:38,057 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1599134091756_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-09-03 11:55:38,057 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1599134091756_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-09-03 11:55:38,215 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 11:55:40,041 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 11:58:29,543 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-09-03 11:58:29,554 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 11:58:29,555 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 11:58:29,656 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-09-03 11:58:29,659 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-09-03 11:58:29,659 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 11:58:29,660 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-09-03 11:58:29,664 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-09-03 11:58:29,664 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-09-03 11:58:29,664 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-09-03 11:58:29,665 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 11:58:29,665 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-09-03 11:58:29,673 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-09-03 11:58:29,673 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 11:58:29,674 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-09-03 11:58:29,675 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 11:58:29,675 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-09-03 11:58:29,675 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-09-03 11:58:29,675 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-09-03 11:58:29,675 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 11:58:29,681 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 11:58:29,681 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 11:58:29,681 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 11:58:29,681 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-09-03 11:58:29,681 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-09-03 11:58:29,683 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-09-03 11:58:29,683 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-09-03 11:58:29,683 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 11:58:29,684 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-09-03 11:58:29,684 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-09-03 12:15:22,333 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-09-03 12:15:22,345 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-09-03 12:15:22,711 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-09-03 12:15:22,866 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-09-03 12:15:22,942 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-09-03 12:15:23,119 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-09-03 12:15:23,191 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-09-03 12:15:23,197 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-09-03 12:15:23,202 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-09-03 12:15:23,238 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-09-03 12:15:23,240 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-09-03 12:15:23,240 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-09-03 12:15:23,261 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-09-03 12:15:23,263 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-09-03 12:15:23,265 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-09-03 12:15:23,266 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-09-03 12:15:23,342 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-09-03 12:15:23,438 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-09-03 12:15:23,438 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-09-03 12:15:23,454 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-09-03 12:15:23,462 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-09-03 12:15:23,464 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-09-03 12:15:23,466 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-09-03 12:15:23,469 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-09-03 12:15:23,471 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-09-03 12:15:23,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-09-03 12:15:23,545 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-09-03 12:15:23,550 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-09-03 12:15:23,550 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-09-03 12:15:23,560 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-09-03 12:15:23,560 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-09-03 12:15:23,561 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-09-03 12:15:23,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:15:23,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:15:23,562 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:15:23,563 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-09-03 12:15:23,563 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-09-03 12:15:23,582 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-09-03 12:15:23,582 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-09-03 12:15:23,596 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-09-03 12:15:23,597 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-09-03 12:15:23,597 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-09-03 12:15:23,597 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:15:23,598 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-09-03 12:15:23,598 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 12:15:23,600 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 12:15:23,600 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:15:23,600 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-09-03 12:15:23,600 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 12:15:23,606 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-09-03 12:15:23,643 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:15:23,655 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-09-03 12:15:23,827 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-09-03 12:15:23,828 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:15:23,829 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-09-03 12:15:23,855 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:15:23,862 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-09-03 12:15:23,878 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-09-03 12:15:23,882 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:15:23,882 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-09-03 12:15:23,931 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:15:23,932 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-09-03 12:15:23,938 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-09-03 12:15:23,938 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:15:23,939 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-09-03 12:15:23,972 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-09-03 12:15:24,129 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-09-03 12:15:24,137 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-09-03 12:15:24,146 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-09-03 12:15:24,157 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-09-03 12:15:24,160 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-09-03 12:15:24,161 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-09-03 12:15:24,161 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-09-03 12:15:24,161 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-09-03 12:15:24,161 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-09-03 12:15:24,161 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-09-03 12:15:24,166 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-09-03 12:15:24,166 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-09-03 12:15:24,533 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-09-03 12:15:24,535 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-09-03 12:15:24,535 INFO org.mortbay.log: jetty-6.1.26
2020-09-03 12:15:24,562 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-09-03 12:15:24,758 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:15:24,765 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 12:15:24,765 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:15:25,657 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 12:15:25,658 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-09-03 12:15:25,680 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-09-03 12:15:25,681 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-09-03 12:15:25,685 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-09-03 12:15:25,686 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:15:25,686 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-09-03 12:15:28,121 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:15:28,127 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 33463 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:33463
2020-09-03 12:15:28,137 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:15:28,137 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 34128 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:34128
2020-09-03 12:15:28,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:33463 Node Transitioned from NEW to RUNNING
2020-09-03 12:15:28,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:34128 Node Transitioned from NEW to RUNNING
2020-09-03 12:15:28,180 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:15:28,181 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 39025 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:39025
2020-09-03 12:15:28,185 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:33463 clusterResource: <memory:61440, vCores:12>
2020-09-03 12:15:28,185 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:34128 clusterResource: <memory:122880, vCores:24>
2020-09-03 12:15:28,185 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:39025 Node Transitioned from NEW to RUNNING
2020-09-03 12:15:28,186 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:39025 clusterResource: <memory:184320, vCores:36>
2020-09-03 12:15:33,282 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-09-03 12:15:45,155 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-09-03 12:15:45,157 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-09-03 12:15:45,159 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1599135323583_0001
2020-09-03 12:15:45,164 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1599135323583_0001
2020-09-03 12:15:45,173 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from NEW to NEW_SAVING on event=START
2020-09-03 12:15:45,179 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1599135323583_0001
2020-09-03 12:15:45,181 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-09-03 12:15:45,183 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1599135323583_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-09-03 12:15:45,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1599135323583_0001 from user: jinhuijun, in queue: default
2020-09-03 12:15:45,202 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-09-03 12:15:45,239 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1599135323583_0001_000001
2020-09-03 12:15:45,240 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from NEW to SUBMITTED
2020-09-03 12:15:45,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1599135323583_0001 from user: jinhuijun activated in queue: default
2020-09-03 12:15:45,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1599135323583_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7374ecce, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-09-03 12:15:45,259 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1599135323583_0001_000001 to scheduler from user jinhuijun in queue default
2020-09-03 12:15:45,266 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from SUBMITTED to SCHEDULED
2020-09-03 12:15:45,431 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:15:45,431 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000001
2020-09-03 12:15:45,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599135323583_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:39025, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-09-03 12:15:45,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599135323583_0001_000001 container=Container: [ContainerId: container_1599135323583_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:39025, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:15:45,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-03 12:15:45,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 12:15:45,466 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:39025 for container : container_1599135323583_0001_01_000001
2020-09-03 12:15:45,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:15:45,489 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1599135323583_0001_000001
2020-09-03 12:15:45,493 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1599135323583_0001 AttemptId: appattempt_1599135323583_0001_000001 MasterContainer: Container: [ContainerId: container_1599135323583_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:39025, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:39025 }, ]
2020-09-03 12:15:45,529 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-09-03 12:15:45,532 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-09-03 12:15:45,536 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1599135323583_0001_000001
2020-09-03 12:15:45,714 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1599135323583_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:39025, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:39025 }, ] for AM appattempt_1599135323583_0001_000001
2020-09-03 12:15:45,714 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1599135323583_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:42011',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-09-03 12:15:45,716 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1599135323583_0001_000001
2020-09-03 12:15:45,720 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1599135323583_0001_000001
2020-09-03 12:15:46,553 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1599135323583_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:39025, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:39025 }, ] for AM appattempt_1599135323583_0001_000001
2020-09-03 12:15:46,553 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from ALLOCATED to LAUNCHED
2020-09-03 12:15:47,445 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:15:59,717 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1599135323583_0001_000001 (auth:SIMPLE)
2020-09-03 12:15:59,771 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1599135323583_0001_000001
2020-09-03 12:15:59,771 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1599135323583_0001	APPATTEMPTID=appattempt_1599135323583_0001_000001
2020-09-03 12:15:59,771 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from LAUNCHED to RUNNING
2020-09-03 12:15:59,772 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000002
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599135323583_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:33463, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599135323583_0001_000001 container=Container: [ContainerId: container_1599135323583_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:33463, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-03 12:16:01,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000003
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599135323583_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:34128, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599135323583_0001_000001 container=Container: [ContainerId: container_1599135323583_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:34128, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-03 12:16:01,617 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-03 12:16:01,671 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:33463 for container : container_1599135323583_0001_01_000002
2020-09-03 12:16:01,673 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:16:01,674 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:34128 for container : container_1599135323583_0001_01_000003
2020-09-03 12:16:01,675 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:16:02,195 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1599135323583_0001
2020-09-03 12:16:02,323 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1599135323583_0001_000001 with final state: FINISHING, and exit status: -1000
2020-09-03 12:16:02,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from RUNNING to FINAL_SAVING
2020-09-03 12:16:02,324 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1599135323583_0001 with final state: FINISHING
2020-09-03 12:16:02,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-09-03 12:16:02,326 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1599135323583_0001
2020-09-03 12:16:02,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from FINAL_SAVING to FINISHING
2020-09-03 12:16:02,326 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-09-03 12:16:02,439 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1599135323583_0001 unregistered successfully. 
2020-09-03 12:16:02,614 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:16:02,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:16:02,921 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-09-03 12:16:02,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599135323583_0001_01_000001 in state: COMPLETED event:FINISHED
2020-09-03 12:16:02,921 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000001
2020-09-03 12:16:02,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599135323583_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:39025, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:3072, vCores:2>
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599135323583_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:39025, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:39025 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.016666668, absoluteUsedCapacity=0.016666668, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.016666668 absoluteUsedCapacity=0.016666668 used=<memory:3072, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.016666668, absoluteUsedCapacity=0.016666668, numApps=1, numContainers=2
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599135323583_0001_000001 released container container_1599135323583_0001_01_000001 on node: host: broker3.c.poetic-set-285601.internal:39025 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-09-03 12:16:02,922 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1599135323583_0001_000001
2020-09-03 12:16:02,924 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1599135323583_0001_000001
2020-09-03 12:16:02,925 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599135323583_0001_000001 State change from FINISHING to FINISHED
2020-09-03 12:16:02,926 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599135323583_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-09-03 12:16:02,927 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1599135323583_0001
2020-09-03 12:16:02,927 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1599135323583_0001_000001 is done. finalState=FINISHED
2020-09-03 12:16:02,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000003 Container Transitioned from RUNNING to KILLED
2020-09-03 12:16:02,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599135323583_0001_01_000003 in state: KILLED event:KILL
2020-09-03 12:16:02,930 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000003
2020-09-03 12:16:02,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599135323583_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:34128, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 12:16:02,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1536, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1536, vCores:1>
2020-09-03 12:16:02,935 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599135323583_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:34128, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:34128 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.008333334 absoluteUsedCapacity=0.008333334 used=<memory:1536, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599135323583_0001_000001 released container container_1599135323583_0001_01_000003 on node: host: broker1.c.poetic-set-285601.internal:34128 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599135323583_0001_01_000002 Container Transitioned from RUNNING to KILLED
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599135323583_0001_01_000002 in state: KILLED event:KILL
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599135323583_0001	CONTAINERID=container_1599135323583_0001_01_000002
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599135323583_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:33463, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 12:16:02,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-09-03 12:16:02,939 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1599135323583_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1599135323583_0001/,appMasterHost=10.178.0.24,startTime=1599135345155,finishTime=1599135362324,finalStatus=SUCCEEDED,memorySeconds=21968,vcoreSeconds=19,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-09-03 12:16:02,939 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599135323583_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:33463, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:33463 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,937 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1599135323583_0001_000001
2020-09-03 12:16:02,940 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-09-03 12:16:02,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-09-03 12:16:02,946 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599135323583_0001_000001 released container container_1599135323583_0001_01_000002 on node: host: broker2.c.poetic-set-285601.internal:33463 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-03 12:16:02,947 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1599135323583_0001 requests cleared
2020-09-03 12:16:02,947 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1599135323583_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-09-03 12:16:02,947 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1599135323583_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-09-03 12:16:03,218 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:16:03,444 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:16:04,222 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:16:04,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:19:01,459 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-09-03 12:19:01,462 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 12:19:01,464 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 12:19:01,564 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-09-03 12:19:01,567 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-09-03 12:19:01,569 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-09-03 12:19:01,569 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:19:01,570 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-09-03 12:19:01,570 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:19:01,571 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-09-03 12:19:01,571 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-09-03 12:19:01,572 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-09-03 12:19:01,575 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-09-03 12:19:01,575 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-09-03 12:19:01,575 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:19:01,577 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-09-03 12:19:01,577 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:19:01,578 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-09-03 12:19:01,578 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-09-03 12:19:01,579 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 12:19:01,583 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 12:19:01,584 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 12:19:01,584 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-09-03 12:19:01,584 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 12:19:01,584 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-09-03 12:19:01,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-09-03 12:19:01,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-09-03 12:19:01,587 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 12:19:01,588 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-09-03 12:19:01,588 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-09-03 12:37:22,003 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-09-03 12:37:22,018 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-09-03 12:37:22,389 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-09-03 12:37:22,550 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-09-03 12:37:22,636 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-09-03 12:37:22,782 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-09-03 12:37:22,884 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-09-03 12:37:22,908 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-09-03 12:37:22,914 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-09-03 12:37:22,950 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-09-03 12:37:22,952 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-09-03 12:37:22,952 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-09-03 12:37:22,979 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-09-03 12:37:22,980 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-09-03 12:37:22,981 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-09-03 12:37:22,982 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-09-03 12:37:23,048 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-09-03 12:37:23,145 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-09-03 12:37:23,145 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-09-03 12:37:23,159 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-09-03 12:37:23,166 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-09-03 12:37:23,168 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-09-03 12:37:23,171 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-09-03 12:37:23,172 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-09-03 12:37:23,173 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-09-03 12:37:23,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-09-03 12:37:23,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-09-03 12:37:23,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-09-03 12:37:23,231 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-09-03 12:37:23,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-09-03 12:37:23,241 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-09-03 12:37:23,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-09-03 12:37:23,242 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:37:23,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:37:23,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-03 12:37:23,243 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-09-03 12:37:23,244 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-09-03 12:37:23,257 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-09-03 12:37:23,257 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-09-03 12:37:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-09-03 12:37:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-09-03 12:37:23,272 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-09-03 12:37:23,273 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:37:23,273 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-09-03 12:37:23,274 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 12:37:23,277 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 12:37:23,277 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:37:23,277 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-09-03 12:37:23,277 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-03 12:37:23,278 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-09-03 12:37:23,311 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:37:23,329 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-09-03 12:37:23,501 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-09-03 12:37:23,501 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:37:23,503 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-09-03 12:37:23,529 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:37:23,536 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-09-03 12:37:23,548 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-09-03 12:37:23,549 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:37:23,549 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-09-03 12:37:23,602 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-03 12:37:23,603 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-09-03 12:37:23,610 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-09-03 12:37:23,611 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:37:23,611 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-09-03 12:37:23,640 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-09-03 12:37:23,785 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-09-03 12:37:23,793 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-09-03 12:37:23,803 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-09-03 12:37:23,812 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-09-03 12:37:23,815 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-09-03 12:37:23,815 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-09-03 12:37:23,815 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-09-03 12:37:23,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-09-03 12:37:23,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-09-03 12:37:23,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-09-03 12:37:23,820 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-09-03 12:37:23,820 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-09-03 12:37:24,203 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-09-03 12:37:24,206 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-09-03 12:37:24,206 INFO org.mortbay.log: jetty-6.1.26
2020-09-03 12:37:24,236 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-09-03 12:37:24,436 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:37:24,450 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-03 12:37:24,450 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-03 12:37:25,496 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 12:37:25,496 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-09-03 12:37:25,525 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-09-03 12:37:25,526 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-09-03 12:37:25,530 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-09-03 12:37:25,534 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-03 12:37:25,535 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-09-03 12:37:27,970 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:37:27,972 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:37:27,988 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 35752 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:35752
2020-09-03 12:37:28,000 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-09-03 12:37:28,001 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 34350 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:34350
2020-09-03 12:37:28,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:35752 Node Transitioned from NEW to RUNNING
2020-09-03 12:37:28,002 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:34350 Node Transitioned from NEW to RUNNING
2020-09-03 12:37:28,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:35752 clusterResource: <memory:61440, vCores:12>
2020-09-03 12:37:28,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:34350 clusterResource: <memory:122880, vCores:24>
2020-09-03 12:37:28,007 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 44355 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:44355
2020-09-03 12:37:28,009 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:44355 Node Transitioned from NEW to RUNNING
2020-09-03 12:37:28,009 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:44355 clusterResource: <memory:184320, vCores:36>
2020-09-03 12:37:32,946 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-09-03 12:37:45,105 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-09-03 12:37:45,106 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-09-03 12:37:45,108 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1599136643258_0001
2020-09-03 12:37:45,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1599136643258_0001
2020-09-03 12:37:45,121 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from NEW to NEW_SAVING on event=START
2020-09-03 12:37:45,121 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1599136643258_0001
2020-09-03 12:37:45,174 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-09-03 12:37:45,178 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1599136643258_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-09-03 12:37:45,179 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1599136643258_0001 from user: jinhuijun, in queue: default
2020-09-03 12:37:45,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-09-03 12:37:45,210 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,212 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from NEW to SUBMITTED
2020-09-03 12:37:45,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1599136643258_0001 from user: jinhuijun activated in queue: default
2020-09-03 12:37:45,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1599136643258_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1de169af, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-09-03 12:37:45,227 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1599136643258_0001_000001 to scheduler from user jinhuijun in queue default
2020-09-03 12:37:45,231 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from SUBMITTED to SCHEDULED
2020-09-03 12:37:45,254 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:37:45,257 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000001
2020-09-03 12:37:45,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599136643258_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-09-03 12:37:45,257 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599136643258_0001_000001 container=Container: [ContainerId: container_1599136643258_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:37:45,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-03 12:37:45,258 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 12:37:45,278 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:34350 for container : container_1599136643258_0001_01_000001
2020-09-03 12:37:45,290 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:37:45,291 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,294 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1599136643258_0001 AttemptId: appattempt_1599136643258_0001_000001 MasterContainer: Container: [ContainerId: container_1599136643258_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ]
2020-09-03 12:37:45,308 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-09-03 12:37:45,309 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-09-03 12:37:45,312 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1599136643258_0001_000001
2020-09-03 12:37:45,456 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1599136643258_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ] for AM appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,456 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1599136643258_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:45063',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-09-03 12:37:45,458 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,462 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,825 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1599136643258_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ] for AM appattempt_1599136643258_0001_000001
2020-09-03 12:37:45,825 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from ALLOCATED to LAUNCHED
2020-09-03 12:37:46,242 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:37:55,056 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1599136643258_0001_000001 (auth:SIMPLE)
2020-09-03 12:37:55,068 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1599136643258_0001_000001
2020-09-03 12:37:55,068 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1599136643258_0001	APPATTEMPTID=appattempt_1599136643258_0001_000001
2020-09-03 12:37:55,068 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from LAUNCHED to RUNNING
2020-09-03 12:37:55,069 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-09-03 12:37:56,356 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:37:56,356 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000002
2020-09-03 12:37:56,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599136643258_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-09-03 12:37:56,356 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599136643258_0001_000001 container=Container: [ContainerId: container_1599136643258_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:37:56,357 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-03 12:37:56,357 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 12:37:56,358 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:34350 for container : container_1599136643258_0001_01_000002
2020-09-03 12:37:56,360 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:37:56,367 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:37:56,367 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000003
2020-09-03 12:37:56,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599136643258_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:35752, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-03 12:37:56,367 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599136643258_0001_000001 container=Container: [ContainerId: container_1599136643258_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:35752, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:37:56,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-03 12:37:56,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-03 12:37:56,821 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:35752 for container : container_1599136643258_0001_01_000003
2020-09-03 12:37:56,823 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:37:57,374 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:37:57,375 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-09-03 12:37:57,376 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000004
2020-09-03 12:37:57,376 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599136643258_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which has 3 containers, <memory:4096, vCores:3> used and <memory:57344, vCores:9> available after allocation
2020-09-03 12:37:57,376 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599136643258_0001_000001 container=Container: [ContainerId: container_1599136643258_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-03 12:37:57,376 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-09-03 12:37:57,376 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-09-03 12:37:57,378 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-09-03 12:37:59,878 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1599136643258_0001
2020-09-03 12:37:59,882 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-03 12:38:02,094 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-09-03 12:38:02,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599136643258_0001_01_000004 in state: RELEASED event:RELEASED
2020-09-03 12:38:02,095 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.23	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000004
2020-09-03 12:38:02,101 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599136643258_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which currently has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available, release resources=true
2020-09-03 12:38:02,103 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-09-03 12:38:02,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599136643258_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,104 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-03 12:38:02,105 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599136643258_0001_000001 released container container_1599136643258_0001_01_000004 on node: host: broker2.c.poetic-set-285601.internal:34350 #containers=2 available=<memory:58880, vCores:10> used=<memory:2560, vCores:2> with event: RELEASED
2020-09-03 12:38:02,159 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1599136643258_0001_000001 with final state: FINISHING, and exit status: -1000
2020-09-03 12:38:02,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from RUNNING to FINAL_SAVING
2020-09-03 12:38:02,161 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1599136643258_0001 with final state: FINISHING
2020-09-03 12:38:02,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-09-03 12:38:02,162 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1599136643258_0001
2020-09-03 12:38:02,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from FINAL_SAVING to FINISHING
2020-09-03 12:38:02,162 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-09-03 12:38:02,182 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-09-03 12:38:02,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599136643258_0001_01_000002 in state: COMPLETED event:FINISHED
2020-09-03 12:38:02,182 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000002
2020-09-03 12:38:02,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599136643258_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-09-03 12:38:02,182 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-09-03 12:38:02,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599136643258_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-03 12:38:02,184 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599136643258_0001_000001 released container container_1599136643258_0001_01_000002 on node: host: broker2.c.poetic-set-285601.internal:34350 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-09-03 12:38:02,276 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1599136643258_0001 unregistered successfully. 
2020-09-03 12:38:02,716 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599136643258_0001_01_000001 in state: COMPLETED event:FINISHED
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000001
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599136643258_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker2.c.poetic-set-285601.internal:34350, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1536, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1536, vCores:1>
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599136643258_0001_01_000001, NodeId: broker2.c.poetic-set-285601.internal:34350, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.23:34350 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.008333334 absoluteUsedCapacity=0.008333334 used=<memory:1536, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1
2020-09-03 12:38:02,717 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599136643258_0001_000001 released container container_1599136643258_0001_01_000001 on node: host: broker2.c.poetic-set-285601.internal:34350 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-09-03 12:38:02,718 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1599136643258_0001_000001
2020-09-03 12:38:02,719 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1599136643258_0001_000001
2020-09-03 12:38:02,720 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599136643258_0001_000001 State change from FINISHING to FINISHED
2020-09-03 12:38:02,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599136643258_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-09-03 12:38:02,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1599136643258_0001_000001 is done. finalState=FINISHED
2020-09-03 12:38:02,721 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599136643258_0001_01_000003 Container Transitioned from RUNNING to KILLED
2020-09-03 12:38:02,721 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599136643258_0001_01_000003 in state: KILLED event:KILL
2020-09-03 12:38:02,721 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599136643258_0001	CONTAINERID=container_1599136643258_0001_01_000003
2020-09-03 12:38:02,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599136643258_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:35752, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-03 12:38:02,722 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1599136643258_0001
2020-09-03 12:38:02,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-09-03 12:38:02,722 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1599136643258_0001_000001
2020-09-03 12:38:02,735 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1599136643258_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1599136643258_0001/,appMasterHost=10.178.0.23,startTime=1599136665105,finishTime=1599136682161,finalStatus=SUCCEEDED,memorySeconds=43836,vcoreSeconds=32,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-09-03 12:38:02,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599136643258_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:35752, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:35752 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-09-03 12:38:02,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-09-03 12:38:02,736 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599136643258_0001_000001 released container container_1599136643258_0001_01_000003 on node: host: broker1.c.poetic-set-285601.internal:35752 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-03 12:38:02,745 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1599136643258_0001 requests cleared
2020-09-03 12:38:02,745 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1599136643258_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-09-03 12:38:02,745 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1599136643258_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-09-03 12:38:03,599 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:38:04,732 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-03 12:41:01,281 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-09-03 12:41:01,286 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 12:41:01,287 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-03 12:41:01,388 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-09-03 12:41:01,390 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-09-03 12:41:01,390 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-09-03 12:41:01,391 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:41:01,392 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-09-03 12:41:01,392 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:41:01,392 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-09-03 12:41:01,392 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-09-03 12:41:01,393 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-09-03 12:41:01,398 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-09-03 12:41:01,398 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:41:01,400 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-09-03 12:41:01,402 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-03 12:41:01,402 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-09-03 12:41:01,403 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-09-03 12:41:01,402 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-09-03 12:41:01,404 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 12:41:01,408 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 12:41:01,408 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-03 12:41:01,409 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-09-03 12:41:01,409 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-03 12:41:01,409 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-09-03 12:41:01,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-09-03 12:41:01,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-09-03 12:41:01,410 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-03 12:41:01,410 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-09-03 12:41:01,411 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-09-04 05:06:50,796 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-09-04 05:06:50,834 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-09-04 05:06:51,203 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-09-04 05:06:51,404 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-09-04 05:06:51,492 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-09-04 05:06:51,689 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-09-04 05:06:51,750 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-09-04 05:06:51,758 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-09-04 05:06:51,764 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-09-04 05:06:51,800 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-09-04 05:06:51,802 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-09-04 05:06:51,803 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-09-04 05:06:51,822 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-09-04 05:06:51,822 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-09-04 05:06:51,823 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-09-04 05:06:51,824 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-09-04 05:06:51,887 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-09-04 05:06:52,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-09-04 05:06:52,001 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-09-04 05:06:52,016 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-09-04 05:06:52,023 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-09-04 05:06:52,025 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-09-04 05:06:52,027 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-09-04 05:06:52,028 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-09-04 05:06:52,029 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-09-04 05:06:52,082 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-09-04 05:06:52,082 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-09-04 05:06:52,086 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-09-04 05:06:52,086 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-09-04 05:06:52,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-09-04 05:06:52,095 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-09-04 05:06:52,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-09-04 05:06:52,096 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:06:52,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:06:52,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:06:52,097 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-09-04 05:06:52,098 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-09-04 05:06:52,116 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-09-04 05:06:52,116 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-09-04 05:06:52,132 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-09-04 05:06:52,132 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-09-04 05:06:52,132 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-09-04 05:06:52,132 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:06:52,133 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-09-04 05:06:52,133 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-04 05:06:52,136 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-04 05:06:52,137 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:06:52,137 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-09-04 05:06:52,137 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-04 05:06:52,138 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-09-04 05:06:52,171 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:06:52,188 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-09-04 05:06:52,351 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-09-04 05:06:52,352 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:06:52,353 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-09-04 05:06:52,375 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:06:52,381 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-09-04 05:06:52,393 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-09-04 05:06:52,394 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:06:52,394 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-09-04 05:06:52,457 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:06:52,458 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-09-04 05:06:52,464 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-09-04 05:06:52,464 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:06:52,465 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-09-04 05:06:52,490 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-09-04 05:06:52,638 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-09-04 05:06:52,647 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-09-04 05:06:52,654 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-09-04 05:06:52,663 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-09-04 05:06:52,667 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-09-04 05:06:52,667 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-09-04 05:06:52,667 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-09-04 05:06:52,667 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-09-04 05:06:52,667 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-09-04 05:06:52,668 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-09-04 05:06:52,671 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-09-04 05:06:52,671 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-09-04 05:06:53,028 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-09-04 05:06:53,031 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-09-04 05:06:53,031 INFO org.mortbay.log: jetty-6.1.26
2020-09-04 05:06:53,064 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-09-04 05:06:53,287 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:06:53,298 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-04 05:06:53,298 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:06:54,383 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-04 05:06:54,383 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-09-04 05:06:54,411 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-09-04 05:06:54,414 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-09-04 05:06:54,418 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-09-04 05:06:54,422 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:06:54,424 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-09-04 05:06:56,795 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:06:56,797 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 40944 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:40944
2020-09-04 05:06:56,801 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:40944 Node Transitioned from NEW to RUNNING
2020-09-04 05:06:56,805 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:40944 clusterResource: <memory:61440, vCores:12>
2020-09-04 05:06:57,065 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:06:57,066 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 45600 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:45600
2020-09-04 05:06:57,066 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:45600 Node Transitioned from NEW to RUNNING
2020-09-04 05:06:57,067 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:45600 clusterResource: <memory:122880, vCores:24>
2020-09-04 05:06:57,220 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:06:57,220 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 42146 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:42146
2020-09-04 05:06:57,220 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:42146 Node Transitioned from NEW to RUNNING
2020-09-04 05:06:57,221 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:42146 clusterResource: <memory:184320, vCores:36>
2020-09-04 05:07:07,962 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-09-04 05:07:21,980 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-09-04 05:07:21,982 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-09-04 05:07:21,984 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1599196012118_0001
2020-09-04 05:07:21,988 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1599196012118_0001
2020-09-04 05:07:21,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from NEW to NEW_SAVING on event=START
2020-09-04 05:07:21,998 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1599196012118_0001
2020-09-04 05:07:22,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-09-04 05:07:22,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1599196012118_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-09-04 05:07:22,054 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1599196012118_0001 from user: jinhuijun, in queue: default
2020-09-04 05:07:22,061 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-09-04 05:07:22,085 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,086 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from NEW to SUBMITTED
2020-09-04 05:07:22,100 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1599196012118_0001 from user: jinhuijun activated in queue: default
2020-09-04 05:07:22,100 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1599196012118_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@1de169af, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-09-04 05:07:22,100 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1599196012118_0001_000001 to scheduler from user jinhuijun in queue default
2020-09-04 05:07:22,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from SUBMITTED to SCHEDULED
2020-09-04 05:07:22,228 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:07:22,228 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000001
2020-09-04 05:07:22,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196012118_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:40944, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-09-04 05:07:22,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196012118_0001_000001 container=Container: [ContainerId: container_1599196012118_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:07:22,229 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-04 05:07:22,230 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:22,249 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker3.c.poetic-set-285601.internal:40944 for container : container_1599196012118_0001_01_000001
2020-09-04 05:07:22,263 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-04 05:07:22,263 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,267 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1599196012118_0001 AttemptId: appattempt_1599196012118_0001_000001 MasterContainer: Container: [ContainerId: container_1599196012118_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:40944 }, ]
2020-09-04 05:07:22,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-09-04 05:07:22,285 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-09-04 05:07:22,290 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1599196012118_0001_000001
2020-09-04 05:07:22,450 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1599196012118_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:40944 }, ] for AM appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,451 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1599196012118_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:37691',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-09-04 05:07:22,453 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,457 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,908 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1599196012118_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:40944 }, ] for AM appattempt_1599196012118_0001_000001
2020-09-04 05:07:22,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from ALLOCATED to LAUNCHED
2020-09-04 05:07:23,259 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-09-04 05:07:34,519 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1599196012118_0001_000001 (auth:SIMPLE)
2020-09-04 05:07:34,527 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1599196012118_0001_000001
2020-09-04 05:07:34,528 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.24	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1599196012118_0001	APPATTEMPTID=appattempt_1599196012118_0001_000001
2020-09-04 05:07:34,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from LAUNCHED to RUNNING
2020-09-04 05:07:34,534 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-09-04 05:07:35,454 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:07:35,454 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000002
2020-09-04 05:07:35,454 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196012118_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:40944, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-09-04 05:07:35,455 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196012118_0001_000001 container=Container: [ContainerId: container_1599196012118_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:07:35,455 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-04 05:07:35,455 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000003
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196012118_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42146, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196012118_0001_000001 container=Container: [ContainerId: container_1599196012118_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42146, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-04 05:07:35,478 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,245 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1599196012118_0001_000001 with final state: FINISHING, and exit status: -1000
2020-09-04 05:07:36,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from RUNNING to FINAL_SAVING
2020-09-04 05:07:36,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1599196012118_0001 with final state: FINISHING
2020-09-04 05:07:36,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-09-04 05:07:36,248 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1599196012118_0001
2020-09-04 05:07:36,248 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from FINAL_SAVING to FINISHING
2020-09-04 05:07:36,248 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-09-04 05:07:36,362 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1599196012118_0001 unregistered successfully. 
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1599196012118_0001_000001
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196012118_0001_01_000001 in state: COMPLETED event:FINISHED
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000001
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196012118_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker3.c.poetic-set-285601.internal:40944, which currently has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available, release resources=true
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:3072, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:3072, vCores:2>
2020-09-04 05:07:36,984 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196012118_0001_01_000001, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.24:40944 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.016666668, absoluteUsedCapacity=0.016666668, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.016666668 absoluteUsedCapacity=0.016666668 used=<memory:3072, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.016666668, absoluteUsedCapacity=0.016666668, numApps=1, numContainers=2
2020-09-04 05:07:36,985 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1599196012118_0001_000001
2020-09-04 05:07:36,985 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196012118_0001_000001 released container container_1599196012118_0001_01_000001 on node: host: broker3.c.poetic-set-285601.internal:40944 #containers=1 available=<memory:59904, vCores:11> used=<memory:1536, vCores:1> with event: FINISHED
2020-09-04 05:07:36,986 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196012118_0001_000001 State change from FINISHING to FINISHED
2020-09-04 05:07:36,987 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196012118_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-09-04 05:07:36,987 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1599196012118_0001_000001 is done. finalState=FINISHED
2020-09-04 05:07:36,988 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1599196012118_0001
2020-09-04 05:07:36,994 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1599196012118_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1599196012118_0001/,appMasterHost=10.178.0.24,startTime=1599196041980,finishTime=1599196056247,finalStatus=SUCCEEDED,memorySeconds=19801,vcoreSeconds=16,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-09-04 05:07:36,995 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000003 Container Transitioned from ALLOCATED to KILLED
2020-09-04 05:07:36,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196012118_0001_01_000003 in state: KILLED event:KILL
2020-09-04 05:07:36,995 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000003
2020-09-04 05:07:36,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196012118_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:42146, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1536, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1536, vCores:1>
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196012118_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:42146, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.008333334 absoluteUsedCapacity=0.008333334 used=<memory:1536, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1536, vCores:1>, usedCapacity=0.008333334, absoluteUsedCapacity=0.008333334, numApps=1, numContainers=1
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196012118_0001_000001 released container container_1599196012118_0001_01_000003 on node: host: broker1.c.poetic-set-285601.internal:42146 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196012118_0001_01_000002 Container Transitioned from ALLOCATED to KILLED
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196012118_0001_01_000002 in state: KILLED event:KILL
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196012118_0001	CONTAINERID=container_1599196012118_0001_01_000002
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196012118_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker3.c.poetic-set-285601.internal:40944, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-09-04 05:07:36,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196012118_0001_01_000002, NodeId: broker3.c.poetic-set-285601.internal:40944, NodeHttpAddress: broker3.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196012118_0001_000001 released container container_1599196012118_0001_01_000002 on node: host: broker3.c.poetic-set-285601.internal:40944 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: KILL
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1599196012118_0001 requests cleared
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1599196012118_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-09-04 05:07:36,997 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1599196012118_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-09-04 05:07:36,992 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1599196012118_0001_000001
2020-09-04 05:10:30,342 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-09-04 05:10:30,346 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-04 05:10:30,348 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-04 05:10:30,350 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-09-04 05:10:30,351 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-09-04 05:10:30,352 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-09-04 05:10:30,352 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:10:30,353 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:10:30,353 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-09-04 05:10:30,353 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-09-04 05:10:30,353 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-09-04 05:10:30,355 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-09-04 05:10:30,360 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-09-04 05:10:30,360 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:10:30,361 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-09-04 05:10:30,362 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:10:30,362 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-09-04 05:10:30,362 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-09-04 05:10:30,362 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-09-04 05:10:30,367 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-04 05:10:30,369 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-04 05:10:30,369 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-04 05:10:30,369 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-09-04 05:10:30,369 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-04 05:10:30,369 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-09-04 05:10:30,370 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-09-04 05:10:30,371 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-09-04 05:10:30,371 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-04 05:10:30,371 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-09-04 05:10:30,371 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
2020-09-04 05:21:11,737 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = producer/10.178.0.25
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.7
STARTUP_MSG:   classpath = /home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hadoop-auth-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsch-0.1.54.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-net-3.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/gson-2.2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/hadoop-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/common/spark-2.3.1-yarn-shuffle.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.7-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/contrib/capacity-scheduler/*.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-client-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-api-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-registry-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.7.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/activation-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/xz-1.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/guice-3.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jettison-1.1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/asm-3.2.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = Unknown -r c1aad84bd27cd79c3d1a7dd58202a8c3ee1ed3ac; compiled by 'stevel' on 2018-07-18T22:47Z
STARTUP_MSG:   java = 1.8.0_262
************************************************************/
2020-09-04 05:21:11,752 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2020-09-04 05:21:12,143 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/core-site.xml
2020-09-04 05:21:12,312 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2020-09-04 05:21:12,394 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/yarn-site.xml
2020-09-04 05:21:12,588 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2020-09-04 05:21:12,653 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2020-09-04 05:21:12,657 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2020-09-04 05:21:12,663 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2020-09-04 05:21:12,698 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2020-09-04 05:21:12,700 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2020-09-04 05:21:12,701 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2020-09-04 05:21:12,721 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2020-09-04 05:21:12,722 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2020-09-04 05:21:12,723 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2020-09-04 05:21:12,723 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2020-09-04 05:21:12,792 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2020-09-04 05:21:12,908 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2020-09-04 05:21:12,908 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2020-09-04 05:21:12,922 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2020-09-04 05:21:12,929 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2020-09-04 05:21:12,931 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2020-09-04 05:21:12,934 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2020-09-04 05:21:12,934 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2020-09-04 05:21:12,936 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/etc/hadoop/capacity-scheduler.xml
2020-09-04 05:21:12,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2020-09-04 05:21:12,991 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2020-09-04 05:21:12,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2020-09-04 05:21:12,995 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2020-09-04 05:21:13,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2020-09-04 05:21:13,005 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2020-09-04 05:21:13,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.98333335 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:30720, vCores:4> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2020-09-04 05:21:13,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:21:13,007 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:21:13,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2020-09-04 05:21:13,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2020-09-04 05:21:13,008 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:512, vCores:1>>, maximumAllocation=<<memory:30720, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2020-09-04 05:21:13,022 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2020-09-04 05:21:13,027 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2020-09-04 05:21:13,042 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2020-09-04 05:21:13,043 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2020-09-04 05:21:13,043 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2020-09-04 05:21:13,043 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:21:13,044 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2020-09-04 05:21:13,044 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-04 05:21:13,048 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-04 05:21:13,048 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:21:13,048 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2020-09-04 05:21:13,048 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2020-09-04 05:21:13,052 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2020-09-04 05:21:13,088 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:21:13,105 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2020-09-04 05:21:13,287 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2020-09-04 05:21:13,288 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:21:13,289 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2020-09-04 05:21:13,323 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:21:13,330 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8880
2020-09-04 05:21:13,342 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2020-09-04 05:21:13,342 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:21:13,343 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8880: starting
2020-09-04 05:21:13,391 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 5000
2020-09-04 05:21:13,392 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2020-09-04 05:21:13,397 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2020-09-04 05:21:13,398 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:21:13,399 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2020-09-04 05:21:13,426 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2020-09-04 05:21:13,565 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2020-09-04 05:21:13,573 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-09-04 05:21:13,581 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2020-09-04 05:21:13,592 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-09-04 05:21:13,595 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2020-09-04 05:21:13,595 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2020-09-04 05:21:13,595 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2020-09-04 05:21:13,596 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2020-09-04 05:21:13,596 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-09-04 05:21:13,596 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-09-04 05:21:13,602 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2020-09-04 05:21:13,602 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2020-09-04 05:21:13,985 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2020-09-04 05:21:13,990 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2020-09-04 05:21:13,990 INFO org.mortbay.log: jetty-6.1.26
2020-09-04 05:21:14,017 INFO org.mortbay.log: Extract jar:file:/home/jinhuijun/streaming-benchmarks/hadoop-2.7.7/share/hadoop/yarn/hadoop-yarn-common-2.7.7.jar!/webapps/cluster to /tmp/Jetty_10_178_0_25_8088_cluster____aw77bf/webapp
2020-09-04 05:21:14,217 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:21:14,218 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-09-04 05:21:14,218 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2020-09-04 05:21:15,228 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-04 05:21:15,228 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app cluster started at 8088
2020-09-04 05:21:15,257 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100
2020-09-04 05:21:15,258 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2020-09-04 05:21:15,262 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2020-09-04 05:21:15,265 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-09-04 05:21:15,265 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2020-09-04 05:21:17,469 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker3.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:21:17,478 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker3.c.poetic-set-285601.internal(cmPort: 43490 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker3.c.poetic-set-285601.internal:43490
2020-09-04 05:21:17,480 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker2.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:21:17,480 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker2.c.poetic-set-285601.internal(cmPort: 43586 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker2.c.poetic-set-285601.internal:43586
2020-09-04 05:21:17,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker3.c.poetic-set-285601.internal:43490 Node Transitioned from NEW to RUNNING
2020-09-04 05:21:17,488 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker2.c.poetic-set-285601.internal:43586 Node Transitioned from NEW to RUNNING
2020-09-04 05:21:17,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker3.c.poetic-set-285601.internal:43490 clusterResource: <memory:61440, vCores:12>
2020-09-04 05:21:17,493 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker2.c.poetic-set-285601.internal:43586 clusterResource: <memory:122880, vCores:24>
2020-09-04 05:21:17,510 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved broker1.c.poetic-set-285601.internal to /default-rack
2020-09-04 05:21:17,510 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node broker1.c.poetic-set-285601.internal(cmPort: 41125 httpPort: 8042) registered with capability: <memory:61440, vCores:12>, assigned nodeId broker1.c.poetic-set-285601.internal:41125
2020-09-04 05:21:17,518 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: broker1.c.poetic-set-285601.internal:41125 Node Transitioned from NEW to RUNNING
2020-09-04 05:21:17,519 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node broker1.c.poetic-set-285601.internal:41125 clusterResource: <memory:184320, vCores:36>
2020-09-04 05:21:23,090 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2020-09-04 05:21:35,130 WARN org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: The specific max attempts: 0 for application: 1 is invalid, because it is out of the range [1, 2]. Use the global max attempts instead.
2020-09-04 05:21:35,131 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user jinhuijun
2020-09-04 05:21:35,133 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.25	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1599196873028_0001
2020-09-04 05:21:35,135 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1599196873028_0001
2020-09-04 05:21:35,177 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from NEW to NEW_SAVING on event=START
2020-09-04 05:21:35,177 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1599196873028_0001
2020-09-04 05:21:35,196 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from NEW_SAVING to SUBMITTED on event=APP_NEW_SAVED
2020-09-04 05:21:35,198 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1599196873028_0001 user: jinhuijun leaf-queue of parent: root #applications: 1
2020-09-04 05:21:35,199 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1599196873028_0001 from user: jinhuijun, in queue: default
2020-09-04 05:21:35,213 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from SUBMITTED to ACCEPTED on event=APP_ACCEPTED
2020-09-04 05:21:35,248 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1599196873028_0001_000001
2020-09-04 05:21:35,250 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from NEW to SUBMITTED
2020-09-04 05:21:35,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1599196873028_0001 from user: jinhuijun activated in queue: default
2020-09-04 05:21:35,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1599196873028_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@7374ecce, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2020-09-04 05:21:35,265 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1599196873028_0001_000001 to scheduler from user jinhuijun in queue default
2020-09-04 05:21:35,270 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from SUBMITTED to SCHEDULED
2020-09-04 05:21:35,748 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:21:35,748 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000001
2020-09-04 05:21:35,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196873028_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:41125, which has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available after allocation
2020-09-04 05:21:35,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196873028_0001_000001 container=Container: [ContainerId: container_1599196873028_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:21:35,750 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-04 05:21:35,751 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-04 05:21:35,782 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:41125 for container : container_1599196873028_0001_01_000001
2020-09-04 05:21:35,794 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-04 05:21:35,797 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1599196873028_0001_000001
2020-09-04 05:21:35,801 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1599196873028_0001 AttemptId: appattempt_1599196873028_0001_000001 MasterContainer: Container: [ContainerId: container_1599196873028_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:41125 }, ]
2020-09-04 05:21:35,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2020-09-04 05:21:35,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2020-09-04 05:21:35,820 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1599196873028_0001_000001
2020-09-04 05:21:35,946 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1599196873028_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:41125 }, ] for AM appattempt_1599196873028_0001_000001
2020-09-04 05:21:35,946 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1599196873028_0001_01_000001 : {{JAVA_HOME}}/bin/java,-server,-Xmx512m,-Djava.io.tmpdir={{PWD}}/tmp,-Dspark.yarn.app.container.log.dir=<LOG_DIR>,org.apache.spark.deploy.yarn.ExecutorLauncher,--arg,'producer.c.poetic-set-285601.internal:46762',--properties-file,{{PWD}}/__spark_conf__/__spark_conf__.properties,1>,<LOG_DIR>/stdout,2>,<LOG_DIR>/stderr
2020-09-04 05:21:35,949 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1599196873028_0001_000001
2020-09-04 05:21:35,952 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1599196873028_0001_000001
2020-09-04 05:21:36,438 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1599196873028_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:41125 }, ] for AM appattempt_1599196873028_0001_000001
2020-09-04 05:21:36,442 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from ALLOCATED to LAUNCHED
2020-09-04 05:21:36,766 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2020-09-04 05:21:45,816 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1599196873028_0001_000001 (auth:SIMPLE)
2020-09-04 05:21:45,829 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1599196873028_0001_000001
2020-09-04 05:21:45,829 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1599196873028_0001	APPATTEMPTID=appattempt_1599196873028_0001_000001
2020-09-04 05:21:45,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from LAUNCHED to RUNNING
2020-09-04 05:21:45,840 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from ACCEPTED to RUNNING on event=ATTEMPT_REGISTERED
2020-09-04 05:21:46,777 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:21:46,777 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000002
2020-09-04 05:21:46,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196873028_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:43586, which has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available after allocation
2020-09-04 05:21:46,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196873028_0001_000001 container=Container: [ContainerId: container_1599196873028_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:43586, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:21:46,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-04 05:21:46,778 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-04 05:21:46,870 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker2.c.poetic-set-285601.internal:43586 for container : container_1599196873028_0001_01_000002
2020-09-04 05:21:46,872 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000003
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196873028_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:41125, which has 2 containers, <memory:2560, vCores:2> used and <memory:58880, vCores:10> available after allocation
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196873028_0001_000001 container=Container: [ContainerId: container_1599196873028_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-04 05:21:46,918 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-04 05:21:47,172 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : broker1.c.poetic-set-285601.internal:41125 for container : container_1599196873028_0001_01_000003
2020-09-04 05:21:47,174 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-04 05:21:47,805 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2020-09-04 05:21:47,806 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000004 Container Transitioned from NEW to ALLOCATED
2020-09-04 05:21:47,806 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000004
2020-09-04 05:21:47,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1599196873028_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:43586, which has 2 containers, <memory:3072, vCores:2> used and <memory:58368, vCores:10> available after allocation
2020-09-04 05:21:47,806 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1599196873028_0001_000001 container=Container: [ContainerId: container_1599196873028_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:43586, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 clusterResource=<memory:184320, vCores:36> type=OFF_SWITCH requestedPartition=
2020-09-04 05:21:47,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:5632, vCores:4>, usedCapacity=0.030555556, absoluteUsedCapacity=0.030555556, numApps=1, numContainers=4
2020-09-04 05:21:47,807 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.030555556 absoluteUsedCapacity=0.030555556 used=<memory:5632, vCores:4> cluster=<memory:184320, vCores:36>
2020-09-04 05:21:47,925 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2020-09-04 05:21:50,188 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1599196873028_0001
2020-09-04 05:21:50,194 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000004 Container Transitioned from ALLOCATED to ACQUIRED
2020-09-04 05:21:53,205 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000004 Container Transitioned from ACQUIRED to RELEASED
2020-09-04 05:21:53,205 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196873028_0001_01_000004 in state: RELEASED event:RELEASED
2020-09-04 05:21:53,205 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	IP=10.178.0.22	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000004
2020-09-04 05:21:53,207 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196873028_0001_01_000004 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:43586, which currently has 1 containers, <memory:1536, vCores:1> used and <memory:59904, vCores:11> available, release resources=true
2020-09-04 05:21:53,208 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:4096, vCores:3> numContainers=3 user=jinhuijun user-resources=<memory:4096, vCores:3>
2020-09-04 05:21:53,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196873028_0001_01_000004, NodeId: broker2.c.poetic-set-285601.internal:43586, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:43586 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3 cluster=<memory:184320, vCores:36>
2020-09-04 05:21:53,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.022222223 absoluteUsedCapacity=0.022222223 used=<memory:4096, vCores:3> cluster=<memory:184320, vCores:36>
2020-09-04 05:21:53,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:4096, vCores:3>, usedCapacity=0.022222223, absoluteUsedCapacity=0.022222223, numApps=1, numContainers=3
2020-09-04 05:21:53,209 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196873028_0001_000001 released container container_1599196873028_0001_01_000004 on node: host: broker2.c.poetic-set-285601.internal:43586 #containers=1 available=<memory:59904, vCores:11> used=<memory:1536, vCores:1> with event: RELEASED
2020-09-04 05:24:30,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2020-09-04 05:24:30,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196873028_0001_01_000002 in state: COMPLETED event:FINISHED
2020-09-04 05:24:30,729 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000002
2020-09-04 05:24:30,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196873028_0001_01_000002 of capacity <memory:1536, vCores:1> on host broker2.c.poetic-set-285601.internal:43586, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-04 05:24:30,729 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2560, vCores:2> numContainers=2 user=jinhuijun user-resources=<memory:2560, vCores:2>
2020-09-04 05:24:30,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196873028_0001_01_000002, NodeId: broker2.c.poetic-set-285601.internal:43586, NodeHttpAddress: broker2.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.23:43586 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2 cluster=<memory:184320, vCores:36>
2020-09-04 05:24:30,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.013888889 absoluteUsedCapacity=0.013888889 used=<memory:2560, vCores:2> cluster=<memory:184320, vCores:36>
2020-09-04 05:24:30,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2560, vCores:2>, usedCapacity=0.013888889, absoluteUsedCapacity=0.013888889, numApps=1, numContainers=2
2020-09-04 05:24:30,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196873028_0001_000001 released container container_1599196873028_0001_01_000002 on node: host: broker2.c.poetic-set-285601.internal:43586 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-09-04 05:24:30,734 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2020-09-04 05:24:30,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196873028_0001_01_000003 in state: COMPLETED event:FINISHED
2020-09-04 05:24:30,734 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000003
2020-09-04 05:24:30,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196873028_0001_01_000003 of capacity <memory:1536, vCores:1> on host broker1.c.poetic-set-285601.internal:41125, which currently has 1 containers, <memory:1024, vCores:1> used and <memory:60416, vCores:11> available, release resources=true
2020-09-04 05:24:30,734 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:1024, vCores:1> numContainers=1 user=jinhuijun user-resources=<memory:1024, vCores:1>
2020-09-04 05:24:30,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196873028_0001_01_000003, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1536, vCores:1>, Priority: 1, Token: Token { kind: ContainerToken, service: 10.178.0.22:41125 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1 cluster=<memory:184320, vCores:36>
2020-09-04 05:24:30,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0055555557 absoluteUsedCapacity=0.0055555557 used=<memory:1024, vCores:1> cluster=<memory:184320, vCores:36>
2020-09-04 05:24:30,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:1024, vCores:1>, usedCapacity=0.0055555557, absoluteUsedCapacity=0.0055555557, numApps=1, numContainers=1
2020-09-04 05:24:30,735 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196873028_0001_000001 released container container_1599196873028_0001_01_000003 on node: host: broker1.c.poetic-set-285601.internal:41125 #containers=1 available=<memory:60416, vCores:11> used=<memory:1024, vCores:1> with event: FINISHED
2020-09-04 05:24:30,814 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1599196873028_0001_000001 with final state: FINISHING, and exit status: -1000
2020-09-04 05:24:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from RUNNING to FINAL_SAVING
2020-09-04 05:24:30,815 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1599196873028_0001 with final state: FINISHING
2020-09-04 05:24:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from RUNNING to FINAL_SAVING on event=ATTEMPT_UNREGISTERED
2020-09-04 05:24:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1599196873028_0001
2020-09-04 05:24:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from FINAL_SAVING to FINISHING
2020-09-04 05:24:30,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from FINAL_SAVING to FINISHING on event=APP_UPDATE_SAVED
2020-09-04 05:24:30,917 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1599196873028_0001 unregistered successfully. 
2020-09-04 05:24:31,298 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1599196873028_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2020-09-04 05:24:31,299 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1599196873028_0001_000001
2020-09-04 05:24:31,299 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1599196873028_0001_000001
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1599196873028_0001_000001 State change from FINISHING to FINISHED
2020-09-04 05:24:31,299 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1599196873028_0001_01_000001 in state: COMPLETED event:FINISHED
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1599196873028_0001	CONTAINERID=container_1599196873028_0001_01_000001
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1599196873028_0001_01_000001 of capacity <memory:1024, vCores:1> on host broker1.c.poetic-set-285601.internal:41125, which currently has 0 containers, <memory:0, vCores:0> used and <memory:61440, vCores:12> available, release resources=true
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=jinhuijun user-resources=<memory:0, vCores:0>
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1599196873028_0001_01_000001, NodeId: broker1.c.poetic-set-285601.internal:41125, NodeHttpAddress: broker1.c.poetic-set-285601.internal:8042, Resource: <memory:1024, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 10.178.0.22:41125 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:184320, vCores:36>
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:184320, vCores:36>
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2020-09-04 05:24:31,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1599196873028_0001_000001 released container container_1599196873028_0001_01_000001 on node: host: broker1.c.poetic-set-285601.internal:41125 #containers=0 available=<memory:61440, vCores:12> used=<memory:0, vCores:0> with event: FINISHED
2020-09-04 05:24:31,301 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1599196873028_0001 State change from FINISHING to FINISHED on event=ATTEMPT_FINISHED
2020-09-04 05:24:31,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1599196873028_0001_000001 is done. finalState=FINISHED
2020-09-04 05:24:31,302 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1599196873028_0001 requests cleared
2020-09-04 05:24:31,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1599196873028_0001 user: jinhuijun queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2020-09-04 05:24:31,303 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1599196873028_0001 user: jinhuijun leaf-queue of parent: root #applications: 0
2020-09-04 05:24:31,303 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=jinhuijun	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1599196873028_0001
2020-09-04 05:24:31,304 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1599196873028_0001_000001
2020-09-04 05:24:31,306 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1599196873028_0001,name=KafkaRedisAdvertisingStream,user=jinhuijun,queue=default,state=FINISHED,trackingUrl=http://producer.c.poetic-set-285601.internal:8088/proxy/application_1599196873028_0001/,appMasterHost=10.178.0.22,startTime=1599196895130,finishTime=1599197070815,finalStatus=SUCCEEDED,memorySeconds=691505,vcoreSeconds=506,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=SPARK
2020-09-04 05:24:32,747 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-04 05:24:33,304 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2020-09-04 05:24:52,637 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2020-09-04 05:24:52,641 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-04 05:24:52,642 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.178.0.25:8088
2020-09-04 05:24:52,643 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2020-09-04 05:24:52,646 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2020-09-04 05:24:52,646 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2020-09-04 05:24:52,646 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:24:52,648 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2020-09-04 05:24:52,648 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2020-09-04 05:24:52,648 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2020-09-04 05:24:52,653 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:24:52,653 INFO org.apache.hadoop.ipc.Server: Stopping server on 8880
2020-09-04 05:24:52,657 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2020-09-04 05:24:52,657 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:24:52,657 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8880
2020-09-04 05:24:52,661 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2020-09-04 05:24:52,661 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2020-09-04 05:24:52,661 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2020-09-04 05:24:52,668 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-04 05:24:52,670 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-04 05:24:52,670 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2020-09-04 05:24:52,670 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2020-09-04 05:24:52,667 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2020-09-04 05:24:52,670 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-09-04 05:24:52,671 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2020-09-04 05:24:52,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2020-09-04 05:24:52,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2020-09-04 05:24:52,672 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2020-09-04 05:24:52,674 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2020-09-04 05:24:52,674 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at producer/10.178.0.25
************************************************************/
